TITLE: March 13-17: Advanced machine learning and data analysis for the physical sciences
AUTHOR: Morten Hjorth-Jensen {copyright, 1999-present|CC BY-NC} at Department of Physics and Center for Computing in Science Education, University of Oslo, Norway & Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA
DATE: March 13-17, 2023

===== Plans for the week March 13-17  =====

!bblock
* Summary of RNNs and discussion of Long-Short-Term memory with examples
* Discussion of Autoencoders (AEs)

* Reading recommendations:
  o For RNNs see Goodfellow et al chapter 10. See also chapter 11 and 12 on practicalities and applications
  o Reading suggestions for implementation of RNNs: "Aurelien Geron's chapter 14":"https://github.com/CompPhysics/MachineLearning/blob/master/doc/Textbooks/TensorflowML.pdf". 
  o "Deep Learning Tutorial on AEs from Stanford University":"http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/"
  o "Building AEs in Keras":"https://blog.keras.io/building-autoencoders-in-keras.html"
  o "Introduction to AEs in TensorFlow":"https://www.tensorflow.org/tutorials/generative/autoencoder"
  o "Grosse, University of Toronto, Lecture on AEs":"http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/slides/lec20.pdf"
  o "Bank et al on AEs":"https://arxiv.org/abs/2003.05991"  
!eblock


!split
===== Summary of RNNs =====
Recurrent neural networks (RNNs) have in general no probabilistic component
in a model. With a given fixed input and target from data, the RNNs learn the intermediate
association between various layers.
The inputs, outputs, and internal representation (hidden states) are all
real-valued vectors.

In a  traditional NN, it is assumed that every input is
independent of each other.  But with sequential data, the input at a given stage $t$ depends on the input from the previous stage $t-1$

!split
===== A typical RNN =====

o Weight matrices $U$, $W$ and $V$ that connect the input layer at a stage $t$ with the hidden layer $h_t$, the previous hidden layer $h_{t-1}$ with $h_t$ and the hidden layer $h_t$ connecting with the output layer at the same stage and producing an output $\tilde{y}_t$, respectively.
o The output from the hidden layer $h_t$ is oftem modulated by a $\tanh{}$ function $h_t=f(x_t,h_{t-1})=\tanh{(Ux_t+Wh_{t-1}+b$ with $b$ a bias value
o The output from the hidden layer produces $\tilde{y}_t=g(Vh_t+c)$ where $c$ is a new bias parameter.
o The output from the training at a given stage is in turn compared with the observation $y_t$ thorugh a chosen cost function.

The function $g$ can any of the standard activation functions, that is a Sigmoid, a Softmax, a ReLU and other.
The parameters are trained through the so-called back-propagation through time (BPTT) algorithm.

=== Gating mechanism: Long Short Term Memory (LSTM) ===

LSTM uses a memory cell for  modeling long-range dependencies and avoid vanishing gradient  problems.
Capable of modeling longer term dependencies by having
memory cells and gates that controls the information flow along
with the memory cells.

o Introduced by Hochreiter and Schmidhuber (1997) who solved the problem of getting an RNN to remember things for a long time (like hundreds of time steps).
o They designed a memory cell using logistic and linear units with multiplicative interactions.
o Information gets into the cell whenever its “write” gate is on.
o The information stays in the cell so long as its _keep_ gate is on.
o Information can be read from the cell by turning on its _read_ gate. 


=== Implementing a memory cell in a neural network ===

To preserve information for a long time in
the activities of an RNN, we use a circuit
that implements an analog memory cell.

o A linear unit that has a self-link with a weight of 1 will maintain its state.
o Information is stored in the cell by activating its write gate.
o Information is retrieved by activating the read gate.
o We can backpropagate through this circuit because logistics are have nice derivatives. 

FIGURE: [figslides/RNN13.png, width=700 frac=0.9]

FIGURE: [figslides/RNN14.png, width=700 frac=0.9]

FIGURE: [figslides/RNN15.png, width=700 frac=0.9]

FIGURE: [figslides/RNN16.png, width=700 frac=0.9]

FIGURE: [figslides/RNN17.png, width=700 frac=0.9]

FIGURE: [figslides/RNN18.png, width=700 frac=0.9]

FIGURE: [figslides/RNN19.png, width=700 frac=0.9]

FIGURE: [figslides/RNN20.png, width=700 frac=0.9]


FIGURE: [figslides/RNN21.png, width=700 frac=0.9]

FIGURE: [figslides/RNN22.png, width=700 frac=0.9]



!split
=====  An extrapolation example =====

The following code provides an example of how recurrent neural
networks can be used to extrapolate to unknown values of physics data
sets.  Specifically, the data sets used in this program come from
a quantum mechanical many-body calculation of energies as functions of the number of particles.


!bc pycod

# For matrices and calculations
import numpy as np
# For machine learning (backend for keras)
import tensorflow as tf
# User-friendly machine learning library
# Front end for TensorFlow
import tensorflow.keras
# Different methods from Keras needed to create an RNN
# This is not necessary but it shortened function calls 
# that need to be used in the code.
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Input
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU
# For timing the code
from timeit import default_timer as timer
# For plotting
import matplotlib.pyplot as plt


# The data set
datatype='VaryDimension'
X_tot = np.arange(2, 42, 2)
y_tot = np.array([-0.03077640549, -0.08336233266, -0.1446729567, -0.2116753732, -0.2830637392, -0.3581341341, -0.436462435, -0.5177783846,
	-0.6019067271, -0.6887363571, -0.7782028952, -0.8702784034, -0.9649652536, -1.062292565, -1.16231451, 
	-1.265109911, -1.370782966, -1.479465113, -1.591317992, -1.70653767])

!ec

!split
===== Formatting the Data =====

The way the recurrent neural networks are trained in this program
differs from how machine learning algorithms are usually trained.
Typically a machine learning algorithm is trained by learning the
relationship between the x data and the y data.  In this program, the
recurrent neural network will be trained to recognize the relationship
in a sequence of y values.  This is type of data formatting is
typically used time series forcasting, but it can also be used in any
extrapolation (time series forecasting is just a specific type of
extrapolation along the time axis).  This method of data formatting
does not use the x data and assumes that the y data are evenly spaced.

For a standard machine learning algorithm, the training data has the
form of (x,y) so the machine learning algorithm learns to assiciate a
y value with a given x value.  This is useful when the test data has x
values within the same range as the training data.  However, for this
application, the x values of the test data are outside of the x values
of the training data and the traditional method of training a machine
learning algorithm does not work as well.  For this reason, the
recurrent neural network is trained on sequences of y values of the
form ((y1, y2), y3), so that the network is concerned with learning
the pattern of the y data and not the relation between the x and y
data.  As long as the pattern of y data outside of the training region
stays relatively stable compared to what was inside the training
region, this method of training can produce accurate extrapolations to
y values far removed from the training data set.


# 
# The idea behind formatting the data in this way comes from [this resource](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) and [this one](https://fairyonice.github.io/Understand-Keras%27s-RNN-behind-the-scenes-with-a-sin-wave-example.html).
# 
# The following method takes in a y data set and formats it so the "x data" are of the form (y1, y2) and the "y data" are of the form y3, with extra brackets added in to make the resulting arrays compatable with both Keras and Tensorflow.
# 
# Note: Using a sequence length of two is not required for time series forecasting so any lenght of sequence could be used (for example instead of ((y1, y2) y3) you could change the length of sequence to be 4 and the resulting data points would have the form ((y1, y2, y3, y4), y5)).  While the following method can be used to create a data set of any sequence length, the remainder of the code expects the length of sequence to be 2.  This is because the data sets are very small and the higher the lenght of the sequence the less resulting data points.

!bc pycod
# FORMAT_DATA
def format_data(data, length_of_sequence = 2):  
    """
        Inputs:
            data(a numpy array): the data that will be the inputs to the recurrent neural
                network
            length_of_sequence (an int): the number of elements in one iteration of the
                sequence patter.  For a function approximator use length_of_sequence = 2.
        Returns:
            rnn_input (a 3D numpy array): the input data for the recurrent neural network.  Its
                dimensions are length of data - length of sequence, length of sequence, 
                dimnsion of data
            rnn_output (a numpy array): the training data for the neural network
        Formats data to be used in a recurrent neural network.
    """

    X, Y = [], []
    for i in range(len(data)-length_of_sequence):
        # Get the next length_of_sequence elements
        a = data[i:i+length_of_sequence]
        # Get the element that immediately follows that
        b = data[i+length_of_sequence]
        # Reshape so that each data point is contained in its own array
        a = np.reshape (a, (len(a), 1))
        X.append(a)
        Y.append(b)
    rnn_input = np.array(X)
    rnn_output = np.array(Y)

    return rnn_input, rnn_output


# ## Defining the Recurrent Neural Network Using Keras
# 
# The following method defines a simple recurrent neural network in keras consisting of one input layer, one hidden layer, and one output layer.

def rnn(length_of_sequences, batch_size = None, stateful = False):
    """
        Inputs:
            length_of_sequences (an int): the number of y values in "x data".  This is determined
                when the data is formatted
            batch_size (an int): Default value is None.  See Keras documentation of SimpleRNN.
            stateful (a boolean): Default value is False.  See Keras documentation of SimpleRNN.
        Returns:
            model (a Keras model): The recurrent neural network that is built and compiled by this
                method
        Builds and compiles a recurrent neural network with one hidden layer and returns the model.
    """
    # Number of neurons in the input and output layers
    in_out_neurons = 1
    # Number of neurons in the hidden layer
    hidden_neurons = 200
    # Define the input layer
    inp = Input(batch_shape=(batch_size, 
                length_of_sequences, 
                in_out_neurons))  
    # Define the hidden layer as a simple RNN layer with a set number of neurons and add it to 
    # the network immediately after the input layer
    rnn = SimpleRNN(hidden_neurons, 
                    return_sequences=False,
                    stateful = stateful,
                    name="RNN")(inp)
    # Define the output layer as a dense neural network layer (standard neural network layer)
    #and add it to the network immediately after the hidden layer.
    dens = Dense(in_out_neurons,name="dense")(rnn)
    # Create the machine learning model starting with the input layer and ending with the 
    # output layer
    model = Model(inputs=[inp],outputs=[dens])
    # Compile the machine learning model using the mean squared error function as the loss 
    # function and an Adams optimizer.
    model.compile(loss="mean_squared_error", optimizer="adam")  
    return model

!ec

!split
===== Predicting New Points With A Trained Recurrent Neural Network =====

!bc pycod
def test_rnn (x1, y_test, plot_min, plot_max):
    """
        Inputs:
            x1 (a list or numpy array): The complete x component of the data set
            y_test (a list or numpy array): The complete y component of the data set
            plot_min (an int or float): the smallest x value used in the training data
            plot_max (an int or float): the largest x valye used in the training data
        Returns:
            None.
        Uses a trained recurrent neural network model to predict future points in the 
        series.  Computes the MSE of the predicted data set from the true data set, saves
        the predicted data set to a csv file, and plots the predicted and true data sets w
        while also displaying the data range used for training.
    """
    # Add the training data as the first dim points in the predicted data array as these
    # are known values.
    y_pred = y_test[:dim].tolist()
    # Generate the first input to the trained recurrent neural network using the last two 
    # points of the training data.  Based on how the network was trained this means that it
    # will predict the first point in the data set after the training data.  All of the 
    # brackets are necessary for Tensorflow.
    next_input = np.array([[[y_test[dim-2]], [y_test[dim-1]]]])
    # Save the very last point in the training data set.  This will be used later.
    last = [y_test[dim-1]]

    # Iterate until the complete data set is created.
    for i in range (dim, len(y_test)):
        # Predict the next point in the data set using the previous two points.
        next = model.predict(next_input)
        # Append just the number of the predicted data set
        y_pred.append(next[0][0])
        # Create the input that will be used to predict the next data point in the data set.
        next_input = np.array([[last, next[0]]], dtype=np.float64)
        last = next

    # Print the mean squared error between the known data set and the predicted data set.
    print('MSE: ', np.square(np.subtract(y_test, y_pred)).mean())
    # Save the predicted data set as a csv file for later use
    name = datatype + 'Predicted'+str(dim)+'.csv'
    np.savetxt(name, y_pred, delimiter=',')
    # Plot the known data set and the predicted data set.  The red box represents the region that was used
    # for the training data.
    fig, ax = plt.subplots()
    ax.plot(x1, y_test, label="true", linewidth=3)
    ax.plot(x1, y_pred, 'g-.',label="predicted", linewidth=4)
    ax.legend()
    # Created a red region to represent the points used in the training data.
    ax.axvspan(plot_min, plot_max, alpha=0.25, color='red')
    plt.show()

# Check to make sure the data set is complete
assert len(X_tot) == len(y_tot)

# This is the number of points that will be used in as the training data
dim=12

# Separate the training data from the whole data set
X_train = X_tot[:dim]
y_train = y_tot[:dim]


# Generate the training data for the RNN, using a sequence of 2
rnn_input, rnn_training = format_data(y_train, 2)


# Create a recurrent neural network in Keras and produce a summary of the 
# machine learning model
model = rnn(length_of_sequences = rnn_input.shape[1])
model.summary()

# Start the timer.  Want to time training+testing
start = timer()
# Fit the model using the training data genenerated above using 150 training iterations and a 5%
# validation split.  Setting verbose to True prints information about each training iteration.
hist = model.fit(rnn_input, rnn_training, batch_size=None, epochs=150, 
                 verbose=True,validation_split=0.05)

for label in ["loss","val_loss"]:
    plt.plot(hist.history[label],label=label)

plt.ylabel("loss")
plt.xlabel("epoch")
plt.title("The final validation loss: {}".format(hist.history["val_loss"][-1]))
plt.legend()
plt.show()

# Use the trained neural network to predict more points of the data set
test_rnn(X_tot, y_tot, X_tot[0], X_tot[dim-1])
# Stop the timer and calculate the total time needed.
end = timer()
print('Time: ', end-start)
!ec

!split
===== Other Things to Try =====


Changing the size of the recurrent neural network and its parameters
can drastically change the results you get from the model.  The below
code takes the simple recurrent neural network from above and adds a
second hidden layer, changes the number of neurons in the hidden
layer, and explicitly declares the activation function of the hidden
layers to be a sigmoid function.  The loss function and optimizer can
also be changed but are kept the same as the above network.  These
parameters can be tuned to provide the optimal result from the
network.  For some ideas on how to improve the performance of a
"recurrent neural network":"https://danijar.com/tips-for-training-recurrent-neural-networks".

!bc pycod
def rnn_2layers(length_of_sequences, batch_size = None, stateful = False):
    """
        Inputs:
            length_of_sequences (an int): the number of y values in "x data".  This is determined
                when the data is formatted
            batch_size (an int): Default value is None.  See Keras documentation of SimpleRNN.
            stateful (a boolean): Default value is False.  See Keras documentation of SimpleRNN.
        Returns:
            model (a Keras model): The recurrent neural network that is built and compiled by this
                method
        Builds and compiles a recurrent neural network with two hidden layers and returns the model.
    """
    # Number of neurons in the input and output layers
    in_out_neurons = 1
    # Number of neurons in the hidden layer, increased from the first network
    hidden_neurons = 500
    # Define the input layer
    inp = Input(batch_shape=(batch_size, 
                length_of_sequences, 
                in_out_neurons))  
    # Create two hidden layers instead of one hidden layer.  Explicitly set the activation
    # function to be the sigmoid function (the default value is hyperbolic tangent)
    rnn1 = SimpleRNN(hidden_neurons, 
                    return_sequences=True,  # This needs to be True if another hidden layer is to follow
                    stateful = stateful, activation = 'sigmoid',
                    name="RNN1")(inp)
    rnn2 = SimpleRNN(hidden_neurons, 
                    return_sequences=False, activation = 'sigmoid',
                    stateful = stateful,
                    name="RNN2")(rnn1)
    # Define the output layer as a dense neural network layer (standard neural network layer)
    #and add it to the network immediately after the hidden layer.
    dens = Dense(in_out_neurons,name="dense")(rnn2)
    # Create the machine learning model starting with the input layer and ending with the 
    # output layer
    model = Model(inputs=[inp],outputs=[dens])
    # Compile the machine learning model using the mean squared error function as the loss 
    # function and an Adams optimizer.
    model.compile(loss="mean_squared_error", optimizer="adam")  
    return model

# Check to make sure the data set is complete
assert len(X_tot) == len(y_tot)

# This is the number of points that will be used in as the training data
dim=12

# Separate the training data from the whole data set
X_train = X_tot[:dim]
y_train = y_tot[:dim]


# Generate the training data for the RNN, using a sequence of 2
rnn_input, rnn_training = format_data(y_train, 2)


# Create a recurrent neural network in Keras and produce a summary of the 
# machine learning model
model = rnn_2layers(length_of_sequences = 2)
model.summary()

# Start the timer.  Want to time training+testing
start = timer()
# Fit the model using the training data genenerated above using 150 training iterations and a 5%
# validation split.  Setting verbose to True prints information about each training iteration.
hist = model.fit(rnn_input, rnn_training, batch_size=None, epochs=150, 
                 verbose=True,validation_split=0.05)


# This section plots the training loss and the validation loss as a function of training iteration.
# This is not required for analyzing the couple cluster data but can help determine if the network is
# being overtrained.
for label in ["loss","val_loss"]:
    plt.plot(hist.history[label],label=label)

plt.ylabel("loss")
plt.xlabel("epoch")
plt.title("The final validation loss: {}".format(hist.history["val_loss"][-1]))
plt.legend()
plt.show()

# Use the trained neural network to predict more points of the data set
test_rnn(X_tot, y_tot, X_tot[0], X_tot[dim-1])
# Stop the timer and calculate the total time needed.
end = timer()
print('Time: ', end-start)
!ec

!split
===== Other Types of Recurrent Neural Networks =====

Besides a simple recurrent neural network layer, there are two other
commonly used types of recurrent neural network layers: Long Short
Term Memory (LSTM) and Gated Recurrent Unit (GRU).  For a short
introduction to these layers see URL:"https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b"
and URL:"https://medium.com/mindboard/lstm-vs-gru-experimental-comparison-955820c21e8b".

The first network created below is similar to the previous network,
but it replaces the SimpleRNN layers with LSTM layers.  The second
network below has two hidden layers made up of GRUs, which are
preceeded by two dense (feeddorward) neural network layers.  These
dense layers "preprocess" the data before it reaches the recurrent
layers.  This architecture has been shown to improve the performance
of recurrent neural networks (see the link above and also
URL:"https://arxiv.org/pdf/1807.02857.pdf".

!bc pycod
def lstm_2layers(length_of_sequences, batch_size = None, stateful = False):
    """
        Inputs:
            length_of_sequences (an int): the number of y values in "x data".  This is determined
                when the data is formatted
            batch_size (an int): Default value is None.  See Keras documentation of SimpleRNN.
            stateful (a boolean): Default value is False.  See Keras documentation of SimpleRNN.
        Returns:
            model (a Keras model): The recurrent neural network that is built and compiled by this
                method
        Builds and compiles a recurrent neural network with two LSTM hidden layers and returns the model.
    """
    # Number of neurons on the input/output layer and the number of neurons in the hidden layer
    in_out_neurons = 1
    hidden_neurons = 250
    # Input Layer
    inp = Input(batch_shape=(batch_size, 
                length_of_sequences, 
                in_out_neurons)) 
    # Hidden layers (in this case they are LSTM layers instead if SimpleRNN layers)
    rnn= LSTM(hidden_neurons, 
                    return_sequences=True,
                    stateful = stateful,
                    name="RNN", use_bias=True, activation='tanh')(inp)
    rnn1 = LSTM(hidden_neurons, 
                    return_sequences=False,
                    stateful = stateful,
                    name="RNN1", use_bias=True, activation='tanh')(rnn)
    # Output layer
    dens = Dense(in_out_neurons,name="dense")(rnn1)
    # Define the midel
    model = Model(inputs=[inp],outputs=[dens])
    # Compile the model
    model.compile(loss='mean_squared_error', optimizer='adam')  
    # Return the model
    return model

def dnn2_gru2(length_of_sequences, batch_size = None, stateful = False):
    """
        Inputs:
            length_of_sequences (an int): the number of y values in "x data".  This is determined
                when the data is formatted
            batch_size (an int): Default value is None.  See Keras documentation of SimpleRNN.
            stateful (a boolean): Default value is False.  See Keras documentation of SimpleRNN.
        Returns:
            model (a Keras model): The recurrent neural network that is built and compiled by this
                method
        Builds and compiles a recurrent neural network with four hidden layers (two dense followed by
        two GRU layers) and returns the model.
    """    
    # Number of neurons on the input/output layers and hidden layers
    in_out_neurons = 1
    hidden_neurons = 250
    # Input layer
    inp = Input(batch_shape=(batch_size, 
                length_of_sequences, 
                in_out_neurons)) 
    # Hidden Dense (feedforward) layers
    dnn = Dense(hidden_neurons/2, activation='relu', name='dnn')(inp)
    dnn1 = Dense(hidden_neurons/2, activation='relu', name='dnn1')(dnn)
    # Hidden GRU layers
    rnn1 = GRU(hidden_neurons, 
                    return_sequences=True,
                    stateful = stateful,
                    name="RNN1", use_bias=True)(dnn1)
    rnn = GRU(hidden_neurons, 
                    return_sequences=False,
                    stateful = stateful,
                    name="RNN", use_bias=True)(rnn1)
    # Output layer
    dens = Dense(in_out_neurons,name="dense")(rnn)
    # Define the model
    model = Model(inputs=[inp],outputs=[dens])
    # Compile the mdoel
    model.compile(loss='mean_squared_error', optimizer='adam')  
    # Return the model
    return model

# Check to make sure the data set is complete
assert len(X_tot) == len(y_tot)

# This is the number of points that will be used in as the training data
dim=12

# Separate the training data from the whole data set
X_train = X_tot[:dim]
y_train = y_tot[:dim]


# Generate the training data for the RNN, using a sequence of 2
rnn_input, rnn_training = format_data(y_train, 2)


# Create a recurrent neural network in Keras and produce a summary of the 
# machine learning model
# Change the method name to reflect which network you want to use
model = dnn2_gru2(length_of_sequences = 2)
model.summary()

# Start the timer.  Want to time training+testing
start = timer()
# Fit the model using the training data genenerated above using 150 training iterations and a 5%
# validation split.  Setting verbose to True prints information about each training iteration.
hist = model.fit(rnn_input, rnn_training, batch_size=None, epochs=150, 
                 verbose=True,validation_split=0.05)


# This section plots the training loss and the validation loss as a function of training iteration.
# This is not required for analyzing the couple cluster data but can help determine if the network is
# being overtrained.
for label in ["loss","val_loss"]:
    plt.plot(hist.history[label],label=label)

plt.ylabel("loss")
plt.xlabel("epoch")
plt.title("The final validation loss: {}".format(hist.history["val_loss"][-1]))
plt.legend()
plt.show()

# Use the trained neural network to predict more points of the data set
test_rnn(X_tot, y_tot, X_tot[0], X_tot[dim-1])
# Stop the timer and calculate the total time needed.
end = timer()
print('Time: ', end-start)


# ### Training Recurrent Neural Networks in the Standard Way (i.e. learning the relationship between the X and Y data)
# 
# Finally, comparing the performace of a recurrent neural network using the standard data formatting to the performance of the network with time sequence data formatting shows the benefit of this type of data formatting with extrapolation.

# Check to make sure the data set is complete
assert len(X_tot) == len(y_tot)

# This is the number of points that will be used in as the training data
dim=12

# Separate the training data from the whole data set
X_train = X_tot[:dim]
y_train = y_tot[:dim]

# Reshape the data for Keras specifications
X_train = X_train.reshape((dim, 1))
y_train = y_train.reshape((dim, 1))


# Create a recurrent neural network in Keras and produce a summary of the 
# machine learning model
# Set the sequence length to 1 for regular data formatting 
model = rnn(length_of_sequences = 1)
model.summary()

# Start the timer.  Want to time training+testing
start = timer()
# Fit the model using the training data genenerated above using 150 training iterations and a 5%
# validation split.  Setting verbose to True prints information about each training iteration.
hist = model.fit(X_train, y_train, batch_size=None, epochs=150, 
                 verbose=True,validation_split=0.05)


# This section plots the training loss and the validation loss as a function of training iteration.
# This is not required for analyzing the couple cluster data but can help determine if the network is
# being overtrained.
for label in ["loss","val_loss"]:
    plt.plot(hist.history[label],label=label)

plt.ylabel("loss")
plt.xlabel("epoch")
plt.title("The final validation loss: {}".format(hist.history["val_loss"][-1]))
plt.legend()
plt.show()

# Use the trained neural network to predict the remaining data points
X_pred = X_tot[dim:]
X_pred = X_pred.reshape((len(X_pred), 1))
y_model = model.predict(X_pred)
y_pred = np.concatenate((y_tot[:dim], y_model.flatten()))

# Plot the known data set and the predicted data set.  The red box represents the region that was used
# for the training data.
fig, ax = plt.subplots()
ax.plot(X_tot, y_tot, label="true", linewidth=3)
ax.plot(X_tot, y_pred, 'g-.',label="predicted", linewidth=4)
ax.legend()
# Created a red region to represent the points used in the training data.
ax.axvspan(X_tot[0], X_tot[dim], alpha=0.25, color='red')
plt.show()

# Stop the timer and calculate the total time needed.
end = timer()
print('Time: ', end-start)

!ec







!split
===== Autoencoders: Overarching view =====

Autoencoders are artificial neural networks capable of learning
efficient representations of the input data (these representations are called codings)  without
any supervision (i.e., the training set is unlabeled). These codings
typically have a much lower dimensionality than the input data, making
autoencoders useful for dimensionality reduction. 

More importantly, autoencoders act as powerful feature detectors, and
they can be used for unsupervised pretraining of deep neural networks.

Lastly, they are capable of randomly generating new data that looks
very similar to the training data; this is called a generative
model. For example, you could train an autoencoder on pictures of
faces, and it would then be able to generate new faces.  Surprisingly,
autoencoders work by simply learning to copy their inputs to their
outputs. This may sound like a trivial task, but we will see that
constraining the network in various ways can make it rather
difficult. For example, you can limit the size of the internal
representation, or you can add noise to the inputs and train the
network to recover the original inputs. These constraints prevent the
autoencoder from trivially copying the inputs directly to the outputs,
which forces it to learn efficient ways of representing the data. In
short, the codings are byproducts of the autoencoder’s attempt to
learn the identity function under some constraints.



!split
===== From supervised to unsupervised training =====

Neural networks are typically used in a supervised setting. Meaning
that for each training observation \(\mathbf{x}_{i}\)\textbf{ }we will
have one label or expected value \(\mathbf{y}_{i}\). During training,
the neural network model will learn the relationship between the input
data and the expected labels. Now suppose we have only unlabeled
observations, meaning we only have our training dataset \( S_{T}\),made of the \( M\) observations \(\mathbf{x}_{i}\) with \( i =
1,\ldots ,M\) %

!bt
\begin{equation}
S_{T} =\left\{\mathbf{x}_{i} \vert  i = 1,\ldots ,M\right\}   \\ 
\end{equation}
!et

%
Where in general \(\mathbf{x}_{i}\in\mathbb{R}^{n}\) with \( n\in\mathbb{N}\).


!split
===== First introduction of AEs =====

Autoencoders were first introduced by Rumelhart, Hinton, and Williams
in 1986 with the goal of learning to reconstruct the input
observations \(\mathbf{x}_{i}\) with the lowest error possible.


Why would one want to learn to reconstruct the input observations? If
you have problems imagining what that means, think of having a dataset
made of images. An autoencoder would be an algorithm that can give as
output an image that is as similar as possible to the input one. You
may be confused, as there is no apparent reason of doing so. To better
understand why autoencoders are useful we need a more informative
(although not yet unambiguous) definition.

!bblock
An autoencoder is a type of algorithm with the primary purpose of learning an "informative" representation of the data that can be used for different applications ("see Bank, D., Koenigstein, N., and Giryes, R., Autoencoders":"https://arxiv.org/abs/2003.05991") by learning to reconstruct a set of input observations well enough.
!eblock

To better understand autoencoders we need to refer to their typical
architecture, visualized in Figure (to be added). The autoencoders'
main components are three: an encoder, a latent feature
representation, and a decoder. The encoder and decoder are simply
functions, while with the name \textit{latent feature representation,}
one typically intends a tensor of real numbers (more on that
later). Generally speaking, we want the autoencoder to reconstruct the
input well enough. Still, at the same time, it should create a latent
representation (the output of the \textbf{encoder} part in Figure
\ref{fig:arch}) that is useful and meaningful. For example, latent
features on hand-written digits\footnote{ Consider for example the
MNIST dataset: \url{http://yann.lecun.com/exdb/mnist/}} could be the
number of lines required to write each number or the angle of each
line and how they connect. Learning how to write numbers certainly
does not require to learn the gray values of each pixel in the input
image. We humans do not certainly learn to write by filling pixels
with gray values. While learning, we extract the essential information
that will allow us to solve a problem (writing digits, for
example). This latent representation (\textit{how} to write each
number) can then be very useful for various tasks (for instance
feature extraction that can be then used for classification or
clustering) or simply understanding the essential features of a
dataset.

\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=3.97cm]{./images/image3.png}
\caption{General structure of an autoencoder.}
\label{fig:arch}
\end{figure}




In most typical architectures, the encoder and the decoder are neural networks\footnote{ For example, if the encoder and the decoder are linear functions, you get what is called a linear autoencoder. See for more information Baldi, P., Hornik, K.: Neural networks and principal component analysis: Learning from examples without local minima, Neural Netw. 2(1), 53-58 (1989).} (that is the case we will discuss at length in this article) since they can be easily trained with existing software libraries such as TensorFlow or PyTorch with backpropagation. 


In general, the encoder can be written as a function \( g\) that will depend on some parameters


!bt
\begin{equation}
\mathbf{h}_{i} = g(\mathbf{x}_{i})
\end{equation}
!et


Where \(\mathbf{h}_{i}\in\mathbb{R}^{q}\) (the latent feature representation) is the output of the \textbf{encoder} block in Figure \ref{fig:arch} when we evaluate it on the input \(\mathbf{x}_{i}\). Note that we will have \( g:\mathbb{R}^{n}\rightarrow\mathbb{R}^{q}\).
The \textbf{decoder} (and the output of the network that we will indicate with \(\tilde{\mathbf{x}}_{i}\)) can be written then as a second generic function \( f\) of the latent features


\begin{equation}
\tilde{\mathbf{x}}_{i} = f\left(\mathbf{h}_{i}\right) = f\left(g\left(\mathbf{x}_{i}\right)\right).
\end{equation}


Where \(\tilde{\mathbf{x}}_{i}\mathbf{\in }\mathbb{R}^{n}\). Training an autoencoder simply means finding the functions \( g(\cdot)\) and \( f(\cdot)\) that satisfy


\begin{equation}
\textrm{arg}\min_{f,g}<\left[\Delta (\mathbf{x}_{i}, f(g\left(\mathbf{x}_{i}\right))\right]>
\end{equation}


where \( \Delta\) indicates a measure of how the input and the output of the autoencoder differ (basically our loss function will penalize the difference between input and output) and \( <\cdot>\) indicates the average over all observations.  Depending on how one designs the autoencoder, it may be possible to find \( f\) and \( g\) so that the autoencoder learns to reconstruct the output perfectly, thus learning the identity function. This is not very useful, as we discussed at the beginning of the article, and to avoid this possibility, two main strategies can be used: creating a bottleneck and add regularization in some form. 

\begin{note}
\textbf{Note} We want the autoencoder to reconstruct the input well enough. Still, at the same time, it should create a latent representation (the output of the encoder) that is useful and meaningful.
\end{note}

Adding a "bottleneck," (more on that later) is achieved by making the
latent feature's dimensionality lower (often much lower) than the
input's. That is the case that we will look in detail in this
article. But before looking at this case, let’s briefly discuss
regularization.


\subsection{Regularization in autoencoders}

We will not discuss regularization at length in this article, but we
should at least mention it. Intuitively it means enforcing sparsity in
the latent feature output. The simplest way of achieving this is to
add a \(\mathcal{l}_{1}\) or \(\mathcal{l}_{2}\) regularization term
to the loss function. That will look like this for the
\(\mathcal{l}_{2}\) regularization term: \begin{equation}
\textrm{arg}\min_{f,g}\mathbb{(E}\left[\Delta (\mathbf{x}_{i},
g(f\left(\mathbf{x}_{i}\right))\right]+\lambda
\sum_{i}^{}\theta_{i}^{2}) \end{equation} In the formula the \(
\theta_{i}\) are the parameters in the functions \( f(\cdot)\) and \(
g(\cdot)\) (you can imagine that in the case where the functions are
neural networks, the parameters will be the weights). This is
typically easy to implement as the derivative with respect to the
parameters are easy to calculate. Another trick that is worth
mentioning is to tie the weights of the encoder to the weights of the
decoder\footnote{ For an example in Keras you can check the following
page:
\url{http://adl.toelt.ai/Chapter25/Your_first_autoencoder_with_Keras.html}
} (in other words make them equal). Those techniques, and a few others
that go beyond the scope of this book, have fundamentally the same
effect: add sparsity to the latent feature representation.

We turn now to a specific type of autoencoders: those that build \(
f\) and \( g\) with feed-forward networks that use a bottleneck. The
reason for this choice is that they are very easy to implement and are
very effective.

\section{Feed Forward Autoencoders}

A Feed-Forward Autoencoder (FFA) is a neural network made of dense layers\footnote{ A dense layer is simply a set of neurons that gets their inputs from the previous layer. Each neuron in a dense layer gets as input the output of all neurons in the previous layer.} with a specific architecture, as can be schematically seen in Figure \ref{fig:arch2}.
\begin{figure}[hbt]
\label{fig:arch2}
\centering
\includegraphics[width=12.6cm,height=7.85cm]{./images/image4.pdf}
\caption{A typical architecture of a Feed-Forward Autoencoder. The number of neurons in the layers at first goes down as we move through the network until it reaches the middle and then starts to grow again until the last layer has the same number of neurons as the input dimensions.}
\end{figure}


A typical FFA architecture (although it is no mandatory requirement)
has an odd number of layers and is symmetrical with respect to the
middle layer. Typically, the first layer has a number of neurons \(
n_{1} = n\) (the size of the input observation
\(\mathbf{x}_{\mathbf{i}}\)). As we move toward the center of the
network, the number of neurons in each layer drops in some
measure. The middle layer (remember we have an odd number of layers)
usually has the smallest number of neurons. The fact that the number
of neurons in this layer is smaller than the size of the input, is the
\textbf{bottleneck} we mentioned earlier.


In almost all practical applications, the layers after the middle one
are a mirrored version of the layers before the middle one. For
example, an autoencoder with 3 layers could have the following numbers
of neurons: \( n_{1} = 10\), \( n_{2} = 5\) and then \( n_{3} = n_{1}
= 10\) (supposing we are working on a problem where the input
dimension is \( n = 10\)). All the layers up to and including the
middle one, make what is called the encoder, and all the layers from
and including the middle one (up to the output) make what is called
the decoder, as you can see depicted in Figure (25.2). If the FFA
training is successful, the result will be a good approximation of the
input, in other words
\(\tilde{\mathbf{x}}_{i}\approx\mathbf{x}_{i}\). What is essential to
notice is that the decoder can reconstruct the input by using only a
much smaller number (\( q\)) of features than the input observations
initially have (\( n\)). The output of the middle layer
\(\mathbf{h}_{\mathbf{i}}\)\textbf{ }are also called a \textit{learned
representation} of the input observation \(\mathbf{x}_{i}\).

\begin{note}
{\bf Note} The encoder can reduce the number of dimensions of the input observation (\( n\)) and create a learned representation (\(\mathbf{h}_{\mathbf{i}}\mathbf{) }\)of the input that has a smaller dimension \( q<n\). This learned representation is enough for the decoder to reconstruct the input accurately (if the autoencoder training was successful as intended). 
\end{note}

\subsection{Activation Function of the Output Layer}

In autoencoders based on neural networks, the output layer's
activation function plays a particularly important role.  The most
used functions are ReLU and sigmoid. Let us look at both and look at
some tips on when to use which and why you should choose one instead
of the other.


\subsubsection{ReLU}

The  ReLU activation function can assume all values in the range \(\left[0,\infty\right]\). As a remainder, its formula is

!bt
\begin{equation}
\textrm{ReLU}\left(x\right) = \max\left(0,x\right).
\end{equation}
!et

This choice is good when the input observations \(\mathbf{x}_{i}\) assume a wide range of positive values.
If the input \(\mathbf{x}_{i}\) can assume negative values, the ReLU is, of course, a terrible choice, and the identity function is a much better choice.

\begin{note}
\textbf{Note }ReLU activation function for the output layer is well suited for cases when the input observations \(\mathbf{x}_{i}\) assume a wide range of positive real values.
\end{note}

\subsubsection{Sigmoid}

The sigmoid function \( \sigma\) can assume all values in the range \( ]0,1[\). As a remained its formula is

!bt
\begin{equation}
\sigma\left(x\right) =\frac{1}{1+e^{-x}}.
\end{equation}
!et


This activation function can only be used if the input observations
\(\mathbf{x}_{i}\) are all in the range \( ]0,1[\) or if you have
normalized them to be in that range. Consider as an example the MNIST
dataset. Each value of the input observation \(\mathbf{x}_{i}\) (one
image) is the gray values of the pixels that can assume any value from
0 to 255. Normalizing the data by dividing the pixel values by 255
would make each observation (each image) have only pixel values
between 0 and 1. In this case, the sigmoid would be a good choice for
the output layer's activation function.

\begin{note}
\textbf{Note }The sigmoid activation function for the output layer is a good choice in all cases where the input observations assume only values between \( 0\) and \( 1\) or if you have normalized them to assume values in the range \( ]0,1[\).
\end{note}

\subsection{Loss Function}

As with any neural network model, we need a loss function to
minimize. This loss functions should measure how big is the difference
between the input \(\mathbf{x}_{i}\) and output
\(\tilde{\mathbf{x}}_{i}\). If you remember the explanations at the
beginning, you will realize that our loss function will be


\begin{equation}
\mathbb{E}\left[\Delta (\mathbf{x}_{i}, g(f\left(\mathbf{x}_{i}\right))\right].
\end{equation}



Where for FFAs, \( g,\) and \( f\) will be the functions that are obtained with dense layers, as discussed in the previous sections. Remember that an autoencoder is trying to learn an approximation of the identity function; therefore, you want to find the weights in the network that gives you the smallest difference according to some metric (\( \Delta (\cdot)\)) between \(\mathbf{x}_{i}\) and \(\tilde{\mathbf{x}}_{i}\). Two loss functions are widely used for autoencoders:  Mean Squared Error (MSE) and Binary Cross-Entropy (BCE). Let us have a more in-depth look at both since they can only be used when specific requirements are met.

\subsubsection{Mean Square Error}

Since an autoencoder is trying to solve a regression problem, the most common choice as a loss function is the Mean Square Error (MSE):
\begin{equation}
\begin{split}
L_{\textrm{MSE}} = \textrm{MSE} = \frac{1}{M}\sum_{i = 1}^{M}\left\vert\mathbf{x}_{i}-\tilde{\mathbf{x}}_{i}\right\vert^{2} \\ 
\end{split}
\end{equation}
The symbol \( \vert \cdot\vert\) indicates the norm of a vector\footnote{ The norm of a vector is simply the square root of the sum of the square of the components.}, and M is the number of the observation in the training dataset. It can be used in almost all cases, independently of how you choose your output layer activation function or how you normalize the input data. 
It is easy to show that the minimum of \( L_{\textrm{MSE}}\) is found for \(\tilde{\mathbf{x}}_{i} =\mathbf{x}_{i}\). To prove it, let us calculate the derivative of \( L_{\textrm{MSE}}\) with respect to a specific observation \( j.\) Remember that the minimum is found when the condition
\begin{equation}
\begin{split}
\frac{\partial L_{MSE}}{\partial\tilde{x}_{j}} = 0 \\ 
\end{split}
\end{equation}
is met for all \( i = 1,\ldots ,M\). To simplify the calculations, let us assume that the inputs are one dimensional\footnote{ If we did not make this assumption, one would have to calculate the gradient of the loss function instead of the simple derivative.} and let us indicate them with \( x_{i}\). We can write
\begin{equation}
\begin{split}
\frac{\partial L_{MSE}}{\partial\tilde{x}_{j}} =  -\frac{2}{M}\left(x_{j}-\tilde{x}_{j}\right) \\ 
\end{split}
\end{equation}
Equation \ref{fig:arch} is satisfied when \( x_{j} =\tilde{x}_{j}\) as can be easily seen from Equation (25.1), as we wanted to prove. To be precise, we also need to show that
\begin{equation}
\begin{split}
\frac{\partial^{2}L_{MSE}}{\partial\tilde{x}_{j}^{2}}>0 \\ 
\end{split}
\end{equation}
This is easily proved as we have
\begin{equation}
\begin{split}
\frac{\partial^{2}L_{MSE}}{\partial\tilde{x}_{j}^{2}} =\frac{2}{M} \\ 
\end{split}
\end{equation}
sthat is greater than zero, therefore confirming our assumption that for \( x_{j} =\tilde{x}_{j}\) we indeed have a minimum.

\subsubsection{Binary Cross-Entropy}

If the activation function of the output layer of the FFA is a sigmoid function, thus limiting neuron outputs to be between 0 and 1, and the input features are normalized to be between 0 and 1 we can use as loss function the binary cross-entropy, indicated here with \( L_{\textrm{CE}}\). Note that this loss function is typically used in classification problems, but it works beautifully for autoencoders. The formula for it is
\begin{equation}
\begin{split}
L_{\textrm{CE}} = -\frac{1}{M}\sum_{i = 1}^{M}\sum_{j = 1}^{n}[x_{j,i} \log\tilde{x}_{j,i}+\left(1-x_{j,i}\right)\log (1-\tilde{x}_{j,i})] \\ 
\end{split}
\end{equation}
Where \( x_{j,i}\) is the \( j^{th}\) component of the \( i^{th}\) observation. The sum is over the entire set of observations and over all components of the vectors. Can we prove that minimizing this loss function is equivalent to reconstructing the input as well as possible? Let us calculate where \( L_{\textrm{CE}}\) has a minimum with respect to \(\tilde{\mathbf{x}}_{i}\). In other words, we need to find out what values should \(\tilde{\mathbf{x}}_{i}\) assume to minimize \( L_{\textrm{CE}}\). As we have done for the MSE, to make the calculations easier, let us consider the simplified case where \(\mathbf{x}_{i}\) and \(\tilde{\mathbf{x}}_{i}\) are one-dimensional and let us indicate them with \( x_{i}\) and \(\tilde{x}_{i}\).

To find the minimum of a function, as you should know from calculus, we need the first derivative of \( L_{\textrm{CE}}\). In particular we need to solve the set of \( M\) equations
\begin{equation}
\frac{\partial L_{\textrm{CE}}}{\partial\tilde{x}_{i}} = 0   \ \ \ \text{for}\ \ \       i = 1,\ldots ,M \\ 
\end{equation}
In this case it is easy to show that the binary cross-entropy \( L_{\textrm{CE}}\) is minimized when \( x_{i} =\tilde{x}_{i}\) for \( i = 1,\ldots ,M\). Note that strictly speaking, this is true only for \( x_{i}\)different than 0 or 1 since \(\tilde{x}_{i}\) can be neither 0 nor 1.
To find when the \( L_{CE}\) is minimized we can derive \( L_{CE}\)with respect to a specific input \(\tilde{x}_{j}\)
\begin{equation}
\begin{array}{lll}
\displaystyle \frac{\partial L_{CE}}{\partial\tilde{x}_{j}} &=& -\displaystyle\frac{1}{M}\left[\frac{x_{j}}{\tilde{x}_{j}}-\frac{1-x_{j}}{1-\tilde{x}_{j}}\right] = -\frac{1}{M}\left[\frac{x_{j}\left(1-\tilde{x}_{j}\right)-\tilde{x}_{j}\left(1-x_{j}\right)}{\tilde{x}_{j}-\tilde{x}_{j}^{2}}\right] =\\ [12px]
&= &-\displaystyle\frac{1}{M}\left[\frac{x_{j}-\tilde{x}_{j}}{\tilde{x}_{j}-\tilde{x}_{j}^{2}}\right]
\end{array}
\end{equation}
Now remember that we need to satisfy the condition 
\begin{equation}
\begin{split}
\frac{\partial L_{CE}}{\partial\tilde{x}_{j}} = 0 \\ 
\end{split}
\end{equation}
That can happen only if \( x_{j} =\tilde{x}_{j}\) as can be seen from Equation (25.2). To make sure that this is a minimum we need to evaluate the second derivative. Since the point for which the first derivative is zero is a minimum only if 
\begin{equation}
\begin{split}
\frac{\partial^{2}L_{CE}}{\partial\tilde{x}_{j}^{2}}>0 \\ 
\end{split}
\end{equation}
We can calculate the second derivative at the minimum point \( x_{j} =\tilde{x}_{j}\)easily 
\begin{equation}
\begin{split}
\left.\frac{\partial^{2}L_{CE}}{\partial\tilde{x}_{j}^{2}}\right\vert_{x_{j} =\tilde{x}_{j}} = -\left.\frac{1}{M}\left[\frac{x_{j}\left(2\tilde{x}_{j}-1\right)-\tilde{x}_{j}^{2}}{\left(1-\tilde{x}_{j}^{2}\right)\tilde{x}_{j}^{2}}\right]\right\vert_{x_{j} =\tilde{x}_{j}} =\frac{1}{M}\left[\frac{\tilde{x}_{j}\left(1-\tilde{x}_{j}\right)}{\left(1-\tilde{x}_{j}^{2}\right)\tilde{x}_{j}^{2}}\right] \\ 
\end{split}
\end{equation}
Now remember that \(\tilde{x}_{j}\in ]0,1[\). We can immediately see that the denominator of the previous formula is greater than zero. The nominator is also clearly greater than zero since \( 1-\tilde{x}_{i}>0\). Dividing two positive numbers gives a positive number, thus we have just proved that 
\begin{equation}
\begin{split}
\frac{\partial^{2}L_{CE}}{\partial\tilde{x}_{i}^{2}}>0 \\ 
\end{split}
\end{equation}
The minimum of the cost function is reached when the output is exactly equal to the inputs, as we wanted to prove. 
\begin{note}
\textbf{Note} an essential prerequisite for using the binary cross-entropy loss function is that the inputs \textbf{must} be normalized between 0 and 1 and that the activation function for the last layer must be a \textit{sigmoid} or \textit{softmax} function.
\end{note}
\subsection{Reconstruction Error}

The reconstruction error (RE) is a metric that gives you an indication of how good (or bad) the autoencoder was able to reconstruct the input observation \(\mathbf{x}_{i}\). The most typical RE used is the MSE
\begin{equation}
\begin{split}
\textrm{RE}\equiv \textrm{MSE} = \frac{1}{M}\sum_{i = 1}^{M}\left\vert\mathbf{x}_{i}-\tilde{\mathbf{x}}_{i}\right\vert^{2}\\ 
\end{split}
\end{equation}



That can be easily calculated. The RE is used often when doing anomaly detection with autoencoders, as we will explain later. There is an easy intuitive explanation of the reconstruction error. When the RE is significant, the autoencoder could not reconstruct the input well, while when it is small, the reconstruction was successful. Figure \ref{fig:rec_err} shows an example of big and small reconstruction errors when an autoencoder tries to reconstruct an image.

\begin{figure}[hbt]
\centering
\includegraphics[width=10.12cm,height=9.16cm]{./images/image5.png}
\caption{An example of big and small reconstruction error when an autoencoder tries to reconstruct an image.}\label{fig:rec_err}
\end{figure}




\subsection{Example: reconstruction of hand-written digits}

Let us now see how an autoencoder performs with a real example, using the MNIST dataset. This dataset\footnote{ More information on the dataset can be found here: \url{http://yann.lecun.com/exdb/mnist/}. } contains 70000 hand-written digits from 0 to 9. Each image is \( 28\times 28\) pixels with only gray values, that means that we have 784 features (the pixel gray values) as inputs. Let us start with an autoencoder with 3 layers with the numbers of neurons in each layer equal to \(\left(784,16,784\right)\). Note that the first and last layers must have a dimension equal to the input dimensions. For this example, we used the Adam optimizer\footnote{ You can find the entire code at the address \url{https://adl.toelt.ai}. }, as loss function the cross-entropy\footnote{ In this case we normalized the input features to be between 0 and 1.} and we trained the model for \( 30\) epochs with a batch size of \( 256\). In Figure  \ref{fig:rec_2} you can see two lines of images of digits. The line at the top contains ten random images from the original dataset, while the ones at the bottom are the reconstructed images with the autoencoder we just described.


\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=2.92cm]{./images/image6.png}
\caption{In the top line, you can see the original digits from the MNIST dataset. In contrast, the line below contains the digits reconstructed by the autoencoder with number of neurons equal to (784, 16, 784).
}\label{fig:rec_2}
\end{figure}
It is impressive that to reconstruct an image with 784 pixels, 10 classes and 70000 images only 16 features are needed to have a result that, although not perfect, allows us to understand almost entirely what digit was used as input. Increasing the middle layer's size to \( 64\) (and leaving all other parameters the same) gets a much better result as you can see in Figure \ref{fig:rec_3}.
\begin{figure}[H]
\centering
\includegraphics[width=12.61cm,height=2.92cm]{./images/image7.png}
\caption{n the top line you can see the original digits from the MNIST dataset. While the line below are the digits reconstructed by the autoencoder with number of neurons equal to (784, 64, 784).}\label{fig:rec_3}
\end{figure}
This tells us that the relevant information on how to write digits is contained in a much lower number of features than 784. 
\begin{note}
\textbf{Note }An autoencoder with a middle layer smaller than the input dimensions (a bottleneck) can be used to extract the essential features of an input dataset creating a learned representation of the inputs given by the function \( g\left(\mathbf{x}_{i}\right)\). Effectively an FFA can be used to perform dimensionality reduction.
\end{note}
The FFA will not recreate the input digits well if the number of neurons in the middle layer is reduced too much (if the bottleneck is too extreme). Figure \ref{fig:rec_4} shows the reconstruction of the same digits with an autoencoder with only 8 neurons in the middle layer. With only 8 neurons in the middle layer, you can see that some reconstructed digits are wrong. As you can see in Figure \ref{fig:rec_4} the 4 is reconstructed as a 9 and a 2 is reconstructed to something that resembles a 3.
\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=2.92cm]{./images/image8.png}
\caption{In the top line you can see the original digits from the MNIST dataset. In contrast, the line below contains the digits reconstructed by the autoencoder with number of neurons equal to (784, 8, 784).
}\label{fig:rec_4}
\end{figure}
In Figure \ref{fig:rec_5}, you can compare the reconstructed digits by all the FFAs we have discussed.
\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=4.36cm]{./images/image9.pdf}
\caption{In the top line, you can see the original digits from the MNIST dataset. The second line of digits contains the digits reconsructed by the FFA (784,8,784), the third by the FFA (784,16,784), and the last one by the FFA (784,64,784).}\label{fig:rec_5}
\end{figure}
From Figure \ref{fig:rec_5} you can see how, increasing the middle layer's size, the reconstruction gets better and better, as we expected. 


For these examples, we have used the binary cross entropy as loss function, but the MSE would have worked also well, and results can be seen in Figure \ref{fig:rec_6}.
\begin{figure}[hbt]
\label{fig:rec_6}
\centering
\includegraphics[width=12.6cm]{./images/image10.png}
\caption{In the top line, you can see ten random original digits from the MNIST dataset. The second line of digits contains the digits reconstructed with an FFA with 16 neurons in the middle layer and the binary cross-entropy as the loss function. The last line contains images reconstructed with the MSE as loss function.}
\end{figure}

\section{Autoencoders Applications}

\subsection{Dimensionality Reduction}

As we mentioned in this article, using the bottleneck method, the latent features will have a dimension \( q\) that is smaller than the dimensions of the input observations \( n\). The \textit{encoder} part (once trained) does naturally (by design) dimension reduction producing \( q\) real numbers. One can use the latent features for various tasks, such as classification (as we will see in the next section) or clustering. We would like to point out some of the advantages of dimensionality reduction with an autoencoder compared to a more classical PCA approach. The autoencoder has one main benefit from a computational point of view: it can deal with a very big amount of data efficiently since its training can be done with mini-batches, while PCA, one of the most used dimensionality reduction algorithms, needs to do its calculations using the entire dataset. PCA is an algorithm that projects a dataset on the eigenvectors of its covariance matrix\footnote{ Akshay Balsubramani, Sanjoy Dasgupta, and Yoav Freund. The fast convergence of incremental pca. In Advances in neural information processing systems, pages 3174–3182, 2013.}, thus providing a linear transformation of the features. Autoencoders are more flexible and consider non-linear transformations of the features. The default PCA method uses \(\mathcal{O}\left(d^{2}\right)\) space for data in \(\mathbb{R}^{d}\). This is, in many cases, not computationally feasible, and the algorithm does not scale up with increasing dataset size. This may seem irrelevant, but in many practical applications, the amount of data and the number of features is so big that PCA is not a practical solution from a computational point of view. 
\begin{note}
\textbf{Note }The use of an autoencoder for dimensionality reduction has one main advantage from a computational point of view: it can deal with a very big amount of data efficiently since its training can be done with mini-batches.
\end{note}
\paragraph{Equivalence with PCA}

It is not a very known results, but one worth to mention, that a FFA is equivalent to PCA if the following conditions are met:
\begin{itemize}
\item We use a linear function for the encoder \( g(\cdot)\)
\item We use a linear function for the decoder \( f(\cdot)\)
\item We use the MSE for the loss function
\item We normalize the inputs to 
\begin{equation}
\hat{x}_{i,j} =\frac{1}{\sqrt{M}}\left(x_{i,j}-\frac{1}{M}\sum_{k = 1}^{M}x_{k,j}\right)
\end{equation}
\end{itemize}


The proof is long and can found in the notes by M.M. Kahpra for the course CS7015 (Indian Institute of Technology Madras) at this link \url{http://toe.lt/1a}. 

\subsection{Classification}

\subsubsection{Classification with Latent Features}

Let us now suppose that we want to classify our input images of the MNIST dataset. We can simply use all the features, in our case, the \( 784\) pixel values of the images. We can simply use an algorithm as kNN for illustrative purposes. Doing it with \( 7\) nearest neighbors on the training MNIST dataset (with 60000 images) will take around 16.6 minutes\footnote{ The examples have been run on Google Colab.} (ca. 1000 sec) and gets you an accuracy on the test dataset of 10000 images of \( 96.4 \%\footnote{ Note that for these examples the accuracy is calculated applying the trained model on the test dataset, while the running time is the time needed to train the algorithm on the training dataset.}\). However, what happens if we use this algorithm not with the original dataset, but with the latent features \( g\left(\mathbf{x}_{i}\right)\)? For example, if we consider an FFA with \( 8\) neurons in the middle layer and again train a kNN algorithm on the latent features \( g\left(\mathbf{x}_{i}\right)\in\mathbb{R}^{8}\) we get an accuracy of 89$\%$ in 1.1 sec. We get a gain of a factor of 1000 in running time, for a loss of 7.4$\%$ in accuracy\footnote{ You can run those tests yourself going to article 25 at https://adl.toelt.ai. } (see Table \ref{tab:run1}). 

\begin{table}[hbt]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{4.89cm}p{4cm}p{4.59cm}}
%\hline
\multicolumn{1}{p{4.9cm}}{Input Data} & 
\multicolumn{1}{p{4cm}}{Accuracy} & 
\multicolumn{1}{p{4.6cm}}{Running Time} \\ 
\hline
\multicolumn{1}{p{4.9cm}}{Original data \(\mathbf{x}_{i}\in\mathbb{R}^{784}\)} & 
\multicolumn{1}{p{4cm}}{96.4$\%$} & 
\multicolumn{1}{p{4.6cm}}{\( 1000\) sec. \( \approx 16.6\) min.} \\ 
%\hline
\multicolumn{1}{p{4.9cm}}{Latent Features g\(\left(\mathbf{x}_{i}\right)\in\mathbb{R}^{8}\)} & 
\multicolumn{1}{p{4cm}}{89$\%$} & 
\multicolumn{1}{p{4.6cm}}{1.1 sec.} \\ 
%\hline
\end{tabular}
\end{adjustbox}
\caption{the different in accuracy and running time when applying the kNN algorithm to the original 784 features or the 8 latent features for the MNIST dataset.}\label{tab:run1}
\end{table}

%Table 25.1: 
Using \( 8\) features allow us to get a very high accuracy in just one second. 
We can do the same analysis with another dataset, the Fashion MNIST\footnote{ https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/ } dataset (a dataset from Zalando very similar to the MNIST one, only with clothing images instead of hand-written digits) for illustrative purposes. The dataset has, as the MNIST one, 60000 training images and 10000 test ones. In Table \ref{tab:run2} you can see the summary of the results of applying kNN to the testing portion of this dataset.
\begin{table}[hbt]
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{4.89cm}p{4cm}p{4.59cm}}
%\hline
\multicolumn{1}{p{4.9cm}}{Input Data} & 
\multicolumn{1}{p{4cm}}{Accuracy} & 
\multicolumn{1}{p{4.6cm}}{Running Time} \\ 
\hline
\multicolumn{1}{p{4.9cm}}{Original data\( \mathbf{x}_{i}\in\mathbb{R}^{784}\)} & 
\multicolumn{1}{p{4cm}}{85.4$\%$} & 
\multicolumn{1}{p{4.6cm}}{\( 1040\) sec. \( \approx 16.6\) min.} \\ 
%\hline
\multicolumn{1}{p{4.9cm}}{Latent Features \( enc\left(\mathbf{x}_{i}\right)\in\mathbb{R}^{8}\)} & 
\multicolumn{1}{p{4cm}}{79.9$\%$} & 
\multicolumn{1}{p{4.6cm}}{1.2 sec.} \\ 
%\hline
\multicolumn{1}{p{4.9cm}}{Latent Features \( enc\left(\mathbf{x}_{i}\right)\in\mathbb{R}^{16}\)} & 
\multicolumn{1}{p{4cm}}{83.6$\%$} & 
\multicolumn{1}{p{4.6cm}}{3.0 sec.} \\ 
%\hline
\end{tabular}
\end{adjustbox}
\caption{the difference in accuracy and running time when applying the kNN algorithm to the original 784 features with a FFA with 8 neurons and with a FFA with 16 neurons for the Fashion MNIST dataset.}\label{tab:run2}
\end{table}
%Table 25.2: 
It is exciting to note that with an FFA with 16 neurons in the middle layer, we reach an accuracy of 83.6$\%$ in just 3 sec. When applying a kNN algorithm to the original features (784), we get an accuracy only 1.8$\%$ higher but with a running time ca. 330 times longer.
\begin{note}
\textbf{Note} Using autoencoders and doing classification with the latent features is a very viable technique to reduce the training time by several order of magnitude while incurring a minor drop in accuracy.
\end{note}
\subsubsection{Curse of dimensionality – a small detour}

Is there any other reason why we want to do dimensionality reduction before doing any classification? Reducing running time is one reason, but another important one plays a significant role when the input dimension is very large, i.e., the datasets that have a very high number of features: the curse of dimensionality. To understand why we need to make a quick detour in the problem of high dimensionality classification and discuss the \textit{curse of dimensionality}. Let us consider the unit cube \(\left[0,1\right]^{d}\) with \( d\) an integer and \( m\) points in it distributed randomly. How big should be the length \( l\) of the smallest hyper-cube to contain at least \( 1\) point? We can easily calculate it as
\begin{equation}
l^{d}\approx\frac{1}{m}\rightarrow l\approx\left(\frac{1}{m}\right)^{1/d}
\end{equation}
We can easily calculate this value of \( l\) for various values of \( d\). Let us suppose that we consider \( m = 1000\) and summarize the results in Table \ref{tab:res1}.

\begin{table}[hbt]
\begin{centering}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{p{3.8cm}p{2.7cm}}
%\hline
\multicolumn{1}{p{3.8cm}}{\centering
d} & 
\multicolumn{1}{p{2.7cm}}{\centering
l} \\ 
\hline
\multicolumn{1}{p{3.8cm}}{\centering
2} & 
\multicolumn{1}{p{2.7cm}}{\centering
0.003} \\ 
%\hline
\multicolumn{1}{p{3.8cm}}{\centering
10} & 
\multicolumn{1}{p{2.7cm}}{\centering
0.50} \\ 
%\hline
\multicolumn{1}{p{3.8cm}}{\centering
100} & 
\multicolumn{1}{p{2.7cm}}{\centering
0.93} \\ 
%\hline
\multicolumn{1}{p{3.8cm}}{\centering
1000} & 
\multicolumn{1}{p{2.7cm}}{\centering
0.99} \\ 
%\hline
\end{tabular}
\end{adjustbox}
\caption{Length \( l\) of the smallest hyper-cube to contain at least \( 1\) point from a population of randomly distributed \( m\) points.}\label{tab:res1}
\end{centering}
\end{table}

%Table 25.3: 
Furthermore, as you can see the data becomes so sparse in high dimensions that you need to consider the entire hyper cube to capture one single observation. When the data becomes so sparse the number of observations you will need to train an algorithm properly becomes much bigger than the size of existing datasets. 
We could look at this differently. Let us consider now a small hypercube of side \( l = 1/10\). How many observations we will find on average in this small portion of the hypercube? This is easy to calculate and is given by
\begin{equation}
\frac{m}{10^{d}}
\end{equation}
You can see that this number is very small for high values of \( d\). For example, if we consider \( d = 100\) is easy to see that we would need more observations than atoms in the universe\footnote{\url{https://www.universetoday.com/36302/atoms-in-the-universe/} } to find at least one observation in that small portion of the hypercube.
\begin{note}
\textbf{Note }Doing dimensionality reduction is a very viable method for reducing dramatically running time while incurring in an only small drop in accuracy. In high dimensionality datasets this becomes fundamental due to the curse of dimensionality.
\end{note}
\subsection{Anomaly Detection}

Autoencoders are often used to perform anomaly detection on the most different datasets. The best way to understand how anomaly detection works with autoencoders is to look at it with a practical example. Let us consider an autoencoder with only three layers with 784 neurons in the first, 64 in the latent feature generation layer, and again 784 neurons in the output layers. We will train it with the MNIST dataset and in particular with the 60000 training portion of it as we have done in the previous sections of the article. Now let us consider the Fashion MNIST dataset. Let us choose an image of a shoe (see Figure \ref{fig:anom1}) from this dataset
\begin{figure}[hbt]
\centering
\includegraphics[width=6.58cm,height=6.56cm]{./images/image11.png}
\caption{one random image from the Zalando MNIST dataset.}\label{fig:anom1}
\end{figure}
%Figure 25.9
and add it to the testing portion of the MNIST dataset. The original testing portion of MNIST has 10000 images. With the shoe we will have a 10001 images dataset. How can we use an autoencoder to find the shoe automatically in those 10001 images? Note that the shoe is an "outlier", an "anomaly" since it is an entirely different image class than hand-written digits. To do that we will take the autoencoder we trained with the 60000 MNIST images and with it we will calculate the reconstruction error for the 10001 test images.


The main idea is that since the autoencoder has only seen hand-written digits images, it will not be able to reconstruct the shoe image. Therefore we expect this image to have the biggest reconstruction error. We can check if that is the case by taking the top 2 reconstruction errors. For this example, we have used the MSE for the reconstruction error. You can check the code of this example at \url{https://adl.toelt.ai}. The shoe has the highest reconstruction error: 0.062. The autoencoder is not able to reconstruct the image as it can be seen from Figure \ref{fig:recon2}.

\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=7.02cm]{./images/image12.png}
\caption{The shoe and the autoencoder's reconstruction trained on the 60000 hand-written images of the MNIST dataset. This image has the biggest RE in the entire 10001 test dataset we built with a value of 0.062.}\label{fig:recon2}
\end{figure}
The second biggest RE is slightly less than one third of that of the shoe: 0.022, indicating that the autoencoder is doing quite a good job in understanding how to reconstruct hand-written digits. You can see the image with the second biggest RE in Figure \ref{fig:recon3}. This image could also be classified as an outlier, as is not completely clear if it is a 4 or an incomplete 9.
\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=7.09cm]{./images/image13.png}
\caption{the image with the second biggest RE in the 10001 test dataset: 0.022.}\label{fig:recon3}
\end{figure}
The readers with most experience may have noticed that we trained our autoencoders on a dataset without any outliers and applied it to a second dataset with outliers. This is not always possible as very often the outliers are not known and are lost in a big dataset. In general, one wants to find outliers in a single big dataset without any information on how many there are or how they look like. Generally speaking, anomaly detection can be done following the main steps below.
\begin{itemize}
\item One train an autoencoder on the entire dataset (or if possible, on a portion of the dataset known \textbf{not} to have any outlier).
\item
For each observation (or input) of the portion of the dataset known to have the wanted outliers one calculates the RE.
\item
One sorts the observations by the RE.
\item
One classifies the observations with the highest RE as outliers. Note that how many observations are outliers will depend on the problem at hand and require an analysis of the results and usually lot of knowledge of the data and the problem.
\end{itemize}
Note that if one train the autoencoder on the entire dataset at disposal, there is an essential assumption: the outliers are a negligible part of the dataset and their presence will not influence (or will influence in an insignificant way) how the autoencoder learns to reconstruct the observations. This is one of the reasons why regularization is so essential. If the autoencoders would learn the identity function, anomaly detection could not be done.
A classic example of anomaly detection is finding fraudulent credit card transactions (the outliers). This case usually presents ca. 0.1$\%$ fraudulent transactions and therefore this would be a case that would allow us to train the autoencoder on the entire dataset. Another is fault detection in industrial environment.
\begin{note}
\textbf{Note} If one train the autoencoder on the entire dataset at disposal, there is an essential assumption: the outliers are a negligible part of the dataset and their presence will not influence (or will influence in an insignificant way) how the autoencoder learns to reconstruct the observations.
\end{note}
\subsubsection{Model Stability – a short note}

Note that doing anomaly detection as described in the previous section seems easy, but those methods are prone to overfitting and give often inconsistent results. This means that training an autoencoder with a different architecture may well give different REs and therefore other outliers. There are several ways of solving this problem, but one of the simplest ways of dealing with instability of results is to train different models and then take the average of the REs. Another often used technique involves taking the maximum of the REs evaluated from several models. 
\begin{note}
\textbf{Note }Anomaly detection done with autoencoders is prone to problems as overfitting and unstable results. It is essential to be aware of these problems and check the results coming from different models to interpret the results correctly.
\end{note}
Note that this section serves to give you some pointers and is not meant to be an exhaustive overview on how to solve this problem.
Like autoencoders ensembles\footnote{ See for example \url{https://saketsathe.net/downloads/autoencode.pdf}.}, more advanced techniques are also used to deal with problems of instable results coming, for example, from small datasets.

\subsection{Denoising autoencoders}

Denoising autoencoders\footnote{ Vincent, P., Larochelle, H. Bengio, Y. Manzagol, P.A.: Extracting and composing robust features with denoising autoencoders. In: Proceedings of the 25th International Conference on Machine Learning, ICML ’08, pp. 1096-1103. ACM, New York, NY USA (2008)} are developed to auto-correct errors (noise) in the input observations. As an example, imagine the hand-written digits we considered before where we added some noise (for example Gaussian noise) in the form of changing randomly the gray values of the pixels. In this case the autoencoders should learn to reconstruct the image without the added noise. As a concrete example, consider the MNIST dataset. We can add to each pixel a random value generated by a normal distribution scaled by a factor (you can check the code at \url{https://adl.toelt.ai} in article 25). We can train an autoencoder using as input the noisy images, and as output the original images. The model should learn to remove the noise, since it is random in nature and have no relationship with the images. 
In Figure \ref{fig:recon5} you can see the results. In the left column you see the noisy images, in the middle the original ones and on the right the de-noised images. It is quite impressive how well it works. Figure \ref{fig:recon5} has been generated by training a FFA autoencoder with 3 layers and 32 neurons in the middle layer.
\begin{figure}[hbt]
\centering
\includegraphics[width=12.16cm,height=11.92cm]{./images/image14.png}
\caption{Results of a denoising FFA autoencoder with 3 layers and 32 neurons in the middle layer. The noise has been generating adding a real number between 0 and 1 taken from a normal distribution. For details see the code at \url{https://adl.toelt.ai}.}\label{fig:recon5}
\end{figure}


\section{Beyond FFA – autoencoders with convolutional layers}

In this article we have described autoencoders with a feed-forward architecture. There is no rule and autoencoders with convolutional layers works as well, and often (especially when dealing with images) are much more efficient. For example, in Figure \ref{fig:recon6} you can see a comparison of the results of a FAA (with architecture (784,32,784)) and of a Convolutional Autoencoder (CA) (with architecture ((28x28), (26x26x64), (24x24,32), (26x26x64), (28x28); keep in mind the layers are convolutions, so the first two numbers indicate the tensor dimensions and the third the number of kernels, that in this example had a size of 3x3). The two autoencoders have been trained with the same parameters (epochs, mini-batch size, etc.). You can see how a CA gives better results than a FAA, since we are dealing with images. To be fair, note that the feature generating layer is only marginally smaller than the input layer in this example. The purpose of this example is only to show you how also convolutional autoencoders are a viable solution that works very well in many practical applications.
\begin{figure}[hbt]
\centering
\includegraphics[width=12.61cm,height=7.3cm]{./images/image15.png}
\caption{Comparison of the results of a FAA (with architecture (784,32,784)) and of a Convolutional Autoencoder (CA) (with architecture ((28x28), (26x26x64), (24x24,32), (26x26x64), (28x28); keep in mind the layers are convolutions, so the first two numbers indicate the tensor dimensions and the third the number of kernels, with kernel size 3x3). The two autoencoders have been trained with the same parameters. You can check the code at \url{https://adl.toelt.ai}.}\label{fig:recon6}
\end{figure}

Another important aspect is that the feature generating layer could be a convolutional layer but could also be a dense one. There is not fix rule and testing is required to find the best architecture for your problem and how you want to model your latent features: as a tensor (multi-dimensional array) or as a one-dimensional array of real numbers.

\section{Code Examples}

On \url{https://adl.toelt.ai} you will find examples of autoencoders, anomaly detection with autoencoders and denoising with autoencoders as described in this article.









<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week13.do.txt --pygments_html_style=perldoc --html_style=solarized3 --html_links_in_new_window --html_output=week13-solarized --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>
<link href="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<link href="https://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
.alert-text-small   { font-size: 80%;  }
.alert-text-large   { font-size: 130%; }
.alert-text-normal  { font-size: 90%;  }
.alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:1px solid #93a1a1;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  -moz-border-radius: 4px;
  color: #555;
  background-color: #eee8d5;
  background-position: 10px 5px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 55px;
  width: 75%;
 }
.alert-block {padding-top:14px; padding-bottom:14px}
.alert-block > p, .alert-block > ul {margin-bottom:1em}
.alert li {margin-top: 1em}
.alert-block p+p {margin-top:5px}
.alert-notice { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_notice.png); }
.alert-summary  { background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_summary.png); }
.alert-warning { background-image: url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_warning.png); }
.alert-question {background-image:url(https://cdn.rawgit.com/doconce/doconce/master/bundled/html_images/small_yellow_question.png); }
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for the week April 21-25, 2025',
               2,
               None,
               'plans-for-the-week-april-21-25-2025'),
              ('Summary of Variational Autoencoders (VAEs)',
               2,
               None,
               'summary-of-variational-autoencoders-vaes'),
              ('Boltzmann machines and energy-based models and contrastive '
               'optimization',
               2,
               None,
               'boltzmann-machines-and-energy-based-models-and-contrastive-optimization'),
              ('Energy models', 2, None, 'energy-models'),
              ('Probability model', 2, None, 'probability-model'),
              ('Marginal and conditional probabilities',
               2,
               None,
               'marginal-and-conditional-probabilities'),
              ('Partition function', 2, None, 'partition-function'),
              ('Optimization problem', 2, None, 'optimization-problem'),
              ('Further simplifications', 2, None, 'further-simplifications'),
              ('Optimizing the logarithm instead',
               2,
               None,
               'optimizing-the-logarithm-instead'),
              ('Expression for the gradients',
               2,
               None,
               'expression-for-the-gradients'),
              ('Contrastive optimization', 2, None, 'contrastive-optimization'),
              ('The derivative of the partition function',
               2,
               None,
               'the-derivative-of-the-partition-function'),
              ('Explicit expression for the derivative',
               2,
               None,
               'explicit-expression-for-the-derivative'),
              ('Final expression', 2, None, 'final-expression'),
              ('Kullback-Leibler divergence',
               2,
               None,
               'kullback-leibler-divergence'),
              ('Jensen-Shannon divergence',
               2,
               None,
               'jensen-shannon-divergence'),
              ('Generative model,  basic overview (Borrowed from Rashcka et '
               'al)',
               2,
               None,
               'generative-model-basic-overview-borrowed-from-rashcka-et-al'),
              ('Reminder on VAEs', 2, None, 'reminder-on-vaes'),
              ('Evidence Lower Bound', 2, None, 'evidence-lower-bound'),
              ('ELBO equations', 2, None, 'elbo-equations'),
              ('Introducing the encoder function',
               2,
               None,
               'introducing-the-encoder-function'),
              ('The derivation from last week',
               2,
               None,
               'the-derivation-from-last-week'),
              ('Analysis', 2, None, 'analysis'),
              ('The VAE', 2, None, 'the-vae'),
              ('Dissecting the equations', 2, None, 'dissecting-the-equations'),
              ('Bottlenecking distribution',
               2,
               None,
               'bottlenecking-distribution'),
              ('Decoder and encoder', 2, None, 'decoder-and-encoder'),
              ('Defining feature of VAEs', 2, None, 'defining-feature-of-vaes'),
              ('Analytical evaluation', 2, None, 'analytical-evaluation'),
              ('Reparameterization trick', 2, None, 'reparameterization-trick'),
              ('Actual implementation', 2, None, 'actual-implementation'),
              ('Interpretation', 2, None, 'interpretation'),
              ('Deterministic function', 2, None, 'deterministic-function'),
              ('After training', 2, None, 'after-training'),
              ('Setting up SGD', 2, None, 'setting-up-sgd'),
              ('More on the SGD', 2, None, 'more-on-the-sgd'),
              ('Simplification', 2, None, 'simplification'),
              ('Terms to compute', 2, None, 'terms-to-compute'),
              ('Computing the gradients', 2, None, 'computing-the-gradients'),
              ('Code examples using Keras',
               2,
               None,
               'code-examples-using-keras'),
              ('Code in PyTorch for VAEs', 2, None, 'code-in-pytorch-for-vaes'),
              ('Diffusion models, basics', 2, None, 'diffusion-models-basics'),
              ('Problems with probabilistic models',
               2,
               None,
               'problems-with-probabilistic-models'),
              ('Diffusion models', 2, None, 'diffusion-models'),
              ('Original idea', 2, None, 'original-idea'),
              ('Diffusion learning', 2, None, 'diffusion-learning'),
              ('Code examples using Keras',
               2,
               None,
               'code-examples-using-keras'),
              ('Code in PyTorch for VAEs', 2, None, 'code-in-pytorch-for-vaes'),
              ('Diffusion models, basics', 2, None, 'diffusion-models-basics'),
              ('Problems with probabilistic models',
               2,
               None,
               'problems-with-probabilistic-models'),
              ('Diffusion models', 2, None, 'diffusion-models'),
              ('Original idea', 2, None, 'original-idea'),
              ('Diffusion learning', 2, None, 'diffusion-learning'),
              ('Mathematics of diffusion models',
               2,
               None,
               'mathematics-of-diffusion-models'),
              ('Chains of VAEs', 2, None, 'chains-of-vaes'),
              ('Mathematical representation',
               2,
               None,
               'mathematical-representation'),
              ('Back to the marginal probability',
               2,
               None,
               'back-to-the-marginal-probability'),
              ('Diffusion models for hierarchical VAE, from '
               'URL:"https://arxiv.org/abs/2208.11970"',
               2,
               None,
               'diffusion-models-for-hierarchical-vae-from-url-https-arxiv-org-abs-2208-11970'),
              ('Equation for the Markovian hierarchical VAE',
               2,
               None,
               'equation-for-the-markovian-hierarchical-vae'),
              ('Variational Diffusion Models',
               2,
               None,
               'variational-diffusion-models'),
              ('Second assumption', 2, None, 'second-assumption'),
              ('Parameterizing Gaussian encoder',
               2,
               None,
               'parameterizing-gaussian-encoder'),
              ('Encoder transitions', 2, None, 'encoder-transitions'),
              ('Third assumption', 2, None, 'third-assumption'),
              ('Noisification', 2, None, 'noisification'),
              ('Diffusion models, from URL:"https://arxiv.org/abs/2208.11970"',
               2,
               None,
               'diffusion-models-from-url-https-arxiv-org-abs-2208-11970'),
              ('Gaussian modeling', 2, None, 'gaussian-modeling'),
              ('Optimizing the variational diffusion model',
               2,
               None,
               'optimizing-the-variational-diffusion-model'),
              ('Continues', 2, None, 'continues'),
              ('Interpretations', 2, None, 'interpretations'),
              ('The last term', 2, None, 'the-last-term'),
              ('Diffusion models, part 2, from '
               'URL:"https://arxiv.org/abs/2208.11970"',
               2,
               None,
               'diffusion-models-part-2-from-url-https-arxiv-org-abs-2208-11970'),
              ('Optimization cost', 2, None, 'optimization-cost'),
              ('More details', 2, None, 'more-details')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- ------------------- main content ---------------------- -->
<center>
<h1>Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> 
</center>
<!-- institution -->
<center>
<b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<br>
<center>
<h4>April 24, 2025</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="plans-for-the-week-april-21-25-2025">Plans for the week April 21-25, 2025  </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Deep generative models</b>
<p>
<ol>
<li> Discussion of project 2</li>
<li> Variational Autoencoders (VAE), Mathematics and codes, continuation from last week</li>
<li> Reading recommendation:
<ol type="a"></li>
 <li> Goodfellow et al chapter 20.10-20-14</li>
 <li> Calvin Luo <a href="https://calvinyluo.com/2022/08/26/diffusion-tutorial.html" target="_blank"><tt>https://calvinyluo.com/2022/08/26/diffusion-tutorial.html</tt></a></li>
 <li> An Introduction to Variational Autoencoders, by Kingma and Welling, see <a href="https://arxiv.org/abs/1906.02691" target="_blank"><tt>https://arxiv.org/abs/1906.02691</tt></a>
<!-- o <a href="https://youtu.be/rw-NBN293o4" target="_blank">Video of lecture</a> -->
<!-- o <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesApril16.pdf" target="_blank">Whiteboard notes</a> --></li>
</ol>
</ol>
</div>


<!-- todo: add about Langevin sampling, see <a href="https://www.lyndonduong.com/sgmcmc/" target="_blank"><tt>https://www.lyndonduong.com/sgmcmc/</tt></a> -->
<!-- code for VAEs applied to MNIST and CIFAR perhaps -->

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="summary-of-variational-autoencoders-vaes">Summary of Variational Autoencoders (VAEs) </h2>

<p>In our short summary of VAes, we will also remind you about the
mathematics of Boltzmann machines and the Kullback-Leibler divergence,
leading to various  ways to optimize the probability
distributions, namely what is called 
</p>
<ul>
<li> Contrastive optimization</li>
</ul>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="boltzmann-machines-and-energy-based-models-and-contrastive-optimization">Boltzmann machines and energy-based models and contrastive optimization </h2>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="energy-models">Energy models </h2>

<p>For Boltzmann machines  we defined a domain \( \boldsymbol{X} \) of stochastic variables \( \boldsymbol{X}= \{x_0,x_1, \dots , x_{n-1}\} \) with a pertinent probability distribution</p>
$$
p(\boldsymbol{X})=\prod_{x_i\in \boldsymbol{X}}p(x_i),
$$

<p>where we have assumed that the random varaibles \( x_i \) are all independent and identically distributed (iid).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="probability-model">Probability model </h2>

<p>We defined a probability</p>
$$
p(x_i,h_j;\boldsymbol{\Theta}) = \frac{f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$

<p>where \( f(x_i,h_j;\boldsymbol{\Theta}) \) is a function which we assume is larger or
equal than zero and obeys all properties required for a probability
distribution and \( Z(\boldsymbol{\Theta}) \) is a normalization constant. Inspired by
statistical mechanics, we call it often for the partition function.
It is defined as (assuming that we have discrete probability distributions)
</p>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}).
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="marginal-and-conditional-probabilities">Marginal and conditional probabilities </h2>

<p>We can in turn define the marginal probabilities</p>
$$
p(x_i;\boldsymbol{\Theta}) = \frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$

<p>and </p>
$$
p(h_i;\boldsymbol{\Theta}) = \frac{\sum_{x_i\in \boldsymbol{X}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="partition-function">Partition function  </h2>

<p><b>Note the change to a vector notation</b>. A variable like \( \boldsymbol{x} \)
represents now a specific <b>configuration</b>. We can generate an infinity
of such configurations. The final partition function is then the sum
over all such possible configurations, that is
</p>

$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$

<p>changes to</p>
$$
Z(\boldsymbol{\Theta})=\sum_{\boldsymbol{x}}\sum_{\boldsymbol{h}} f(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}).
$$

<p>If we have a binary set of variable \( x_i \) and \( h_j \) and \( M \) values of \( x_i \) and \( N \) values of \( h_j \) we have in total \( 2^M \) and \( 2^N \) possible \( \boldsymbol{x} \) and \( \boldsymbol{h} \) configurations, respectively.</p>

<p>We see that even for the modest binary case, we can easily approach a
number of configuration which is not possible to deal with.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="optimization-problem">Optimization problem </h2>

<p>At the end, we are not interested in the probabilities of the hidden variables. The probability we thus want to optimize is </p>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}\left(\frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}\right),
$$

<p>which we rewrite as</p>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}\left(\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})\right).
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="further-simplifications">Further simplifications </h2>

<p>We simplify further by rewriting it as</p>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}),
$$

<p>where we used \( p(x_i;\boldsymbol{\Theta}) = \sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta}) \).
The optimization problem is then
</p>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}p(\boldsymbol{X};\boldsymbol{\Theta}).
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="optimizing-the-logarithm-instead">Optimizing the logarithm instead </h2>

<p>Computing the derivatives with respect to the parameters \( \boldsymbol{\Theta} \) is
easier (and equivalent) with taking the logarithm of the
probability. We will thus optimize
</p>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}\log{p(\boldsymbol{X};\boldsymbol{\Theta})},
$$

<p>which leads to</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=0.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="expression-for-the-gradients">Expression for the gradients </h2>

<p>This leads to the following equation</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=\nabla_{\boldsymbol{\Theta}}\left(\sum_{x_i\in \boldsymbol{X}}\log{f(x_i;\boldsymbol{\Theta})}\right)-\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=0.
$$

<p>The first term is called the positive phase and we assume that we have a model for the function \( f \) from which we can sample values. Below we will develop an explicit model for this.
The second term is called the negative phase and is the one which leads to more difficulties.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="contrastive-optimization">Contrastive optimization </h2>
<p>The evaluation of these two terms leads to what in the literature is called contrastive optimization.</p>

<p>If we optimize the negative <b>log</b> of the PDF, the aboves phases simply change sign.</p>

<p>For a further discussion of energy-based models, see the notes by Philip Lippe at <a href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html" target="_blank"><tt>https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html</tt></a></p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="the-derivative-of-the-partition-function">The derivative of the partition function </h2>

<p>The partition function, defined above as</p>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$

<p>is in general the most problematic term. In principle both \( x \) and \( h \) can span large degrees of freedom, if not even infinitely many ones, and computing the partition function itself is often not desirable or even feasible. The above derivative of the partition function can however be written in terms of an expectation value which is in turn evaluated  using Monte Carlo sampling and the theory of Markov chains, popularly shortened to MCMC (or just MC$^2$).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="explicit-expression-for-the-derivative">Explicit expression for the derivative </h2>
<p>We can rewrite</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}}Z(\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$

<p>which reads in more detail</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}} \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta})   }{Z(\boldsymbol{\Theta})}.
$$

<p>We can rewrite the function \( f \) (we have assumed that is larger or
equal than zero) as \( f=\exp{\log{f}} \). We can then reqrite the last
equation as
</p>

$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}} \nabla_{\boldsymbol{\Theta}}\exp{\log{f(x_i;\boldsymbol{\Theta})}}   }{Z(\boldsymbol{\Theta})}.
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="final-expression">Final expression </h2>

<p>Taking the derivative gives us</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})}   }{Z(\boldsymbol{\Theta})}, 
$$

<p>which is the expectation value of \( \log{f} \)</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\sum_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})},
$$

<p>that is</p>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\mathbb{E}(\log{f(x_i;\boldsymbol{\Theta})}).
$$

<p>This quantity is evaluated using Monte Carlo sampling, with Gibbs
sampling as the standard sampling rule.  
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="kullback-leibler-divergence">Kullback-Leibler divergence </h2>

<p>Before we continue, we need to remind ourselves about the
Kullback-Leibler divergence introduced earlier. This will also allow
us to introduce another measure used in connection with the training
of Generative Adversarial Networks, the so-called Jensen-Shannon divergence..
These metrics are useful for quantifying the similarity between two probability distributions.
</p>

<p>The Kullback&#8211;Leibler (KL) divergence, labeled \( D_{KL} \),   measures how one probability distribution \( p \) diverges from a second expected probability distribution \( q \),
that is
</p>
$$
D_{KL}(p \| q) = \int_x p(x) \log \frac{p(x)}{q(x)} dx.
$$

<p>The KL-divegrnece \( D_{KL} \) achieves the minimum zero when \( p(x) == q(x) \) everywhere.</p>

<p>Note that the KL divergence is asymmetric. In cases where \( p(x) \) is
close to zero, but \( q(x) \) is significantly non-zero, the \( q \)'s effect
is disregarded. It could cause buggy results when we just want to
measure the similarity between two equally important distributions.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="jensen-shannon-divergence">Jensen-Shannon divergence </h2>

<p>The Jensen&#8211;Shannon (JS) divergence is another measure of similarity between
two probability distributions, bounded by \( [0, 1] \). The JS-divergence is
symmetric and more smooth than the KL-divergence.
It is defined as
</p>
$$
D_{JS}(p \| q) = \frac{1}{2} D_{KL}(p \| \frac{p + q}{2}) + \frac{1}{2} D_{KL}(q \| \frac{p + q}{2})
$$

<p>Many practitioners believe that one reason behind GANs' big success is
switching the loss function from asymmetric KL-divergence in
traditional maximum-likelihood approach to symmetric JS-divergence.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="generative-model-basic-overview-borrowed-from-rashcka-et-al">Generative model,  basic overview (Borrowed from Rashcka et al) </h2>

<br/><br/>
<center>
<p><img src="figures/figure1.png" width="900" align="bottom"></p>
</center>
<br/><br/>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="reminder-on-vaes">Reminder on VAEs </h2>

<p>Mathematically, we can imagine the latent variables and the data we
observe as modeled by a joint distribution \( p(\boldsymbol{x}, \boldsymbol{h};\boldsymbol{\Theta}) \).  Recall one
approach of generative modeling, termed likelihood-based, is to
learn a model to maximize the likelihood \( p(\boldsymbol{x};\boldsymbol{\Theta}) \) of all observed
\( \boldsymbol{x} \).  There are two ways we can manipulate this joint distribution
to recover the likelihood of purely our observed data \( p(\boldsymbol{x};\boldsymbol{\Theta}) \); we can
explicitly marginalize
out the latent variable \( \boldsymbol{h} \)
</p>
$$
\begin{equation*}
p(\boldsymbol{x}) = \int p(\boldsymbol{x}, \boldsymbol{h})d\boldsymbol{h}
\end{equation*}
$$

<p>or, we could also appeal to the chain rule of probability</p>
$$
\begin{equation*}
p(\boldsymbol{x}) = \frac{p(\boldsymbol{x}, \boldsymbol{h})}{p(\boldsymbol{h}|\boldsymbol{x})}
\end{equation*}
$$

<p>We suppress here the dependence	on the optimization parameters \( \boldsymbol{\Theta} \).</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="evidence-lower-bound">Evidence Lower Bound </h2>
<p>Directly computing and maximizing the likelihood \( p(\boldsymbol{x}) \) is
difficult because it either involves integrating out all latent
variables \( \boldsymbol{h} \), which is intractable for
complex models, or it involves having access to a ground truth latent
encoder \( p(\boldsymbol{h}|\boldsymbol{x}) \).
</p>

<p>Using the last  two equations, we can derive a term called the Evidence Lower Bound (ELBO), which as its name suggests, is a lower
  bound of the evidence.  The evidence is quantified in this case as
the log likelihood of the observed data.  Then, maximizing the ELBO
becomes a proxy objective with which to optimize a latent variable
model; in the best case, when the ELBO is powerfully parameterized and
perfectly optimized, it becomes exactly equivalent to the evidence.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="elbo-equations">ELBO equations </h2>
<p>Formally, the equation of the ELBO is</p>
$$
\begin{equation*}
\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]
\end{equation*}
$$

<p>To make the relationship with the evidence explicit, we can mathematically write:</p>
$$
\begin{equation*}
\log p(\boldsymbol{x}) \geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]
\end{equation*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="introducing-the-encoder-function">Introducing the encoder function </h2>

<p>Here, \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) is a flexible approximate
variational distribution with parameters \( \boldsymbol{\phi} \) that we seek to
optimize.  Intuitively, it can be thought of as a parameterizable
model that is learned to estimate the true distribution over latent
variables for given observations \( \boldsymbol{x} \); in other words, it seeks to
approximate true posterior \( p(\boldsymbol{h}|\boldsymbol{x}) \).  As we saw last week when we
explored Variational Autoencoders, as we increase the lower bound
by tuning the parameters \( \boldsymbol{\phi} \) to maximize the ELBO, we gain
access to components that can be used to model the true data
distribution and sample from it, thus learning a generative model.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="the-derivation-from-last-week">The derivation from last week </h2>

<p>To better understand the relationship between the evidence and the ELBO, let us remind ourselves about the derivations from our previous lecture, this time using</p>

$$
\begin{align*}
\log p(\boldsymbol{x}) & = \log p(\boldsymbol{x}) \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})d\boldsymbol{h} && \text{(Multiply by $1 = \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})d\boldsymbol{h}$)}\\
          & = \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})(\log p(\boldsymbol{x}))d\boldsymbol{h} && \text{(Bring evidence into integral)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p(\boldsymbol{x})\right] && \text{(Definition of Expectation)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{p(\boldsymbol{h}|\boldsymbol{x})}\right]&& \\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{p(\boldsymbol{h}|\boldsymbol{x})q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]&& \text{(Multiply by $1 = \frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}$)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right] + \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{p(\boldsymbol{h}|\boldsymbol{x})}\right] && \text{(Split the Expectation)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right] +
	  D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h}|\boldsymbol{x}))  && \text{(Definition of KL Divergence)}\\
          & \geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]  && \text{(KL Divergence always $\geq 0$)}
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="analysis">Analysis </h2>

<p>From this derivation, we clearly observe from the last equation
that the evidence is equal to the ELBO plus the KL Divergence between
the approximate posterior \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) and the true
posterior \( p(\boldsymbol{h}|\boldsymbol{x}) \).  Understanding this term is the
key to understanding not only the relationship between the ELBO and
the evidence, but also the reason why optimizing the ELBO is an
appropriate objective at all.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="the-vae">The VAE </h2>

<p>In the default formulation of the VAE by Kingma and Welling (2015), we directly maximize the ELBO.  This
approach is \textit{variational}, because we optimize for the best
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) amongst a family of potential posterior
distributions parameterized by \( \boldsymbol{\phi} \).  It is called an
\textit{autoencoder} because it is reminiscent of a traditional
autoencoder model, where input data is trained to predict itself after
undergoing an intermediate bottlenecking representation step.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="dissecting-the-equations">Dissecting the equations </h2>
<p>To make
this connection explicit, let us dissect the ELBO term further:
</p>

$$
\begin{align*}
{\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}
&= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})p(\boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}         && {\text{(Chain Rule of Probability)}}\\
&= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right] + \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}         && {\text{(Split the Expectation)}}\\
&= \underbrace{{\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right]}}_\text{reconstruction term} - \underbrace{{D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\vert\vert{p(\boldsymbol{h}))}}_\text{prior matching term} && {\text{(Definition of KL Divergence)}}
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="bottlenecking-distribution">Bottlenecking distribution </h2>

<p>In this case, we learn an intermediate bottlenecking distribution
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) that can be treated as
an \textit{encoder}; it transforms inputs into a distribution over
possible latents.  Simultaneously, we learn a deterministic function
\( p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}) \) to convert a given latent vector
\( \boldsymbol{h} \) into an observation \( \boldsymbol{x} \), which can be interpreted as
a \textit{decoder}.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="decoder-and-encoder">Decoder and encoder </h2>
<p>The two terms in the last equation each have intuitive descriptions: the first
term measures the reconstruction likelihood of the decoder from our
variational distribution; this ensures that the learned distribution
is modeling effective latents that the original data can be
regenerated from.  The second term measures how similar the learned
variational distribution is to a prior belief held over latent
variables.  Minimizing this term encourages the encoder to actually
learn a distribution rather than collapse into a Dirac delta function.
Maximizing the ELBO is thus equivalent to maximizing its first term
and minimizing its second term.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="defining-feature-of-vaes">Defining feature of VAEs </h2>

<p>A defining feature of the VAE is how the ELBO is optimized jointly over parameters \( \boldsymbol{\phi} \) and \( \boldsymbol{\theta} \).  The encoder of the VAE is commonly chosen to model a multivariate Gaussian with diagonal covariance, and the prior is often selected to be a standard multivariate Gaussian: </p>
$$
\begin{align*}
    q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) &= N(\boldsymbol{h}; \boldsymbol{\mu}_{\boldsymbol{\phi}}(\boldsymbol{x}), \boldsymbol{\sigma}_{\boldsymbol{\phi}}^2(\boldsymbol{x})\textbf{I})\\
    p(\boldsymbol{h}) &= N(\boldsymbol{h}; \boldsymbol{0}, \textbf{I})
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="analytical-evaluation">Analytical evaluation </h2>

<p>Then, the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can be approximated using a Monte Carlo estimate.  Our objective can then be rewritten as:</p>
$$
\begin{align*}
  \mathrm{argmax}_{\boldsymbol{\phi}, \boldsymbol{\theta}} \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right] - D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h})) \approx \mathrm{argmax}_{\boldsymbol{\phi}, \boldsymbol{\theta}} \sum_{l=1}^{L}\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}^{(l)}) - D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h}))
\end{align*}
$$

<p>where latents \( \{\boldsymbol{h}^{(l)}\}_{l=1}^L \) are sampled from \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \), for every observation \( \boldsymbol{x} \) in the dataset.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="reparameterization-trick">Reparameterization trick </h2>

<p>However, a problem arises in this default setup: each \( \boldsymbol{h}^{(l)} \)
that our loss is computed on is generated by a stochastic sampling
procedure, which is generally non-differentiable.  Fortunately, this
can be addressed via the \textit{reparameterization trick} when
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) is designed to model certain
distributions, including the multivariate Gaussian.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="actual-implementation">Actual implementation </h2>

<p>The reparameterization trick rewrites a random variable as a
deterministic function of a noise variable; this allows for the
optimization of the non-stochastic terms through gradient descent.
For example, samples from a normal distribution
\( x \sim N(x;\mu, \sigma^2) \) with arbitrary mean \( \mu \) and
variance \( \sigma^2 \) can be rewritten as
</p>

$$
\begin{align*}
    x &= \mu + \sigma\epsilon \quad \text{with } \epsilon \sim N(\epsilon; 0, \boldsymbol{I})
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="interpretation">Interpretation </h2>
<p>An arbitrary Gaussian distributions can be interpreted as
standard Gaussians (of which \( \epsilon \) is a sample) that have their
mean shifted from zero to the target mean \( \mu \) by addition, and their
variance stretched by the target variance \( \sigma^2 \).  Therefore, by
the reparameterization trick, sampling from an arbitrary Gaussian
distribution can be performed by sampling from a standard Gaussian,
scaling the result by the target standard deviation, and shifting it
by the target mean.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="deterministic-function">Deterministic function  </h2>

<p>In a VAE, each \( \boldsymbol{h} \) is thus computed as a deterministic function of input \( \boldsymbol{x} \) and auxiliary noise variable \( \boldsymbol{\epsilon} \):</p>
$$
\begin{align*}
    \boldsymbol{h} &= \boldsymbol{\mu}_{\boldsymbol{\phi}}(\boldsymbol{x}) + \boldsymbol{\sigma}_{\boldsymbol{\phi}}(\boldsymbol{x})\odot\boldsymbol{\epsilon} \quad \text{with } \boldsymbol{\epsilon} \sim N(\boldsymbol{\epsilon};\boldsymbol{0}, \textbf{I})
\end{align*}
$$

<p>where \( \odot \) represents an element-wise product.  Under this
reparameterized version of \( \boldsymbol{h} \), gradients can then be computed
with respect to \( \boldsymbol{\phi} \) as desired, to optimize
\( \boldsymbol{\mu}_{\boldsymbol{\phi}} \) and \( \boldsymbol{\sigma}_{\boldsymbol{\phi}} \).  The VAE
therefore utilizes the reparameterization trick and Monte Carlo
estimates to optimize the ELBO jointly over \( \boldsymbol{\phi} \) and
\( \boldsymbol{\theta} \).
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="after-training">After training </h2>

<p>After training a VAE, generating new data can be performed by sampling
directly from the latent space \( p(\boldsymbol{h}) \) and then running it through
the decoder.  Variational Autoencoders are particularly interesting
when the dimensionality of \( \boldsymbol{h} \) is less than that of input
\( \boldsymbol{x} \), as we might then be learning compact, useful
representations.  Furthermore, when a semantically meaningful latent
space is learned, latent vectors can be edited before being passed to
the decoder to more precisely control the data generated.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="setting-up-sgd">Setting up SGD </h2>
<p>So how can we perform stochastic gradient descent?</p>

<p>First we need to be a bit more specific about the form that \( Q(\boldsymbol{h}|\boldsymbol{x}) \)
will take.  The usual choice is to say that
\( Q(\boldsymbol{h}|\boldsymbol{x})=\mathcal{N}(\boldsymbol{h}|\mu(\boldsymbol{x};\vartheta),\Sigma(;\vartheta)) \), where
\( \mu \) and \( \Sigma \) are arbitrary deterministic functions with
parameters \( \vartheta \) that can be learned from data (we will omit
\( \vartheta \) in later equations).  In practice, \( \mu \) and \( \Sigma \) are
again implemented via neural networks, and \( \Sigma \) is constrained to
be a diagonal matrix.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="more-on-the-sgd">More on the SGD </h2>

<p>The name variational &quot;autoencoder&quot; comes from
the fact that \( \mu \) and \( \Sigma \) are &quot;encoding&quot; \( \boldsymbol{x} \) into the latent
space \( \boldsymbol{h} \).  The advantages of this choice are computational, as they
make it clear how to compute the right hand side.  The last
term---\( \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h})\right] \)---is now a KL-divergence
between two multivariate Gaussian distributions, which can be computed
in closed form as:
</p>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu_0,\Sigma_0) \| \mathcal{N}(\mu_1,\Sigma_1)] = \hspace{20em}\\
  \hspace{5em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma_1^{-1} \Sigma_0 \right) + \left( \mu_1 - \mu_0\right)^\top \Sigma_1^{-1} ( \mu_1 - \mu_0 ) - k + \log \left( \frac{ \det \Sigma_1 }{ \det \Sigma_0  } \right)  \right)
\end{array}
$$

<p>where \( k \) is the dimensionality of the distribution.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="simplification">Simplification </h2>
<p>In our case, this simplifies to:</p>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu(X),\Sigma(X)) \| \mathcal{N}(0,I)] = \hspace{20em}\\
\hspace{6em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma(X) \right) + \left( \mu(X)\right)^\top ( \mu(X) ) - k - \log\det\left(  \Sigma(X)  \right)  \right).
\end{array}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="terms-to-compute">Terms to compute </h2>

<p>The first term on the right hand side is a bit more tricky.
We could use sampling to estimate \( E_{z\sim Q}\left[\log P(X|z)  \right] \), but getting a good estimate would require passing many samples of \( z \) through \( f \), which would be expensive.
Hence, as is standard in stochastic gradient descent, we take one sample of \( z \) and treat \( \log P(X|z) \) for that \( z \) as an approximation of \( E_{z\sim Q}\left[\log P(X|z)  \right] \).
After all, we are already doing stochastic gradient descent over different values of \( X \) sampled from a dataset \( D \).
The full equation we want to optimize is:
</p>

$$
\begin{array}{c}
    E_{X\sim D}\left[\log P(X) - \mathcal{D}\left[Q(z|X)\|P(z|X)\right]\right]=\hspace{16em}\\
\hspace{10em}E_{X\sim D}\left[E_{z\sim Q}\left[\log P(X|z)  \right] - \mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
\end{array}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="computing-the-gradients">Computing the gradients </h2>

<p>If we take the gradient of this equation, the gradient symbol can be moved into the expectations.
Therefore, we can sample a single value of \( X \) and a single value of \( z \) from the distribution \( Q(z|X) \), and compute the gradient of:
</p>
$$
\begin{equation}
 \log P(X|z)-\mathcal{D}\left[Q(z|X)\|P(z)\right].
\label{_auto1}
\end{equation}
$$

<p>We can then average the gradient of this function over arbitrarily many samples of \( X \) and \( z \), and the result converges to the gradient.</p>

<p>There is, however, a significant problem
\( E_{z\sim Q}\left[\log P(X|z)  \right] \) depends not just on the parameters of \( P \), but also on the parameters of \( Q \).
</p>

<p>In order to make VAEs work, it is essential to drive \( Q \) to produce codes for \( X \) that \( P \) can reliably decode.  </p>
$$
 E_{X\sim D}\left[E_{\epsilon\sim\mathcal{N}(0,I)}[\log P(X|z=\mu(X)+\Sigma^{1/2}(X)*\epsilon)]-\mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="code-examples-using-keras">Code examples using Keras </h2>

<p>Code taken from  <a href="https://keras.io/examples/generative/vae/" target="_blank"><tt>https://keras.io/examples/generative/vae/</tt></a></p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">Title: Variational AutoEncoder</span>
<span style="color: #CD5555">Author: [fchollet](https://twitter.com/fchollet)</span>
<span style="color: #CD5555">Date created: 2020/05/03</span>
<span style="color: #CD5555">Last modified: 2023/11/22</span>
<span style="color: #CD5555">Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.</span>
<span style="color: #CD5555">Accelerator: GPU</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Setup</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

os.environ[<span style="color: #CD5555">&quot;KERAS_BACKEND&quot;</span>] = <span style="color: #CD5555">&quot;tensorflow&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">tensorflow</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">tf</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">keras</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">keras</span> <span style="color: #8B008B; font-weight: bold">import</span> layers

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Create a sampling layer</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Sampling</span>(layers.Layer):
    <span style="color: #CD5555">&quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;</span>

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">call</span>(<span style="color: #658b00">self</span>, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[<span style="color: #B452CD">0</span>]
        dim = tf.shape(z_mean)[<span style="color: #B452CD">1</span>]
        epsilon = tf.random.normal(shape=(batch, dim))
        <span style="color: #8B008B; font-weight: bold">return</span> z_mean + tf.exp(<span style="color: #B452CD">0.5</span> * z_log_var) * epsilon


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the encoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_dim = <span style="color: #B452CD">2</span>

encoder_inputs = keras.Input(shape=(<span style="color: #B452CD">28</span>, <span style="color: #B452CD">28</span>, <span style="color: #B452CD">1</span>))
x = layers.Conv2D(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(encoder_inputs)
x = layers.Conv2D(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Flatten()(x)
x = layers.Dense(<span style="color: #B452CD">16</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(x)
z_mean = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_mean&quot;</span>)(x)
z_log_var = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_log_var&quot;</span>)(x)
z = Sampling()([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=<span style="color: #CD5555">&quot;encoder&quot;</span>)
encoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the decoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(<span style="color: #B452CD">7</span> * <span style="color: #B452CD">7</span> * <span style="color: #B452CD">64</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(latent_inputs)
x = layers.Reshape((<span style="color: #B452CD">7</span>, <span style="color: #B452CD">7</span>, <span style="color: #B452CD">64</span>))(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder_outputs = layers.Conv2DTranspose(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;sigmoid&quot;</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name=<span style="color: #CD5555">&quot;decoder&quot;</span>)
decoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Define the VAE as a `Model` with a custom `train_step`</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(keras.Model):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder, **kwargs):
        <span style="color: #658b00">super</span>().<span style="color: #008b45">__init__</span>(**kwargs)
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder
        <span style="color: #658b00">self</span>.total_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;total_loss&quot;</span>)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker = keras.metrics.Mean(
            name=<span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>
        )
        <span style="color: #658b00">self</span>.kl_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;kl_loss&quot;</span>)

    <span style="color: #707a7c">@property</span>
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">metrics</span>(<span style="color: #658b00">self</span>):
        <span style="color: #8B008B; font-weight: bold">return</span> [
            <span style="color: #658b00">self</span>.total_loss_tracker,
            <span style="color: #658b00">self</span>.reconstruction_loss_tracker,
            <span style="color: #658b00">self</span>.kl_loss_tracker,
        ]

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">train_step</span>(<span style="color: #658b00">self</span>, data):
        <span style="color: #8B008B; font-weight: bold">with</span> tf.GradientTape() <span style="color: #8B008B; font-weight: bold">as</span> tape:
            z_mean, z_log_var, z = <span style="color: #658b00">self</span>.encoder(data)
            reconstruction = <span style="color: #658b00">self</span>.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>),
                )
            )
            kl_loss = -<span style="color: #B452CD">0.5</span> * (<span style="color: #B452CD">1</span> + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=<span style="color: #B452CD">1</span>))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, <span style="color: #658b00">self</span>.trainable_weights)
        <span style="color: #658b00">self</span>.optimizer.apply_gradients(<span style="color: #658b00">zip</span>(grads, <span style="color: #658b00">self</span>.trainable_weights))
        <span style="color: #658b00">self</span>.total_loss_tracker.update_state(total_loss)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker.update_state(reconstruction_loss)
        <span style="color: #658b00">self</span>.kl_loss_tracker.update_state(kl_loss)
        <span style="color: #8B008B; font-weight: bold">return</span> {
            <span style="color: #CD5555">&quot;loss&quot;</span>: <span style="color: #658b00">self</span>.total_loss_tracker.result(),
            <span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>: <span style="color: #658b00">self</span>.reconstruction_loss_tracker.result(),
            <span style="color: #CD5555">&quot;kl_loss&quot;</span>: <span style="color: #658b00">self</span>.kl_loss_tracker.result(),
        }


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Train the VAE</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()
mnist_digits = np.concatenate([x_train, x_test], axis=<span style="color: #B452CD">0</span>)
mnist_digits = np.expand_dims(mnist_digits, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(mnist_digits, epochs=<span style="color: #B452CD">30</span>, batch_size=<span style="color: #B452CD">128</span>)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display a grid of sampled digits</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_latent_space</span>(vae, n=<span style="color: #B452CD">30</span>, figsize=<span style="color: #B452CD">15</span>):
    <span style="color: #228B22"># display a n*n 2D manifold of digits</span>
    digit_size = <span style="color: #B452CD">28</span>
    scale = <span style="color: #B452CD">1.0</span>
    figure = np.zeros((digit_size * n, digit_size * n))
    <span style="color: #228B22"># linearly spaced coordinates corresponding to the 2D plot</span>
    <span style="color: #228B22"># of digit classes in the latent space</span>
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-<span style="color: #B452CD">1</span>]

    <span style="color: #8B008B; font-weight: bold">for</span> i, yi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_y):
        <span style="color: #8B008B; font-weight: bold">for</span> j, xi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample, verbose=<span style="color: #B452CD">0</span>)
            digit = x_decoded[<span style="color: #B452CD">0</span>].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + <span style="color: #B452CD">1</span>) * digit_size,
                j * digit_size : (j + <span style="color: #B452CD">1</span>) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // <span style="color: #B452CD">2</span>
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, <span style="color: #B452CD">1</span>)
    sample_range_y = np.round(grid_y, <span style="color: #B452CD">1</span>)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.imshow(figure, cmap=<span style="color: #CD5555">&quot;Greys_r&quot;</span>)
    plt.show()


plot_latent_space(vae)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display how the latent space clusters different digit classes</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_label_clusters</span>(vae, data, labels):
    <span style="color: #228B22"># display a 2D plot of the digit classes in the latent space</span>
    z_mean, _, _ = vae.encoder.predict(data, verbose=<span style="color: #B452CD">0</span>)
    plt.figure(figsize=(<span style="color: #B452CD">12</span>, <span style="color: #B452CD">10</span>))
    plt.scatter(z_mean[:, <span style="color: #B452CD">0</span>], z_mean[:, <span style="color: #B452CD">1</span>], c=labels)
    plt.colorbar()
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.show()


(x_train, y_train), _ = keras.datasets.mnist.load_data()
x_train = np.expand_dims(x_train, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

plot_label_clusters(vae, x_train, y_train)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="code-in-pytorch-for-vaes">Code in PyTorch for VAEs </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch.autograd</span> <span style="color: #8B008B; font-weight: bold">import</span> Variable
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn.functional</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">F</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torchvision</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> <span style="color: #8B008B; font-weight: bold">import</span> transforms
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.optim</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">optim</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> nn
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> distributions

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Encoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, latent_size):
        <span style="color: #658b00">super</span>(Encoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, H)
        <span style="color: #658b00">self</span>.enc_mu = torch.nn.Linear(H, latent_size)
        <span style="color: #658b00">self</span>.enc_log_sigma = torch.nn.Linear(H, latent_size)

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        x = F.relu(<span style="color: #658b00">self</span>.linear2(x))
        mu = <span style="color: #658b00">self</span>.enc_mu(x)
        log_sigma = <span style="color: #658b00">self</span>.enc_log_sigma(x)
        sigma = torch.exp(log_sigma)
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(loc=mu, scale=sigma)


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Decoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, D_out):
        <span style="color: #658b00">super</span>(Decoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, D_out)
        

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        mu = torch.tanh(<span style="color: #658b00">self</span>.linear2(x))
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(mu, torch.ones_like(mu))

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder):
        <span style="color: #658b00">super</span>(VAE, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, state):
        q_z = <span style="color: #658b00">self</span>.encoder(state)
        z = q_z.rsample()
        <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #658b00">self</span>.decoder(z), q_z


transform = transforms.Compose(
    [transforms.ToTensor(),
     <span style="color: #228B22"># Normalize the images to be -0.5, 0.5</span>
     transforms.Normalize(<span style="color: #B452CD">0.5</span>, <span style="color: #B452CD">1</span>)]
    )
mnist = torchvision.datasets.MNIST(<span style="color: #CD5555">&#39;./&#39;</span>, download=<span style="color: #8B008B; font-weight: bold">True</span>, transform=transform)

input_dim = <span style="color: #B452CD">28</span> * <span style="color: #B452CD">28</span>
batch_size = <span style="color: #B452CD">128</span>
num_epochs = <span style="color: #B452CD">100</span>
learning_rate = <span style="color: #B452CD">0.001</span>
hidden_size = <span style="color: #B452CD">512</span>
latent_size = <span style="color: #B452CD">8</span>

<span style="color: #8B008B; font-weight: bold">if</span> torch.cuda.is_available():
    device = torch.device(<span style="color: #CD5555">&#39;cuda&#39;</span>)
<span style="color: #8B008B; font-weight: bold">else</span>:
    device = torch.device(<span style="color: #CD5555">&#39;cpu&#39;</span>)

dataloader = torch.utils.data.DataLoader(
    mnist, batch_size=batch_size,
    shuffle=<span style="color: #8B008B; font-weight: bold">True</span>, 
    pin_memory=torch.cuda.is_available())

<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Number of samples: &#39;</span>, <span style="color: #658b00">len</span>(mnist))

encoder = Encoder(input_dim, hidden_size, latent_size)
decoder = Decoder(latent_size, hidden_size, input_dim)

vae = VAE(encoder, decoder).to(device)

optimizer = optim.Adam(vae.parameters(), lr=learning_rate)
<span style="color: #8B008B; font-weight: bold">for</span> epoch <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(num_epochs):
    <span style="color: #8B008B; font-weight: bold">for</span> data <span style="color: #8B008B">in</span> dataloader:
        inputs, _ = data
        inputs = inputs.view(-<span style="color: #B452CD">1</span>, input_dim).to(device)
        optimizer.zero_grad()
        p_x, q_z = vae(inputs)
        log_likelihood = p_x.log_prob(inputs).sum(-<span style="color: #B452CD">1</span>).mean()
        kl = torch.distributions.kl_divergence(
            q_z, 
            torch.distributions.Normal(<span style="color: #B452CD">0</span>, <span style="color: #B452CD">1.</span>)
        ).sum(-<span style="color: #B452CD">1</span>).mean()
        loss = -(log_likelihood - kl)
        loss.backward()
        optimizer.step()
        l = loss.item()
    <span style="color: #658b00">print</span>(epoch, l, log_likelihood.item(), kl.item())
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models-basics">Diffusion models, basics </h2>

<p>Diffusion models are inspired by non-equilibrium thermodynamics. They
define a Markov chain of diffusion steps to slowly add random noise to
data and then learn to reverse the diffusion process to construct
desired data samples from the noise. Unlike VAE or flow models,
diffusion models are learned with a fixed procedure and the latent
variable has high dimensionality (same as the original data).
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="problems-with-probabilistic-models">Problems with probabilistic models </h2>

<p>Historically, probabilistic models suffer from a tradeoff between two
conflicting objectives: \textit{tractability} and
\textit{flexibility}. Models that are \textit{tractable} can be
analytically evaluated and easily fit to data (e.g. a Gaussian or
Laplace). However, these models are unable to aptly describe structure
in rich datasets. On the other hand, models that are \textit{flexible}
can be molded to fit structure in arbitrary data. For example, we can
define models in terms of any (non-negative) function \( \phi(\boldsymbol{x}) \)
yielding the flexible distribution \( p\left(\boldsymbol{x}\right) =
\frac{\phi\left(\boldsymbol{x} \right)}{Z} \), where \( Z \) is a normalization
constant. However, computing this normalization constant is generally
intractable. Evaluating, training, or drawing samples from such
flexible models typically requires a very expensive Monte Carlo
process.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models">Diffusion models </h2>
<p>Diffusion models have several interesting features</p>
<ul>
<li> extreme flexibility in model structure,</li>
<li> exact sampling,</li>
<li> easy multiplication with other distributions, e.g. in order to compute a posterior, and</li>
<li> the model log likelihood, and the probability of individual states, to be cheaply evaluated.</li>
</ul>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="original-idea">Original idea </h2>

<p>In the original formulation, one uses a Markov chain to gradually
convert one distribution into another, an idea used in non-equilibrium
statistical physics and sequential Monte Carlo. Diffusion models build
a generative Markov chain which converts a simple known distribution
(e.g. a Gaussian) into a target (data) distribution using a diffusion
process. Rather than use this Markov chain to approximately evaluate a
model which has been otherwise defined, one can  explicitly define the
probabilistic model as the endpoint of the Markov chain. Since each
step in the diffusion chain has an analytically evaluable probability,
the full chain can also be analytically evaluated.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-learning">Diffusion learning </h2>

<p>Learning in this framework involves estimating small perturbations to
a diffusion process. Estimating small, analytically tractable,
perturbations is more tractable than explicitly describing the full
distribution with a single, non-analytically-normalizable, potential
function.  Furthermore, since a diffusion process exists for any
smooth target distribution, this method can capture data distributions
of arbitrary form.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="code-examples-using-keras">Code examples using Keras </h2>

<p>Code taken from  <a href="https://keras.io/examples/generative/vae/" target="_blank"><tt>https://keras.io/examples/generative/vae/</tt></a></p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">Title: Variational AutoEncoder</span>
<span style="color: #CD5555">Author: [fchollet](https://twitter.com/fchollet)</span>
<span style="color: #CD5555">Date created: 2020/05/03</span>
<span style="color: #CD5555">Last modified: 2023/11/22</span>
<span style="color: #CD5555">Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.</span>
<span style="color: #CD5555">Accelerator: GPU</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Setup</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

os.environ[<span style="color: #CD5555">&quot;KERAS_BACKEND&quot;</span>] = <span style="color: #CD5555">&quot;tensorflow&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">tensorflow</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">tf</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">keras</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">keras</span> <span style="color: #8B008B; font-weight: bold">import</span> layers

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Create a sampling layer</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Sampling</span>(layers.Layer):
    <span style="color: #CD5555">&quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;</span>

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">call</span>(<span style="color: #658b00">self</span>, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[<span style="color: #B452CD">0</span>]
        dim = tf.shape(z_mean)[<span style="color: #B452CD">1</span>]
        epsilon = tf.random.normal(shape=(batch, dim))
        <span style="color: #8B008B; font-weight: bold">return</span> z_mean + tf.exp(<span style="color: #B452CD">0.5</span> * z_log_var) * epsilon


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the encoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_dim = <span style="color: #B452CD">2</span>

encoder_inputs = keras.Input(shape=(<span style="color: #B452CD">28</span>, <span style="color: #B452CD">28</span>, <span style="color: #B452CD">1</span>))
x = layers.Conv2D(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(encoder_inputs)
x = layers.Conv2D(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Flatten()(x)
x = layers.Dense(<span style="color: #B452CD">16</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(x)
z_mean = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_mean&quot;</span>)(x)
z_log_var = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_log_var&quot;</span>)(x)
z = Sampling()([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=<span style="color: #CD5555">&quot;encoder&quot;</span>)
encoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the decoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(<span style="color: #B452CD">7</span> * <span style="color: #B452CD">7</span> * <span style="color: #B452CD">64</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(latent_inputs)
x = layers.Reshape((<span style="color: #B452CD">7</span>, <span style="color: #B452CD">7</span>, <span style="color: #B452CD">64</span>))(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder_outputs = layers.Conv2DTranspose(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;sigmoid&quot;</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name=<span style="color: #CD5555">&quot;decoder&quot;</span>)
decoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Define the VAE as a `Model` with a custom `train_step`</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(keras.Model):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder, **kwargs):
        <span style="color: #658b00">super</span>().<span style="color: #008b45">__init__</span>(**kwargs)
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder
        <span style="color: #658b00">self</span>.total_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;total_loss&quot;</span>)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker = keras.metrics.Mean(
            name=<span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>
        )
        <span style="color: #658b00">self</span>.kl_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;kl_loss&quot;</span>)

    <span style="color: #707a7c">@property</span>
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">metrics</span>(<span style="color: #658b00">self</span>):
        <span style="color: #8B008B; font-weight: bold">return</span> [
            <span style="color: #658b00">self</span>.total_loss_tracker,
            <span style="color: #658b00">self</span>.reconstruction_loss_tracker,
            <span style="color: #658b00">self</span>.kl_loss_tracker,
        ]

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">train_step</span>(<span style="color: #658b00">self</span>, data):
        <span style="color: #8B008B; font-weight: bold">with</span> tf.GradientTape() <span style="color: #8B008B; font-weight: bold">as</span> tape:
            z_mean, z_log_var, z = <span style="color: #658b00">self</span>.encoder(data)
            reconstruction = <span style="color: #658b00">self</span>.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>),
                )
            )
            kl_loss = -<span style="color: #B452CD">0.5</span> * (<span style="color: #B452CD">1</span> + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=<span style="color: #B452CD">1</span>))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, <span style="color: #658b00">self</span>.trainable_weights)
        <span style="color: #658b00">self</span>.optimizer.apply_gradients(<span style="color: #658b00">zip</span>(grads, <span style="color: #658b00">self</span>.trainable_weights))
        <span style="color: #658b00">self</span>.total_loss_tracker.update_state(total_loss)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker.update_state(reconstruction_loss)
        <span style="color: #658b00">self</span>.kl_loss_tracker.update_state(kl_loss)
        <span style="color: #8B008B; font-weight: bold">return</span> {
            <span style="color: #CD5555">&quot;loss&quot;</span>: <span style="color: #658b00">self</span>.total_loss_tracker.result(),
            <span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>: <span style="color: #658b00">self</span>.reconstruction_loss_tracker.result(),
            <span style="color: #CD5555">&quot;kl_loss&quot;</span>: <span style="color: #658b00">self</span>.kl_loss_tracker.result(),
        }


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Train the VAE</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()
mnist_digits = np.concatenate([x_train, x_test], axis=<span style="color: #B452CD">0</span>)
mnist_digits = np.expand_dims(mnist_digits, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(mnist_digits, epochs=<span style="color: #B452CD">30</span>, batch_size=<span style="color: #B452CD">128</span>)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display a grid of sampled digits</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_latent_space</span>(vae, n=<span style="color: #B452CD">30</span>, figsize=<span style="color: #B452CD">15</span>):
    <span style="color: #228B22"># display a n*n 2D manifold of digits</span>
    digit_size = <span style="color: #B452CD">28</span>
    scale = <span style="color: #B452CD">1.0</span>
    figure = np.zeros((digit_size * n, digit_size * n))
    <span style="color: #228B22"># linearly spaced coordinates corresponding to the 2D plot</span>
    <span style="color: #228B22"># of digit classes in the latent space</span>
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-<span style="color: #B452CD">1</span>]

    <span style="color: #8B008B; font-weight: bold">for</span> i, yi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_y):
        <span style="color: #8B008B; font-weight: bold">for</span> j, xi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample, verbose=<span style="color: #B452CD">0</span>)
            digit = x_decoded[<span style="color: #B452CD">0</span>].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + <span style="color: #B452CD">1</span>) * digit_size,
                j * digit_size : (j + <span style="color: #B452CD">1</span>) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // <span style="color: #B452CD">2</span>
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, <span style="color: #B452CD">1</span>)
    sample_range_y = np.round(grid_y, <span style="color: #B452CD">1</span>)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.imshow(figure, cmap=<span style="color: #CD5555">&quot;Greys_r&quot;</span>)
    plt.show()


plot_latent_space(vae)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display how the latent space clusters different digit classes</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_label_clusters</span>(vae, data, labels):
    <span style="color: #228B22"># display a 2D plot of the digit classes in the latent space</span>
    z_mean, _, _ = vae.encoder.predict(data, verbose=<span style="color: #B452CD">0</span>)
    plt.figure(figsize=(<span style="color: #B452CD">12</span>, <span style="color: #B452CD">10</span>))
    plt.scatter(z_mean[:, <span style="color: #B452CD">0</span>], z_mean[:, <span style="color: #B452CD">1</span>], c=labels)
    plt.colorbar()
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.show()


(x_train, y_train), _ = keras.datasets.mnist.load_data()
x_train = np.expand_dims(x_train, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

plot_label_clusters(vae, x_train, y_train)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="code-in-pytorch-for-vaes">Code in PyTorch for VAEs </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch.autograd</span> <span style="color: #8B008B; font-weight: bold">import</span> Variable
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn.functional</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">F</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torchvision</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> <span style="color: #8B008B; font-weight: bold">import</span> transforms
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.optim</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">optim</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> nn
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> distributions

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Encoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, latent_size):
        <span style="color: #658b00">super</span>(Encoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, H)
        <span style="color: #658b00">self</span>.enc_mu = torch.nn.Linear(H, latent_size)
        <span style="color: #658b00">self</span>.enc_log_sigma = torch.nn.Linear(H, latent_size)

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        x = F.relu(<span style="color: #658b00">self</span>.linear2(x))
        mu = <span style="color: #658b00">self</span>.enc_mu(x)
        log_sigma = <span style="color: #658b00">self</span>.enc_log_sigma(x)
        sigma = torch.exp(log_sigma)
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(loc=mu, scale=sigma)


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Decoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, D_out):
        <span style="color: #658b00">super</span>(Decoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, D_out)
        

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        mu = torch.tanh(<span style="color: #658b00">self</span>.linear2(x))
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(mu, torch.ones_like(mu))

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder):
        <span style="color: #658b00">super</span>(VAE, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, state):
        q_z = <span style="color: #658b00">self</span>.encoder(state)
        z = q_z.rsample()
        <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #658b00">self</span>.decoder(z), q_z


transform = transforms.Compose(
    [transforms.ToTensor(),
     <span style="color: #228B22"># Normalize the images to be -0.5, 0.5</span>
     transforms.Normalize(<span style="color: #B452CD">0.5</span>, <span style="color: #B452CD">1</span>)]
    )
mnist = torchvision.datasets.MNIST(<span style="color: #CD5555">&#39;./&#39;</span>, download=<span style="color: #8B008B; font-weight: bold">True</span>, transform=transform)

input_dim = <span style="color: #B452CD">28</span> * <span style="color: #B452CD">28</span>
batch_size = <span style="color: #B452CD">128</span>
num_epochs = <span style="color: #B452CD">100</span>
learning_rate = <span style="color: #B452CD">0.001</span>
hidden_size = <span style="color: #B452CD">512</span>
latent_size = <span style="color: #B452CD">8</span>

<span style="color: #8B008B; font-weight: bold">if</span> torch.cuda.is_available():
    device = torch.device(<span style="color: #CD5555">&#39;cuda&#39;</span>)
<span style="color: #8B008B; font-weight: bold">else</span>:
    device = torch.device(<span style="color: #CD5555">&#39;cpu&#39;</span>)

dataloader = torch.utils.data.DataLoader(
    mnist, batch_size=batch_size,
    shuffle=<span style="color: #8B008B; font-weight: bold">True</span>, 
    pin_memory=torch.cuda.is_available())

<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Number of samples: &#39;</span>, <span style="color: #658b00">len</span>(mnist))

encoder = Encoder(input_dim, hidden_size, latent_size)
decoder = Decoder(latent_size, hidden_size, input_dim)

vae = VAE(encoder, decoder).to(device)

optimizer = optim.Adam(vae.parameters(), lr=learning_rate)
<span style="color: #8B008B; font-weight: bold">for</span> epoch <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(num_epochs):
    <span style="color: #8B008B; font-weight: bold">for</span> data <span style="color: #8B008B">in</span> dataloader:
        inputs, _ = data
        inputs = inputs.view(-<span style="color: #B452CD">1</span>, input_dim).to(device)
        optimizer.zero_grad()
        p_x, q_z = vae(inputs)
        log_likelihood = p_x.log_prob(inputs).sum(-<span style="color: #B452CD">1</span>).mean()
        kl = torch.distributions.kl_divergence(
            q_z, 
            torch.distributions.Normal(<span style="color: #B452CD">0</span>, <span style="color: #B452CD">1.</span>)
        ).sum(-<span style="color: #B452CD">1</span>).mean()
        loss = -(log_likelihood - kl)
        loss.backward()
        optimizer.step()
        l = loss.item()
    <span style="color: #658b00">print</span>(epoch, l, log_likelihood.item(), kl.item())
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models-basics">Diffusion models, basics </h2>

<p>Diffusion models are inspired by non-equilibrium thermodynamics. They
define a Markov chain of diffusion steps to slowly add random noise to
data and then learn to reverse the diffusion process to construct
desired data samples from the noise. Unlike VAE or flow models,
diffusion models are learned with a fixed procedure and the latent
variable has high dimensionality (same as the original data).
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="problems-with-probabilistic-models">Problems with probabilistic models </h2>

<p>Historically, probabilistic models suffer from a tradeoff between two
conflicting objectives: \textit{tractability} and
\textit{flexibility}. Models that are \textit{tractable} can be
analytically evaluated and easily fit to data (e.g. a Gaussian or
Laplace). However, these models are unable to aptly describe structure
in rich datasets. On the other hand, models that are \textit{flexible}
can be molded to fit structure in arbitrary data. For example, we can
define models in terms of any (non-negative) function \( \phi(\boldsymbol{x}) \)
yielding the flexible distribution \( p\left(\boldsymbol{x}\right) =
\frac{\phi\left(\boldsymbol{x} \right)}{Z} \), where \( Z \) is a normalization
constant. However, computing this normalization constant is generally
intractable. Evaluating, training, or drawing samples from such
flexible models typically requires a very expensive Monte Carlo
process.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models">Diffusion models </h2>
<p>Diffusion models have several interesting features</p>
<ul>
<li> extreme flexibility in model structure,</li>
<li> exact sampling,</li>
<li> easy multiplication with other distributions, e.g. in order to compute a posterior, and</li>
<li> the model log likelihood, and the probability of individual states, to be cheaply evaluated.</li>
</ul>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="original-idea">Original idea </h2>

<p>In the original formulation, one uses a Markov chain to gradually
convert one distribution into another, an idea used in non-equilibrium
statistical physics and sequential Monte Carlo. Diffusion models build
a generative Markov chain which converts a simple known distribution
(e.g. a Gaussian) into a target (data) distribution using a diffusion
process. Rather than use this Markov chain to approximately evaluate a
model which has been otherwise defined, one can  explicitly define the
probabilistic model as the endpoint of the Markov chain. Since each
step in the diffusion chain has an analytically evaluable probability,
the full chain can also be analytically evaluated.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-learning">Diffusion learning </h2>

<p>Learning in this framework involves estimating small perturbations to
a diffusion process. Estimating small, analytically tractable,
perturbations is more tractable than explicitly describing the full
distribution with a single, non-analytically-normalizable, potential
function.  Furthermore, since a diffusion process exists for any
smooth target distribution, this method can capture data distributions
of arbitrary form.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="mathematics-of-diffusion-models">Mathematics of diffusion models </h2>

<p>Let us go back our discussions of the variational autoencoders from
last week, see
<a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb" target="_blank"><tt>https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb</tt></a>. As
a first attempt at understanding diffusion models, we can think of
these as stacked VAEs, or better, recursive VAEs.
</p>

<p>Let us try to see why. As an intermediate step, we consider so-called
hierarchical VAEs, which can be seen as a generalization of VAEs that
include multiple hierarchies of latent spaces.
</p>

<p><b>Note</b>: Many of the derivations and figures here are inspired and borrowed from the excellent exposition of diffusion models by Calvin Luo at <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>. </p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="chains-of-vaes">Chains of VAEs </h2>

<p>Markovian
VAEs represent a  generative process where we use  Markov chain to build a hierarchy of VAEs.
</p>

<p>Each transition down the hierarchy is Markovian, where we decode each
latent set of variables \( \boldsymbol{h}_t \) in terms of the previous latent variable \( \boldsymbol{h}_{t-1} \).
Intuitively, and visually, this can be seen as simply stacking VAEs on
top of each other (see figure next slide).
</p>

<p>One can think of such a model as a recursive VAE.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="mathematical-representation">Mathematical representation </h2>

<p>Mathematically, we represent the joint distribution and the posterior
of a Markovian VAE as
</p>
$$
\begin{align*}
    p(\boldsymbol{x}, \boldsymbol{h}_{1:T}) &= p(\boldsymbol{h}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}_1)\prod_{t=2}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{h}_{t-1}|\boldsymbol{h}_{t})\\
    q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x}) &= q_{\boldsymbol{\phi}}(\boldsymbol{h}_1|\boldsymbol{x})\prod_{t=2}^{T}q_{\boldsymbol{\phi}}(\boldsymbol{h}_{t}|\boldsymbol{h}_{t-1})
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="back-to-the-marginal-probability">Back to the marginal probability </h2>

<p>We can then define the marginal probability we want to optimize as</p>
$$
\begin{align*}
\log p(\boldsymbol{x}) &= \log \int p(\boldsymbol{x}, \boldsymbol{h}_{1:T}) d\boldsymbol{h}_{1:T}  \\
&= \log \int \frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})} d\boldsymbol{h}_{1:T}         && \text{(Multiply by 1 = $\frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}$)}\\
&= \log \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\right]         && \text{(Definition of Expectation)}\\
&\geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\log \frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\right]         && \text{(Discussed last week)}
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models-for-hierarchical-vae-from-url-https-arxiv-org-abs-2208-11970">Diffusion models for hierarchical VAE, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<p>A Markovian hierarchical Variational Autoencoder with \( T \) hierarchical
latents.  The generative process is modeled as a Markov chain, where
each latent \( \boldsymbol{h}_t \) is generated only from the previous latent
\( \boldsymbol{h}_{t+1} \). Here \( \boldsymbol{z} \) is our latent variable \( \boldsymbol{h} \).
</p>

<br/><br/>
<center>
<p><img src="figures/figure1.png" width="800" align="bottom"></p>
</center>
<br/><br/>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="equation-for-the-markovian-hierarchical-vae">Equation for the Markovian hierarchical VAE </h2>

<p>We obtain then</p>
$$
\begin{align*}
\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\log \frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\right]
&= \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\log \frac{p(\boldsymbol{h}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}_1)\prod_{t=2}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{h}_{t-1}|\boldsymbol{h}_{t})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_1|\boldsymbol{x})\prod_{t=2}^{T}q_{\boldsymbol{\phi}}(\boldsymbol{h}_{t}|\boldsymbol{h}_{t-1})}\right]
\end{align*}
$$

<p>We will modify this equation when we discuss what are normally called Variational Diffusion Models.</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="variational-diffusion-models">Variational Diffusion Models </h2>

<p>The easiest way to think of a Variational Diffusion Model (VDM) is as a Markovian Hierarchical Variational Autoencoder with three key restrictions:</p>

<ol>
<li> The latent dimension is exactly equal to the data dimension</li>
<li> The structure of the latent encoder at each timestep is not learned; it is pre-defined as a linear Gaussian model.  In other words, it is a Gaussian distribution centered around the output of the previous timestep</li>
<li> The Gaussian parameters of the latent encoders vary over time in such a way that the distribution of the latent at final timestep \( T \) is a standard Gaussian</li>
</ol>
<p>The VDM posterior is</p>
$$
\begin{align*}
    q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0) = \prod_{t = 1}^{T}q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="second-assumption">Second assumption </h2>

<p>The distribution of each latent variable in the encoder is a Gaussian centered around its previous hierarchical latent.
Here then, the structure of the encoder at each timestep \( t \) is not learned; it
is fixed as a linear Gaussian model, where the mean and standard
deviation can be set beforehand as hyperparameters, or learned as
parameters.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="parameterizing-gaussian-encoder">Parameterizing Gaussian encoder </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>We parameterize the Gaussian encoder with mean \( \boldsymbol{\mu}_t(\boldsymbol{x}_t) =
\sqrt{\alpha_t} \boldsymbol{x}_{t-1} \), and variance \( \boldsymbol{\Sigma}_t(\boldsymbol{x}_t) =
(1 - \alpha_t) \textbf{I} \), where the form of the coefficients are
chosen such that the variance of the latent variables stay at a
similar scale; in other words, the encoding process is
variance-preserving.
</p>
</div>


<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<p>Note that alternate Gaussian parameterizations
are allowed, and lead to similar derivations.  The main takeaway is
that \( \alpha_t \) is a (potentially learnable) coefficient that can vary
with the hierarchical depth \( t \), for flexibility.
</p>
</div>


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="encoder-transitions">Encoder transitions </h2>

<p>Mathematically, the encoder transitions are defined as</p>
$$
\begin{align*}
    q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1}) = \mathcal{N}(\boldsymbol{x}_{t} ; \sqrt{\alpha_t} \boldsymbol{x}_{t-1}, (1 - \alpha_t) \textbf{I}) \label{eq:27}
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="third-assumption">Third assumption </h2>

<p>From the third assumption, we know that \( \alpha_t \) evolves over time
according to a fixed or learnable schedule structured such that the
distribution of the final latent \( p(\boldsymbol{x}_T) \) is a standard Gaussian.
We can then update the joint distribution of a Markovian VAE to write
the joint distribution for a VDM as
</p>

$$
\begin{align*}
p(\boldsymbol{x}_{0:T}) &= p(\boldsymbol{x}_T)\prod_{t=1}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t) \\
\text{where,}&\nonumber\\
p(\boldsymbol{x}_T) &= \mathcal{N}(\boldsymbol{x}_T; \boldsymbol{0}, \textbf{I})
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="noisification">Noisification </h2>

<p>Collectively, what this set of assumptions describes is a steady
noisification of an image input over time. We progressively corrupt an
image by adding Gaussian noise until eventually it becomes completely
identical to pure Gaussian noise.  See figure on next slide.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models-from-url-https-arxiv-org-abs-2208-11970">Diffusion models, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<br/><br/>
<center>
<p><img src="figures/figure2.png" width="800" align="bottom"></p>
</center>
<br/><br/>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="gaussian-modeling">Gaussian modeling </h2>

<p>Note that our encoder distributions \( q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1}) \) are no
longer parameterized by \( \boldsymbol{\phi} \), as they are completely modeled as
Gaussians with defined mean and variance parameters at each timestep.
Therefore, in a VDM, we are only interested in learning conditionals
\( p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_{t}) \), so that we can simulate
new data.  After optimizing the VDM, the sampling procedure is as
simple as sampling Gaussian noise from \( p(\boldsymbol{x}_T) \) and iteratively
running the denoising transitions
\( p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_{t}) \) for \( T \) steps to generate a
novel \( \boldsymbol{x}_0 \).
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="optimizing-the-variational-diffusion-model">Optimizing the variational diffusion model </h2>

$$
\begin{align*}
\log p(\boldsymbol{x})
&= \log \int p(\boldsymbol{x}_{0:T}) d\boldsymbol{x}_{1:T}\\
&= \log \int \frac{p(\boldsymbol{x}_{0:T})q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)} d\boldsymbol{x}_{1:T}\\
&= \log \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\right]\\
&\geq {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)\prod_{t=1}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)}{\prod_{t = 1}^{T}q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\prod_{t=2}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})\prod_{t = 1}^{T-1}q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\prod_{t=1}^{T-1}p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})\prod_{t = 1}^{T-1}q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})}\right] + \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \prod_{t = 1}^{T-1}\frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="continues">Continues </h2>

$$
\begin{align*}
\log p(\boldsymbol{x})
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})}\right] + \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \prod_{t = 1}^{T-1}\frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\right] + \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})}\right] + \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[ \sum_{t=1}^{T-1} \log \frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\right] + \mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})}\right] + \sum_{t=1}^{T-1}\mathbb{E}_{q(\boldsymbol{x}_{1:T}|\boldsymbol{x}_0)}\left[ \log \frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
&= {\mathbb{E}_{q(\boldsymbol{x}_{1}|\boldsymbol{x}_0)}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\right] + \mathbb{E}_{q(\boldsymbol{x}_{T-1}, \boldsymbol{x}_T|\boldsymbol{x}_0)}\left[\log \frac{p(\boldsymbol{x}_T)}{q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})}\right] + \sum_{t=1}^{T-1}\mathbb{E}_{q(\boldsymbol{x}_{t-1}, \boldsymbol{x}_t, \boldsymbol{x}_{t+1}|\boldsymbol{x}_0)}\left[\log \frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})}\right]}\\
\end{align*}
$$


<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="interpretations">Interpretations </h2>

<p>These equations can be interpreted as</p>

<ul>
<li> \( \mathbb{E}_{q(\boldsymbol{x}_{1}|\boldsymbol{x}_0)}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}_0|\boldsymbol{x}_1)\right] \) can be interpreted as a <b>reconstruction term</b>, predicting the log probability of the original data sample given the first-step latent.  This term also appears in a vanilla VAE, and can be trained similarly.</li>
<li> \( \mathbb{E}_{q(\boldsymbol{x}_{T-1}|\boldsymbol{x}_0)}\left[D_{KL}(q(\boldsymbol{x}_T|\boldsymbol{x}_{T-1})\vert\vert p(\boldsymbol{x}_T))\right] \) is a <b>prior matching term</b>; it is minimized when the final latent distribution matches the Gaussian prior.  This term requires no optimization, as it has no trainable parameters; furthermore, as we have assumed a large enough \( T \) such that the final distribution is Gaussian, this term effectively becomes zero.</li>
</ul>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="the-last-term">The last term </h2>

<ul>
<li> \( \mathbb{E}_{q(\boldsymbol{x}_{t-1}, \boldsymbol{x}_{t+1}|\boldsymbol{x}_0)}\left[D_{KL}(q(\boldsymbol{x}_{t}|\boldsymbol{x}_{t-1})\vert\vert p_{\boldsymbol{\theta}}(\boldsymbol{x}_{t}|\boldsymbol{x}_{t+1}))\right] \) is a \textit{consistency term}; it endeavors to make the distribution at \( \boldsymbol{x}_t \) consistent, from both forward and backward processes.  That is, a denoising step from a noisier image should match the corresponding noising step from a cleaner image, for every intermediate timestep; this is reflected mathematically by the KL Divergence.  This term is minimized when we train \( p_{\theta}(\boldsymbol{x}_t|\boldsymbol{x}_{t+1}) \) to match the Gaussian distribution \( q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1}) \).</li>
</ul>
<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="diffusion-models-part-2-from-url-https-arxiv-org-abs-2208-11970">Diffusion models, part 2, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<br/><br/>
<center>
<p><img src="figures/figure3.png" width="800" align="bottom"></p>
</center>
<br/><br/>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="optimization-cost">Optimization cost </h2>

<p>The cost of optimizing a VDM is primarily dominated by the third term, since we must optimize over all timesteps \( t \).</p>

<p>Under this derivation, all three terms are computed as expectations,
and can therefore be approximated using Monte Carlo estimates.
However, actually optimizing the ELBO using the terms we just derived
might be suboptimal; because the consistency term is computed as an
expectation over two random variables \( \left\{\boldsymbol{x}_{t-1},
\boldsymbol{x}_{t+1}\right\} \) for every timestep, the variance of its Monte
Carlo estimate could potentially be higher than a term that is
estimated using only one random variable per timestep.  As it is
computed by summing up \( T-1 \) consistency terms, the final estimated
value may have high variance for large \( T \) values.
</p>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="more-details">More details </h2>

<p>For more details and implementaions, see Calvin Luo at <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a></p>

<!-- FIGURE: [figures/figure4.png, width=800 frac=1.0] -->

<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>


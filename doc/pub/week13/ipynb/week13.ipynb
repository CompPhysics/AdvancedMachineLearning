{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650e4bf8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week13.do.txt --no_mako -->\n",
    "<!-- dom:TITLE: Advanced machine learning and data analysis for the physical sciences -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a874527",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Advanced machine learning and data analysis for the physical sciences\n",
    "**Morten Hjorth-Jensen**, Department of Physics and Center for Computing in Science Education, University of Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **April 16, 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2e500",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Plans for the week April 15-19, 2024\n",
    "\n",
    "**Deep generative models.**\n",
    "\n",
    "1. Implementation of Boltzmann machines using TensorFlow and Pytorch\n",
    "\n",
    "2. Discussion of other energy-based models\n",
    "\n",
    "3. Variational Autoencoders (VAE)\n",
    "\n",
    "4. Generative Adversarial Networks (GANs)\n",
    "<!-- o [Video of lecture](https://youtu.be/0VBmdP_iCzA) -->\n",
    "<!-- o [Whiteboard notes](https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/NotesApr262023.pdf) -->\n",
    "\n",
    "**Readings.**\n",
    "\n",
    "1. Reading recommendation: Goodfellow et al chapter 20.10-20-14\n",
    "\n",
    "2. To create Boltzmann machine using Keras, see Babcock and Bali chapter 4, see <https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_4/models/rbm.py>\n",
    "\n",
    "3. See Foster, chapter 7 on energy-based models at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm>\n",
    "\n",
    "<!-- todo: add about Langevin sampling, see <https://www.lyndonduong.com/sgmcmc/> -->\n",
    "<!-- add material about VAEs -->\n",
    "<!-- add code on RBMs -->\n",
    "<!-- code for VAEs applied to MNIST and CIFAR perhaps -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c69a72",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Code for RBMs using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38abde1",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor()])\n",
    "     ),\n",
    "     batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "    ),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "class RBM(nn.Module):\n",
    "   def __init__(self,\n",
    "               n_vis=784,\n",
    "               n_hin=500,\n",
    "               k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "   def sample_from_p(self,p):\n",
    "       return F.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "   def v_to_h(self,v):\n",
    "        p_h = F.sigmoid(F.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_from_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "   def h_to_v(self,h):\n",
    "        p_v = F.sigmoid(F.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_from_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "   def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_\n",
    "    \n",
    "   def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = F.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rbm = RBM(k=1)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_ = []\n",
    "    for _, (data,target) in enumerate(train_loader):\n",
    "        data = Variable(data.view(-1,784))\n",
    "        sample_data = data.bernoulli()\n",
    "        \n",
    "        v,v1 = rbm(sample_data)\n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data)\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "\n",
    "    print(\"Training loss for {} epoch: {}\".format(epoch, np.mean(loss_)))\n",
    "\n",
    "\n",
    "def show_adn_save(file_name,img):\n",
    "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
    "    f = \"./%s.png\" % file_name\n",
    "    plt.imshow(npimg)\n",
    "    plt.imsave(f,npimg)\n",
    "\n",
    "show_adn_save(\"real\",make_grid(v.view(32,1,28,28).data))\n",
    "show_adn_save(\"generate\",make_grid(v1.view(32,1,28,28).data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961852b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Energy-based models and Langevin sampling\n",
    "\n",
    "See discussions in Foster, chapter 7 on energy-based models at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm>\n",
    "\n",
    "That notebook is based on a recent article by Du and Mordatch, **Implicit generation and modeling with energy-based models**, see <https://arxiv.org/pdf/1903.08689.pdf.>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b11565",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Tensor-flow examples\n",
    "\n",
    "1. To create Boltzmann machine using Keras, see Babcock and Bali chapter 4, see <https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_4/models/rbm.py>\n",
    "\n",
    "2. See also Foster, chapter 7 on energy-based models at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfb9b4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Theory of Variational Autoencoders\n",
    "\n",
    "Notes to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a1e4f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Code in PyTorch for VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f087ecf",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.enc_mu = torch.nn.Linear(H, latent_size)\n",
    "        self.enc_log_sigma = torch.nn.Linear(H, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mu = self.enc_mu(x)\n",
    "        log_sigma = self.enc_log_sigma(x)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        return torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu = torch.tanh(self.linear2(x))\n",
    "        return torch.distributions.Normal(mu, torch.ones_like(mu))\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, state):\n",
    "        q_z = self.encoder(state)\n",
    "        z = q_z.rsample()\n",
    "        return self.decoder(z), q_z\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     # Normalize the images to be -0.5, 0.5\n",
    "     transforms.Normalize(0.5, 1)]\n",
    "    )\n",
    "mnist = torchvision.datasets.MNIST('./', download=True, transform=transform)\n",
    "\n",
    "input_dim = 28 * 28\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "hidden_size = 512\n",
    "latent_size = 8\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mnist, batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "print('Number of samples: ', len(mnist))\n",
    "\n",
    "encoder = Encoder(input_dim, hidden_size, latent_size)\n",
    "decoder = Decoder(latent_size, hidden_size, input_dim)\n",
    "\n",
    "vae = VAE(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(-1, input_dim).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        p_x, q_z = vae(inputs)\n",
    "        log_likelihood = p_x.log_prob(inputs).sum(-1).mean()\n",
    "        kl = torch.distributions.kl_divergence(\n",
    "            q_z, \n",
    "            torch.distributions.Normal(0, 1.)\n",
    "        ).sum(-1).mean()\n",
    "        loss = -(log_likelihood - kl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()\n",
    "    print(epoch, l, log_likelihood.item(), kl.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d383d00",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Generative Adversarial Networks\n",
    "**Generative Adversarial Networks** are a type of unsupervised machine learning\n",
    "algorithm proposed by [Goodfellow et. al](https://arxiv.org/pdf/1406.2661.pdf)\n",
    "in 2014 (Read the paper first it's only 6 pages). The simplest formulation of\n",
    "the model is based on a game theoretic approach, *zero sum game*, where we pit\n",
    "two neural networks against one another. We define two rival networks, one\n",
    "generator $g$, and one discriminator $d$. The generator directly produces\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72861b9f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    x = g(z; \\theta^{(g)})\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21457c5",
   "metadata": {
    "editable": true
   },
   "source": [
    "The discriminator attempts to distinguish between samples drawn from the\n",
    "training data and samples drawn from the generator. In other words, it tries to\n",
    "tell the difference between the fake data produced by $g$ and the actual data\n",
    "samples we want to do prediction on. The discriminator outputs a probability\n",
    "value given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a7b03",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    d(x; \\theta^{(d)})\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c575cfe",
   "metadata": {
    "editable": true
   },
   "source": [
    "indicating the probability that $x$ is a real training example rather than a\n",
    "fake sample the generator has generated. The simplest way to formulate the\n",
    "learning process in a generative adversarial network is a zero-sum game, in\n",
    "which a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d0a2d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    v(\\theta^{(g)}, \\theta^{(d)})\n",
    "\\label{_auto3} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ff0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "determines the reward for the discriminator, while the generator gets the\n",
    "conjugate reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdab61",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    -v(\\theta^{(g)}, \\theta^{(d)})\n",
    "\\label{_auto4} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214a240",
   "metadata": {
    "editable": true
   },
   "source": [
    "During learning both of the networks maximize their own reward function, so that\n",
    "the generator gets better and better at tricking the discriminator, while the\n",
    "discriminator gets better and better at telling the difference between the fake\n",
    "and real data. The generator and discriminator alternate on which one trains at\n",
    "one time (i.e. for one epoch). In other words, we keep the generator constant\n",
    "and train the discriminator, then we keep the discriminator constant to train\n",
    "the generator and repeat. It is this back and forth dynamic which lets GANs\n",
    "tackle otherwise intractable generative problems. As the generator improves with\n",
    " training, the discriminator's performance gets worse because it cannot easily\n",
    " tell the difference between real and fake. If the generator ends up succeeding\n",
    " perfectly, the the discriminator will do no better than random guessing i.e.\n",
    " 50\\%. This progression in the training poses a problem for the convergence\n",
    " criteria for GANs. The discriminator feedback gets less meaningful over time,\n",
    " if we continue training after this point then the generator is effectively\n",
    " training on junk data which can undo the learning up to that point. Therefore,\n",
    " we stop training when the discriminator starts outputting $1/2$ everywhere.\n",
    " At convergence we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c4b56",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    g^* = \\underset{g}{\\mathrm{argmin}}\\hspace{2pt}\n",
    "          \\underset{d}{\\mathrm{max}}v(\\theta^{(g)}, \\theta^{(d)})\n",
    "\\label{_auto5} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700499d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "The default choice for $v$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae40540",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    v(\\theta^{(g)}, \\theta^{(d)}) = \\mathbb{E}_{x\\sim p_\\mathrm{data}}\\log d(x)\n",
    "                                  + \\mathbb{E}_{x\\sim p_\\mathrm{model}}\n",
    "                                  \\log (1 - d(x))\n",
    "\\label{_auto6} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22081ad0",
   "metadata": {
    "editable": true
   },
   "source": [
    "The main motivation for the design of GANs is that the learning process requires\n",
    "neither approximate inference (variational autoencoders for example) nor\n",
    "approximation of a partition function. In the case where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345f831",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto7\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\underset{d}{\\mathrm{max}}v(\\theta^{(g)}, \\theta^{(d)})\n",
    "\\label{_auto7} \\tag{7}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b5fcc",
   "metadata": {
    "editable": true
   },
   "source": [
    "is convex in $\\theta^{(g)}$ then the procedure is guaranteed to converge and is\n",
    "asymptotically consistent\n",
    "( [Seth Lloyd on QuGANs](https://arxiv.org/pdf/1804.09139.pdf)  ). This is in\n",
    "general not the case and it is possible to get situations where the training\n",
    "process never converges because the generator and discriminator chase one\n",
    "another around in the parameter space indefinitely. A much deeper discussion on\n",
    "the currently open research problem of GAN convergence is available\n",
    "[here](https://www.deeplearningbook.org/contents/generative_models.html). To\n",
    "anyone interested in learning more about GANs it is a highly recommended read.\n",
    "Direct quote: \"In this best-performing formulation, the generator aims to\n",
    "increase the log probability that the discriminator makes a mistake, rather than\n",
    "aiming to decrease the log probability that the discriminator makes the correct\n",
    "prediction.\" [Another interesting read](https://arxiv.org/abs/1701.00160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04387c52",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Writing Our First Generative Adversarial Network\n",
    "\n",
    "Let us now move on to actually implementing a GAN in tensorflow. We will study\n",
    "the performance of our GAN on the MNIST dataset. This code is based on and\n",
    "adapted from the\n",
    "[google tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
    "\n",
    "First we import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f9173e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd6235",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next we define our hyperparameters and import our data the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac827089",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "\n",
    "data = tf.keras.datasets.mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = data\n",
    "train_images = np.reshape(train_images, (train_images.shape[0],\n",
    "                                         28,\n",
    "                                         28,\n",
    "                                         1)).astype('float32')\n",
    "\n",
    "# we normalize between -1 and 1\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "                      train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a381e",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's have a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d004ba5",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf541f",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we define our two models. This is where the 'magic' happens. There are a\n",
    "huge amount of possible formulations for both models. A lot of engineering and\n",
    "trial and error can be done here to try to produce better performing models. For\n",
    "more advanced GANs this is by far the step where you can 'make or break' a\n",
    "model.\n",
    "\n",
    "We start with the generator. As stated in the introductory text the generator\n",
    "$g$ upsamples from a random sample to the shape of what we want to predict. In\n",
    "our case we are trying to predict MNIST images ($28\\times 28$ pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f87212",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    \"\"\"\n",
    "    The generator uses upsampling layers tf.keras.layers.Conv2DTranspose() to\n",
    "    produce an image from a random seed. We start with a Dense layer taking this\n",
    "    random sample as an input and subsequently upsample through multiple\n",
    "    convolutional layers.\n",
    "    \"\"\"\n",
    "\n",
    "    # we define our model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "    # adding our input layer. Dense means that every neuron is connected and\n",
    "    # the input shape is the shape of our random noise. The units need to match\n",
    "    # in some sense the upsampling strides to reach our desired output shape.\n",
    "    # we are using 100 random numbers as our seed\n",
    "    model.add(layers.Dense(units=7*7*BATCH_SIZE,\n",
    "                           use_bias=False,\n",
    "                           input_shape=(100, )))\n",
    "    # we normalize the output form the Dense layer\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # and add an activation function to our 'layer'. LeakyReLU avoids vanishing\n",
    "    # gradient problem\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, BATCH_SIZE)))\n",
    "    assert model.output_shape == (None, 7, 7, BATCH_SIZE)\n",
    "    # even though we just added four keras layers we think of everything above\n",
    "    # as 'one' layer\n",
    "\n",
    "    # next we add our upscaling convolutional layers\n",
    "    model.add(layers.Conv2DTranspose(filters=128,\n",
    "                                     kernel_size=(5, 5),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=64,\n",
    "                                     kernel_size=(5, 5),\n",
    "                                     strides=(2, 2),\n",
    "                                     padding='same',\n",
    "                                     use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(filters=1,\n",
    "                                     kernel_size=(5, 5),\n",
    "                                     strides=(2, 2),\n",
    "                                     padding='same',\n",
    "                                     use_bias=False,\n",
    "                                     activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b69b1",
   "metadata": {
    "editable": true
   },
   "source": [
    "And there we have our 'simple' generator model. Now we move on to defining our\n",
    "discriminator model $d$, which is a convolutional neural network based image\n",
    "classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ca641f",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    \"\"\"\n",
    "    The discriminator is a convolutional neural network based image classifier\n",
    "    \"\"\"\n",
    "\n",
    "    # we define our model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(filters=64,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # adding a dropout layer as you do in conv-nets\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # adding a dropout layer as you do in conv-nets\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dc59e",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let us take a look at our models. **Note**: double click images for bigger view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f3dda2",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "plot_model(generator, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec936e5",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "plot_model(discriminator, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0302a75",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next we need a few helper objects we will use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864ccfe9",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9de4c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "The first object, $cross\\_entropy$ is our loss function and the two others are\n",
    "our optimizers. Notice we use the same learning rate for both $g$ and $d$. This\n",
    "is because they need to improve their accuracy at approximately equal speeds to\n",
    "get convergence (not necessarily exactly equal). Now we define our loss\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37517c73",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bfdeec4",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_liks(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba35e2",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next we define a kind of seed to help us compare the learning process over\n",
    "multiple training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590229d6",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "noise_dimension = 100\n",
    "n_examples_to_generate = 16\n",
    "seed_images = tf.random.normal([n_examples_to_generate, noise_dimension])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3823c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we have everything we need to define our training step, which we will apply\n",
    "for every step in our training loop. Notice the @tf.function flag signifying\n",
    "that the function is tensorflow 'compiled'. Removing this flag doubles the\n",
    "computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e625512",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dimension])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss,\n",
    "                                            generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss,\n",
    "                                            discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator,\n",
    "                                            generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,\n",
    "                                            discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a721d704",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next we define a helper function to produce an output over our training epochs\n",
    "to see the predictive progression of our generator model. **Note**: I am including\n",
    "this code here, but comment it out in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93f47c3",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # we're making inferences here\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f'./images_from_seed_images/image_at_epoch_{str(epoch).zfill(3)}.png')\n",
    "    plt.close()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484b4e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "Setting up checkpoints to periodically save our model during training so that\n",
    "everything is not lost even if the program were to somehow terminate while\n",
    "training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c80a46",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setting up checkpoints to save model during training\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                            discriminator_optimizer=discriminator_optimizer,\n",
    "                            generator=generator,\n",
    "                            discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c20a0f",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we define our training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f48026c2",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    generator_loss_list = []\n",
    "    discriminator_loss_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            generator_loss_list.append(gen_loss.numpy())\n",
    "            discriminator_loss_list.append(disc_loss.numpy())\n",
    "\n",
    "        #generate_and_save_images(generator, epoch + 1, seed_images)\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print(f'Time for epoch {epoch} is {time.time() - start}')\n",
    "\n",
    "    #generate_and_save_images(generator, epochs, seed_images)\n",
    "\n",
    "    loss_file = './data/lossfile.txt'\n",
    "    with open(loss_file, 'w') as outfile:\n",
    "        outfile.write(str(generator_loss_list))\n",
    "        outfile.write('\\n')\n",
    "        outfile.write('\\n')\n",
    "        outfile.write(str(discriminator_loss_list))\n",
    "        outfile.write('\\n')\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6778432",
   "metadata": {
    "editable": true
   },
   "source": [
    "To train simply call this function. **Warning**: this might take a long time so\n",
    "there is a folder of a pretrained network already included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a403d7",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda1f9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "And here is the result of training our model for 100 epochs\n",
    "\n",
    "<!-- dom:MOVIE: [images_from_seed_images/generation.gif] -->\n",
    "<!-- begin movie -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8ef5be",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "_s = \"\"\"\n",
    "<embed src=\"images_from_seed_images/generation.gif\"  autoplay=\"false\" loop=\"true\"></embed>\n",
    "<p><em></em></p>\n",
    "\"\"\"\n",
    "HTML(_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc28ff",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- end movie -->\n",
    "\n",
    "Now to avoid having to train and everything, which will take a while depending\n",
    "on your computer setup we now load in the model which produced the above gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "284f2eba",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "restored_generator = checkpoint.generator\n",
    "restored_discriminator = checkpoint.discriminator\n",
    "\n",
    "print(restored_generator)\n",
    "print(restored_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8787e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exploring the Latent Space\n",
    "\n",
    "So we have successfully loaded in our latest model. Let us now play around a bit\n",
    "and see what kind of things we can learn about this model. Our generator takes\n",
    "an array of 100 numbers. One idea can be to try to systematically change our\n",
    "input. Let us try and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb00e0f",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_latent_points(number=100, scale_means=1, scale_stds=1):\n",
    "    latent_dim = 100\n",
    "    means = scale_means * tf.linspace(-1, 1, num=latent_dim)\n",
    "    stds = scale_stds * tf.linspace(-1, 1, num=latent_dim)\n",
    "    latent_space_value_range = tf.random.normal([number, number],\n",
    "                                                means,\n",
    "                                                stds,\n",
    "                                                dtype=tf.float64)\n",
    "\n",
    "    return latent_space_value_range\n",
    "\n",
    "def generate_images(latent_points):\n",
    "    # notice we set training to false because we are making inferences\n",
    "    generated_images = restored_generator(latent_space_value_range,\n",
    "                                          training=False)\n",
    "\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee271039",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_result(generated_images, number):\n",
    "    # obviously this assumes sqrt number is an int\n",
    "    fig, axs = plt.subplots(int(np.sqrt(number)), int(np.sqrt(number)),\n",
    "                            figsize=(10, 10))\n",
    "\n",
    "    for i in range(int(np.sqrt(number))):\n",
    "        for j in range(int(np.sqrt(number))):\n",
    "            axs[i, j].imshow(generated_images[i*j], cmap='Greys')\n",
    "            axs[i, j].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6538226",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generated_images = generate_images(generate_latent_points())\n",
    "plot_result(generated_images, number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c4d02",
   "metadata": {
    "editable": true
   },
   "source": [
    "Interesting! We see that the generator generates images that look like MNIST\n",
    "numbers: $1, 4, 7, 9$. Let's try to tweak it a bit more to see if we are able\n",
    "to generate a similar plot where we generate every MNIST number. Let us now try\n",
    "to 'move' a bit around in the latent space. **Note**: decrease the plot number if\n",
    "these following cells take too long to run on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c216479",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_number = 225\n",
    "\n",
    "generated_images = generate_images(generate_latent_points(number=plot_number,\n",
    "                                                          scale_means=5,\n",
    "                                                          scale_stds=1))\n",
    "plot_result(generated_images, plot_number)\n",
    "\n",
    "generated_images = generate_images(generate_latent_points(number=plot_number,\n",
    "                                                          scale_means=-5,\n",
    "                                                          scale_stds=1))\n",
    "plot_result(generated_images, plot_number)\n",
    "\n",
    "generated_images = generate_images(generate_latent_points(number=plot_number,\n",
    "                                                          scale_means=1,\n",
    "                                                          scale_stds=5))\n",
    "plot_result(generated_images, plot_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0851d0",
   "metadata": {
    "editable": true
   },
   "source": [
    "Again, we have found something interesting. *Moving* around using our means\n",
    "takes us from digit to digit, while *moving* around using our standard\n",
    "deviations seem to increase the number of different digits! In the last image\n",
    "above, we can barely make out every MNIST digit. Let us make on last plot using\n",
    "this information by upping the standard deviation of our Gaussian noises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c22bd4c",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot_number = 400\n",
    "generated_images = generate_images(generate_latent_points(number=plot_number,\n",
    "                                                          scale_means=1,\n",
    "                                                          scale_stds=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0db94f",
   "metadata": {
    "editable": true
   },
   "source": [
    "A pretty cool result! We see that our generator indeed has learned a\n",
    "distribution which qualitatively looks a whole lot like the MNIST dataset."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

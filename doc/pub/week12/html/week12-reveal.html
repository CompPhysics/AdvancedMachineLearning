<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week12-reveal.html week12-reveal reveal --html_slide_theme=beige
-->
<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>

<!-- reveal.js: https://lab.hakim.se/reveal-js/ -->

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<!--
<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/beigesmall.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/serif.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/moon.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/darkgray.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/default.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/cbc.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simula.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/league.css" id="theme">
-->

<!-- For syntax highlighting -->
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<style type="text/css">
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.reveal .alert-text-small   { font-size: 80%;  }
.reveal .alert-text-large   { font-size: 130%; }
.reveal .alert-text-normal  { font-size: 90%;  }
.reveal .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
  -webkit-border-radius: 14px; -moz-border-radius: 14px;
  border-radius:14px;
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.reveal .alert-block {padding-top:14px; padding-bottom:14px}
.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
/*.reveal .alert li {margin-top: 1em}*/
.reveal .alert-block p+p {margin-top:5px}
/*.reveal .alert-notice { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_notice.png); }
.reveal .alert-summary  { background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_summary.png); }
.reveal .alert-warning { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_warning.png); }
.reveal .alert-question {background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_question.png); } */
/* Override reveal.js table border */
.reveal table td {
  border: 0;
}

<style type="text/css">
/* Override h1, h2, ... styles */
h1 { font-size: 2.8em; }
h2 { font-size: 1.5em; }
h3 { font-size: 1.4em; }
h4 { font-size: 1.3em; }
h1, h2, h3, h4 { font-weight: bold; line-height: 1.2; }
body { overflow: auto; } /* vertical scrolling */
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.slide .alert-text-small   { font-size: 80%;  }
.slide .alert-text-large   { font-size: 130%; }
.slide .alert-text-normal  { font-size: 90%;  }
.slide .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
    -webkit-border-radius:14px; -moz-border-radius:14px;
  border-radius:14px
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.slide .alert-block {padding-top:14px; padding-bottom:14px}
.slide .alert-block > p, .alert-block > ul {margin-bottom:0}
/*.slide .alert li {margin-top: 1em}*/
.deck .alert-block p+p {margin-top:5px}
/*.slide .alert-notice { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_notice.png); }
.slide .alert-summary  { background-image:url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_summary.png); }
.slide .alert-warning { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_warning.png); }
.slide .alert-question {background-image:url(https://hplgit.github.io/doconce/
bundled/html_images/small_gray_question.png); } */
.dotable table, .dotable th, .dotable tr, .dotable tr td {
  border: 2px solid black;
  border-collapse: collapse;
  padding: 2px;
}
</style>


<!-- Styles for table layout of slides -->
<style type="text/css">
td.padding {
  padding-top:20px;
  padding-bottom:20px;
  padding-right:50px;
  padding-left:50px;
}
</style>

</head>


<body>
<div class="reveal">
<div class="slides">





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




<section>
<!-- ------------------- main content ---------------------- -->
<center>
<h1 style="text-align: center;">Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> 
</center>
<!-- institution -->
<center>
<b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<br>
<center>
<h4>April 9, 2024</h4>
</center> <!-- date -->
<br>


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</section>

<section>
<h2 id="plans-for-the-week-april-8-12-2024">Plans for the week April 8-12, 2024  </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Generative methods, energy models and Boltzmann machines</b>
<p>
<ol>
<p><li> Summary of discussions on Restricted Boltzmann machines, reminder from last week</li>
<p><li> Introduction to Variational Autoencoders (VAEs)
<!-- o <a href="https://youtu.be/hEjcK0ZkuAA" target="_blank">Video of lecture</a> -->
<!-- o <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesApril9.pdf" target="_blank">Whiteboard notes</a> --></li>
</ol>
</div>
</section>

<section>
<h2 id="reading-recommendations">Reading recommendations </h2>
<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<ol>
<p><li> Boltzmann machines: Goodfellow et al chapters 18.1-18.2,  20.1-20-7; To create Boltzmann machine using Keras, see Babcock and Bali chapter 4, see <a href="https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_4/models/rbm.py" target="_blank"><tt>https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_4/models/rbm.py</tt></a></li>
<p><li> More on Boltzmann machines: see also Foster, chapter 7 on energy-based models at <a href="https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm" target="_blank"><tt>https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm</tt></a></li>
<p><li> VAEs: Goodfellow et al, for VAEs see sections 20.10-20.11</li>
</ol>
</div>
</section>

<section>
<h2 id="essential-elements-of-generative-models">Essential elements of generative models </h2>

<p>The aim of generative methods is to train a probability distribution \( p \). The methods we will focus on are:</p>
<ol>
<p><li> Energy based models, with the family of Boltzmann distributions as a typical example</li>
<p><li> Variational autoencoders, based on our discussions on autoencoders</li>
<p><li> Generative adversarial networks (GANs) and</li>
<p><li> Diffusion models</li>
</ol>
</section>

<section>
<h2 id="energy-models-reminders-from-last-two-weeks">Energy models, reminders from last two weeks </h2>

<p>During the last two weeks we defined a domain \( \boldsymbol{X} \) of stochastic variables \( \boldsymbol{X}= \{x_0,x_1, \dots , x_{n-1}\} \) with a pertinent probability distribution</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X})=\prod_{x_i\in \boldsymbol{X}}p(x_i),
$$
<p>&nbsp;<br>

<p>where we have assumed that the random varaibles \( x_i \) are all independent and identically distributed (iid).</p>

<p>We will now assume that we can defined this function in terms of optimization parameters \( \boldsymbol{\Theta} \), which could be the biases and weights of deep network, and a set of hidden variables we also assume to be random variables which also are iid. The domain of these variables is
\( \boldsymbol{H}= \{h_0,h_1, \dots , h_{m-1}\} \).
</p>
</section>

<section>
<h2 id="probability-model">Probability model </h2>

<p>We define a probability</p>
<p>&nbsp;<br>
$$
p(x_i,h_j;\boldsymbol{\Theta}) = \frac{f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>where \( f(x_i,h_j;\boldsymbol{\Theta}) \) is a function which we assume is larger or
equal than zero and obeys all properties required for a probability
distribution and \( Z(\boldsymbol{\Theta}) \) is a normalization constant. Inspired by
statistical mechanics, we call it often for the partition function.
It is defined as (assuming that we have discrete probability distributions)
</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="marginal-and-conditional-probabilities">Marginal and conditional probabilities </h2>

<p>We can in turn define the marginal probabilities</p>
<p>&nbsp;<br>
$$
p(x_i;\boldsymbol{\Theta}) = \frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>and </p>
<p>&nbsp;<br>
$$
p(h_i;\boldsymbol{\Theta}) = \frac{\sum_{x_i\in \boldsymbol{X}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="change-of-notation">Change of notation </h2>

<p><b>Note the change to a vector notation</b>. A variable like \( \boldsymbol{x} \)
represents now a specific <b>configuration</b>. We can generate an infinity
of such configurations. The final partition function is then the sum
over all such possible configurations, that is
</p>

<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>changes to</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{\boldsymbol{x}}\sum_{\boldsymbol{h}} f(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>

<p>If we have a binary set of variable \( x_i \) and \( h_j \) and \( M \) values of \( x_i \) and \( N \) values of \( h_j \) we have in total \( 2^M \) and \( 2^N \) possible \( \boldsymbol{x} \) and \( \boldsymbol{h} \) configurations, respectively.</p>

<p>We see that even for the modest binary case, we can easily approach a
number of configuration which is not possible to deal with.
</p>
</section>

<section>
<h2 id="optimization-problem">Optimization problem </h2>

<p>At the end, we are not interested in the probabilities of the hidden variables. The probability we thus want to optimize is </p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}\left(\frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}\right),
$$
<p>&nbsp;<br>

<p>which we rewrite as</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}\left(\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})\right).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="further-simplifications">Further simplifications </h2>

<p>We simplify further by rewriting it as</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>where we used \( p(x_i;\boldsymbol{\Theta}) = \sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta}) \).
The optimization problem is then
</p>
<p>&nbsp;<br>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}p(\boldsymbol{X};\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="optimizing-the-logarithm-instead">Optimizing the logarithm instead </h2>

<p>Computing the derivatives with respect to the parameters \( \boldsymbol{\Theta} \) is
easier (and equivalent) with taking the logarithm of the
probability. We will thus optimize
</p>
<p>&nbsp;<br>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}\log{p(\boldsymbol{X};\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>which leads to</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=0.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="expression-for-the-gradients">Expression for the gradients </h2>
<p>This leads to the following equation</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=\nabla_{\boldsymbol{\Theta}}\left(\sum_{x_i\in \boldsymbol{X}}\log{f(x_i;\boldsymbol{\Theta})}\right)-\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=0.
$$
<p>&nbsp;<br>

<p>The first term is called the positive phase and we assume that we have a model for the function \( f \) from which we can sample values. Below we will develop an explicit model for this.
The second term is called the negative phase and is the one which leads to more difficulties.
</p>
</section>

<section>
<h2 id="the-derivative-of-the-partition-function">The derivative of the partition function </h2>

<p>The partition function, defined above as</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>is in general the most problematic term. In principle both \( x \) and \( h \) can span large degrees of freedom, if not even infinitely many ones, and computing the partition function itself is often not desirable or even feasible. The above derivative of the partition function can however be written in terms of an expectation value which is in turn evaluated  using Monte Carlo sampling and the theory of Markov chains, popularly shortened to MCMC (or just MC$^2$).</p>
</section>

<section>
<h2 id="explicit-expression-for-the-derivative">Explicit expression for the derivative </h2>
<p>We can rewrite</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}}Z(\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>which reads in more detail</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}} \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta})   }{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>

<p>We can rewrite the function \( f \) (we have assumed that is larger or
equal than zero) as \( f=\exp{\log{f}} \). We can then reqrite the last
equation as
</p>

<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}} \nabla_{\boldsymbol{\Theta}}\exp{\log{f(x_i;\boldsymbol{\Theta})}}   }{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="final-expression">Final expression </h2>

<p>Taking the derivative gives us</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})}   }{Z(\boldsymbol{\Theta})}, 
$$
<p>&nbsp;<br>

<p>which is the expectation value of \( \log{f} \)</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\sum_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>that is</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\mathbb{E}(\log{f(x_i;\boldsymbol{\Theta})}).
$$
<p>&nbsp;<br>

<p>This quantity is evaluated using Monte Carlo sampling, with Gibbs
sampling as the standard sampling rule.  Before we discuss the
explicit algorithms, we need to remind ourselves about Markov chains
and sampling rules like the Metropolis-Hastings algorithm and Gibbs
sampling.
</p>
</section>

<section>
<h2 id="positive-and-negative-phases">Positive and negative phases </h2>
<p>As discussed earlier, the data-dependent term in the gradient is known as the positive phase
of the gradient, while the model-dependent term is known as the
negative phase of the gradient. The aim of the training is to lower
the energy of configurations that are near observed data points
(increasing their probability), and raising the energy of
configurations that are far from observed data points (decreasing
their probability).
</p>
</section>

<section>
<h2 id="gradient-examples">Gradient examples </h2>
<p>The gradient of the negative log-likelihood cost function of a Binary-Binary RBM is then</p>
<p>&nbsp;<br>
$$
\begin{align*}
	\frac{\partial \mathcal{C} (w_{ij}, a_i, b_j)}{\partial w_{ij}} =& \langle x_i h_j \rangle_{data} - \langle x_i h_j \rangle_{model} \\
	\frac{\partial \mathcal{C} (w_{ij}, a_i, b_j)}{\partial a_{ij}} =& \langle x_i \rangle_{data} - \langle x_i \rangle_{model} \\
	\frac{\partial \mathcal{C} (w_{ij}, a_i, b_j)}{\partial b_{ij}} =& \langle h_i \rangle_{data} - \langle h_i \rangle_{model}. \\
\end{align*}
$$
<p>&nbsp;<br>

<p>To get the expectation values with respect to the <em>data</em>, we set the visible units to each of the observed samples in the training data, then update the hidden units according to the conditional probability found before. We then average over all samples in the training data to calculate expectation values with respect to the data. </p>
</section>

<section>
<h2 id="kullback-leibler-relative-entropy">Kullback-Leibler relative entropy </h2>

<p>When the goal of the training is to approximate a probability
distribution, as it is in generative modeling, another relevant
measure is the <b>Kullback-Leibler divergence</b>, also known as the
relative entropy or Shannon entropy. It is a non-symmetric measure of the
dissimilarity between two probability density functions \( p \) and
\( q \). If \( p \) is the unkown probability which we approximate with \( q \),
we can measure the difference by
</p>
<p>&nbsp;<br>
$$
\begin{align*}
	\text{KL}(p||q) = \int_{-\infty}^{\infty} p (\boldsymbol{x}) \log \frac{p(\boldsymbol{x})}{q(\boldsymbol{x})}  d\boldsymbol{x}.
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="kullback-leibler-divergence">Kullback-Leibler divergence </h2>

<p>Thus, the Kullback-Leibler divergence between the distribution of the
training data \( f(\boldsymbol{x}) \) and the model distribution \( p(\boldsymbol{x}|
\boldsymbol{\Theta}) \) is
</p>

<p>&nbsp;<br>
$$
\begin{align*}
	\text{KL} (f(\boldsymbol{x})|| p(\boldsymbol{x}| \boldsymbol{\Theta})) =& \int_{-\infty}^{\infty}
	f (\boldsymbol{x}) \log \frac{f(\boldsymbol{x})}{p(\boldsymbol{x}| \boldsymbol{\Theta})} d\boldsymbol{x} \\
	=& \int_{-\infty}^{\infty} f(\boldsymbol{x}) \log f(\boldsymbol{x}) d\boldsymbol{x} - \int_{-\infty}^{\infty} f(\boldsymbol{x}) \log
	p(\boldsymbol{x}| \boldsymbol{\Theta}) d\boldsymbol{x} \\
	%=& \mathbb{E}_{f(\boldsymbol{x})} (\log f(\boldsymbol{x})) - \mathbb{E}_{f(\boldsymbol{x})} (\log p(\boldsymbol{x}| \boldsymbol{\Theta}))
	=& \langle \log f(\boldsymbol{x}) \rangle_{f(\boldsymbol{x})} - \langle \log p(\boldsymbol{x}| \boldsymbol{\Theta}) \rangle_{f(\boldsymbol{x})} \\
	=& \langle \log f(\boldsymbol{x}) \rangle_{data} + \langle E(\boldsymbol{x}) \rangle_{data} + \log Z \\
	=& \langle \log f(\boldsymbol{x}) \rangle_{data} + \mathcal{C}_{LL} .
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="maximizing-log-likelihood">Maximizing log-likelihood </h2>

<p>The first term is constant with respect to \( \boldsymbol{\Theta} \) since
\( f(\boldsymbol{x}) \) is independent of \( \boldsymbol{\Theta} \). Thus the Kullback-Leibler
Divergence is minimal when the second term is minimal. The second term
is the log-likelihood cost function, hence minimizing the
Kullback-Leibler divergence is equivalent to maximizing the
log-likelihood.
</p>

<p>To further understand generative models it is useful to study the
gradient of the cost function which is needed in order to minimize it
using methods like stochastic gradient descent. 
</p>
</section>

<section>
<h2 id="more-on-the-partition-function">More on the partition function </h2>

<p>The partition function is the generating function of
expectation values, in particular there are mathematical relationships
between expectation values and the log-partition function. In this
case we have
</p>
<p>&nbsp;<br>
$$
\begin{align*}
	\langle \frac{ \partial E(\boldsymbol{x}; \Theta_i) } { \partial \Theta_i} \rangle_{model}
	= \int p(\boldsymbol{x}| \boldsymbol{\Theta}) \frac{ \partial E(\boldsymbol{x}; \Theta_i) } { \partial \Theta_i} d\boldsymbol{x} 
	= -\frac{\partial \log Z(\Theta_i)}{ \partial  \Theta_i} .
\end{align*}
$$
<p>&nbsp;<br>

<p>Here \( \langle \cdot \rangle_{model} \) is the expectation value over the model probability distribution \( p(\boldsymbol{x}| \boldsymbol{\Theta}) \).</p>
</section>

<section>
<h2 id="setting-up-for-gradient-descent-calculations">Setting up for gradient descent calculations </h2>

<p>Using the previous relationship we can express the gradient of the cost function as</p>

<p>&nbsp;<br>
$$
\begin{align*}
	\frac{\partial \mathcal{C}_{LL}}{\partial \Theta_i}
	=& \langle \frac{ \partial E(\boldsymbol{x}; \Theta_i) } { \partial \Theta_i} \rangle_{data} + \frac{\partial \log Z(\Theta_i)}{ \partial  \Theta_i} \\
	=& \langle \frac{ \partial E(\boldsymbol{x}; \Theta_i) } { \partial \Theta_i} \rangle_{data} - \langle \frac{ \partial E(\boldsymbol{x}; \Theta_i) } { \partial \Theta_i} \rangle_{model} \\
	%=& \langle O_i(\boldsymbol{x}) \rangle_{data} - \langle O_i(\boldsymbol{x}) \rangle_{model}
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="difference-of-moments">Difference of moments </h2>

<p>This expression shows that the gradient of the log-likelihood cost
function is a <b>difference of moments</b>, with one calculated from
the data and one calculated from the model. The data-dependent term is
called the <b>positive phase</b> and the model-dependent term is
called the <b>negative phase</b> of the gradient. We see now that
minimizing the cost function results in lowering the energy of
configurations \( \boldsymbol{x} \) near points in the training data and
increasing the energy of configurations not observed in the training
data. That means we increase the model's probability of configurations
similar to those in the training data.
</p>
</section>

<section>
<h2 id="more-observations">More observations </h2>

<p>The gradient of the cost function also demonstrates why gradients of
unsupervised, generative models must be computed differently from for
those of for example FNNs. While the data-dependent expectation value
is easily calculated based on the samples \( \boldsymbol{x}_i \) in the training
data, we must sample from the model in order to generate samples from
which to caclulate the model-dependent term. We sample from the model
by using MCMC-based methods. We can not sample from the model directly
because the partition function \( Z \) is generally intractable.
</p>
</section>

<section>
<h2 id="adding-hyperparameters">Adding hyperparameters </h2>

<p>As in supervised machine learning problems, the goal is also here to
perform well on <b>unseen</b> data, that is to have good
generalization from the training data. The distribution \( f(x) \) we
approximate is not the <b>true</b> distribution we wish to estimate,
it is limited to the training data. Hence, in unsupervised training as
well it is important to prevent overfitting to the training data. Thus
it is common to add regularizers to the cost function in the same
manner as we discussed for say linear regression.
</p>
</section>

<section>
<h2 id="theory-of-variational-autoencoders">Theory of Variational Autoencoders </h2>

<p>Let us remind ourself about what an autoencoder is, see the jupyter-notebook at <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week10/ipynb/week10.ipynb" target="_blank"><tt>https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week10/ipynb/week10.ipynb</tt></a>.</p>
</section>

<section>
<h2 id="the-autoencoder-again">The Autoencoder again </h2>

<p>Autoencoders are neural networks where the outputs are its own
inputs. They are split into an <b>encoder part</b>
which maps the input \( \boldsymbol{x} \) via a function \( f(\boldsymbol{x},\boldsymbol{W}) \) (this
is the encoder part) to a <b>so-called code part</b> (or intermediate part)
with the result \( \boldsymbol{h} \)
</p>

<p>&nbsp;<br>
$$
\boldsymbol{h} = f(\boldsymbol{x},\boldsymbol{W})),
$$
<p>&nbsp;<br>

<p>where \( \boldsymbol{W} \) are the weights to be determined.  The <b>decoder</b> parts maps, via its own parameters (weights given by the matrix \( \boldsymbol{V} \) and its own biases) to 
the final ouput
</p>
<p>&nbsp;<br>
$$
\tilde{\boldsymbol{x}} = g(\boldsymbol{h},\boldsymbol{V})).
$$
<p>&nbsp;<br>

<p>The goal is to minimize the construction error, often done by optimizing the means squared error.</p>
</section>

<section>
<h2 id="schematic-image-of-an-autoencoder">Schematic image of an Autoencoder </h2>

<br/><br/>
<center>
<p><img src="figures/ae1.png" width="700" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="mathematics-of-variational-autoencoders">Mathematics of Variational Autoencoders </h2>

<p>We have defined earlier a probability (marginal) distribution with hidden variables \( \boldsymbol{h} \) and parameters \( \boldsymbol{\Theta} \) as</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x};\boldsymbol{\Theta}) = \int d\boldsymbol{h}p(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>for continuous variables \( \boldsymbol{h} \) and</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x};\boldsymbol{\Theta}) = \sum_{\boldsymbol{h}}p(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>for discrete stochastic events \( \boldsymbol{h} \). The variables \( \boldsymbol{h} \) are normally called the <b>latent variables</b> in the theory of autoencoders. We will also call then for that here.</p>
</section>

<section>
<h2 id="using-the-conditional-probability">Using the conditional probability </h2>

<p>Using the the definition of the conditional probabilities \( p(\boldsymbol{x}\vert\boldsymbol{h};\boldsymbol{\Theta}) \), \( p(\boldsymbol{h}\vert\boldsymbol{x};\boldsymbol{\Theta}) \) and 
and the prior \( p(\boldsymbol{h}) \), we can rewrite the above equation as
</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x};\boldsymbol{\Theta}) = \sum_{\boldsymbol{h}}p(\boldsymbol{x}\vert\boldsymbol{h};\boldsymbol{\Theta})p(\boldsymbol{h},
$$
<p>&nbsp;<br>

<p>which allows us to make the dependence of \( \boldsymbol{x} \) on \( \boldsymbol{h} \)
explicit by using the law of total probability. The intuition behind
this approach for finding the marginal probability for \( \boldsymbol{x} \) is to
optimize the above equations with respect to the parameters
\( \boldsymbol{\Theta} \).  This is done normally by maximizing the probability,
the so-called maximum-likelihood approach discussed earlier.
</p>
</section>

<section>
<h2 id="vaes-versus-autoencoders">VAEs versus autoencoders </h2>

<p>This trained probability is assumed to be able to produce similar
samples as the input.  In VAEs it is then common to compare via for
example the mean-squared error or the cross-entropy the predicted
values with the input values.  Compared with autoencoders, we are now
producing a probability instead of a functions which mimicks the
input.
</p>

<p>In VAEs, the choice of this output distribution is often Gaussian,
meaning that the conditional probability is
</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x}\vert\boldsymbol{h};\boldsymbol{\Theta})=N(\boldsymbol{x}\vert f(\boldsymbol{h};\boldsymbol{\Theta}), \sigma^2\times \boldsymbol{I}),
$$
<p>&nbsp;<br>

<p>with mean value given by the function \( f(\boldsymbol{h};\boldsymbol{\Theta}) \) and a
diagonal covariance matrix multiplied by a parameter \( \sigma^2 \) which
is treated as a hyperparameter.
</p>
</section>

<section>
<h2 id="gradient-descent">Gradient descent </h2>

<p>By having a Gaussian distribution, we can use gradient descent (or any
other optimization technique) to increase \( p(\boldsymbol{x};\boldsymbol{\Theta}) \) by
making \( f(\boldsymbol{h};\boldsymbol{\Theta}) \) approach \( \boldsymbol{x} \) for some \( \boldsymbol{h} \),
gradually making the training data more likely under the generative
model. The important property is simply that the marginal probability
can be computed, and it is continuous in \( \boldsymbol{\Theta} \)..
</p>
</section>

<section>
<h2 id="are-vaes-just-modified-autoencoders">Are VAEs just modified autoencoders? </h2>

<p>The mathematical basis of VAEs actually has relatively little to do
with classical autoencoders, for example the sparse autoencoders or
denoising autoencoders discussed earlier.
</p>

<p>VAEs approximately maximize the probability equation discussed
above. They are called autoencoders only because the final training
objective that derives from this setup does have an encoder and a
decoder, and resembles a traditional autoencoder. Unlike sparse
autoencoders, there are generally no tuning parameters analogous to
the sparsity penalties. And unlike sparse and denoising autoencoders,
we can sample directly from \( p(\boldsymbol{x}) \) without performing Markov
Chain Monte Carlo.
</p>
</section>

<section>
<h2 id="training-vaes">Training VAEs </h2>

<p>To solve the integral or sum for \( p(\boldsymbol{x}) \), there are two problems
that VAEs must deal with: how to define the latent variables \( \boldsymbol{h} \),
that is decide what information they represent, and how to deal with
the integral over \( \boldsymbol{h} \).  VAEs give a definite answer to both.
</p>
</section>

<section>
<h2 id="kullback-leibler-relative-entropy">Kullback-Leibler relative entropy  </h2>

<p>When the goal of the training is to approximate a probability
distribution, as it is in generative modeling, another relevant
measure is the <b>Kullback-Leibler divergence</b>, also known as the
relative entropy or Shannon entropy. It is a non-symmetric measure of the
dissimilarity between two probability density functions \( p \) and
\( q \). If \( p \) is the unkown probability which we approximate with \( q \),
we can measure the difference by
</p>
<p>&nbsp;<br>
$$
\begin{align*}
	\text{KL}(p||q) = \int_{-\infty}^{\infty} p (\boldsymbol{x}) \log \frac{p(\boldsymbol{x})}{q(\boldsymbol{x})}  d\boldsymbol{x}.
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="kullback-leibler-divergence-and-rbms">Kullback-Leibler divergence and RBMs </h2>

<p>Thus, the Kullback-Leibler divergence between the distribution of the
training data \( f(\boldsymbol{x}) \) and the model marginal distribution \( p(\boldsymbol{x};\boldsymbol{\Theta}) \) from an RBM is
</p>

<p>&nbsp;<br>
$$
\begin{align*}
	\text{KL} (f(\boldsymbol{x})|| p(\boldsymbol{x}| \boldsymbol{\Theta})) =& \int_{-\infty}^{\infty}
	f (\boldsymbol{x}) \log \frac{f(\boldsymbol{x})}{p(\boldsymbol{x}; \boldsymbol{\Theta})} d\boldsymbol{x} \\
	=& \int_{-\infty}^{\infty} f(\boldsymbol{x}) \log f(\boldsymbol{x}) d\boldsymbol{x} - \int_{-\infty}^{\infty} f(\boldsymbol{x}) \log
	p(\boldsymbol{x};\boldsymbol{\Theta}) d\boldsymbol{x} \\
	%=& \mathbb{E}_{f(\boldsymbol{x})} (\log f(\boldsymbol{x})) - \mathbb{E}_{f(\boldsymbol{x})} (\log p(\boldsymbol{x}; \boldsymbol{\Theta}))
	=& \langle \log f(\boldsymbol{x}) \rangle_{f(\boldsymbol{x})} - \langle \log p(\boldsymbol{x};\boldsymbol{\Theta}) \rangle_{f(\boldsymbol{x})} \\
	=& \langle \log f(\boldsymbol{x}) \rangle_{data} + \langle E(\boldsymbol{x}) \rangle_{data} + \log Z.
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="maximizing-log-likelihood">Maximizing log-likelihood </h2>

<p>The first term is constant with respect to \( \boldsymbol{\Theta} \) since
\( f(\boldsymbol{x}) \) is independent of \( \boldsymbol{\Theta} \). Thus the Kullback-Leibler
divergence is minimal when the second term is minimal. The second term
is the log-likelihood cost function, hence minimizing the
Kullback-Leibler divergence is equivalent to maximizing the
log-likelihood. 
</p>
</section>

<section>
<h2 id="back-to-vaes">Back to VAEs </h2>

<p>We want to train the marginal probability with some latent variables \( \boldsymbol{h} \)</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x};\boldsymbol{\Theta}) = \int d\boldsymbol{h}p(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>for the continuous version (see previous slides for the discrete variant).</p>
</section>

<section>
<h2 id="using-the-kl-divergence">Using the KL divergence </h2>

<p>In practice, for most \( \boldsymbol{h} \), \( p(\boldsymbol{x}\vert \boldsymbol{h}; \boldsymbol{\Theta}) \)
will be nearly zero, and hence contribute almost nothing to our
estimate of \( p(\boldsymbol{x}) \).
</p>

<p>The key idea behind the variational autoencoder is to attempt to
sample values of \( \boldsymbol{h} \) that are likely to have produced \( \boldsymbol{x} \),
and compute \( p(\boldsymbol{x}) \) just from those.
</p>

<p>This means that we need a new function \( Q(\boldsymbol{h}|\boldsymbol{x}) \) which can
take a value of \( \boldsymbol{x} \) and give us a distribution over \( \boldsymbol{h} \)
values that are likely to produce \( \boldsymbol{x} \).  Hopefully the space of
\( \boldsymbol{h} \) values that are likely under \( Q \) will be much smaller than
the space of all \( \boldsymbol{h} \)'s that are likely under the prior
\( p(\boldsymbol{h}) \).  This lets us, for example, compute \( E_{\boldsymbol{h}\sim
Q}p(\boldsymbol{x}\vert \boldsymbol{h}) \) relatively easily. Note that we drop
\( \boldsymbol{\Theta} \) from here and for notational simplicity.
</p>
</section>

<section>
<h2 id="kullback-leibler-again">Kullback-Leibler again </h2>

<p>However, if \( \boldsymbol{h} \) is sampled from an arbitrary distribution with
PDF \( Q(\boldsymbol{h}) \), which is not \( \mathcal{N}(0,I) \), then how does that
help us optimize \( p(\boldsymbol{x}) \)?
</p>

<p>The first thing we need to do is relate
\( E_{\boldsymbol{h}\sim Q}P(\boldsymbol{x}\vert \boldsymbol{h}) \) and \( p(\boldsymbol{x}) \).  We will see where \( Q \) comes from later.
</p>

<p>The relationship between \( E_{\boldsymbol{h}\sim Q}p(\boldsymbol{x}\vert \boldsymbol{h}) \) and \( p(\boldsymbol{x}) \) is one of the cornerstones of variational Bayesian methods.
We begin with the definition of Kullback-Leibler divergence (KL divergence or \( \mathcal{D} \)) between \( p(\boldsymbol{h}\vert \boldsymbol{x}) \) and \( Q(\boldsymbol{h}) \), for some arbitrary \( Q \) (which may or may not depend on \( \boldsymbol{x} \)):
</p>
<p>&nbsp;<br>
$$
    \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}|\boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h}) - \log p(\boldsymbol{h}|\boldsymbol{x}) \right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="and-applying-bayes-rule">And applying Bayes rule </h2>

<p>We can get both \( p(\boldsymbol{x}) \) and \( p(\boldsymbol{x}\vert \boldsymbol{h}) \) into this equation by applying Bayes rule to \( p(\boldsymbol{h}|\boldsymbol{x}) \)</p>
<p>&nbsp;<br>
$$
    \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}\vert \boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h}) - \log p(\boldsymbol{x}|\boldsymbol{h}) - \log p(\boldsymbol{h}) \right] + \log p(\boldsymbol{x}).
$$
<p>&nbsp;<br>

<p>Here, \( \log p(\boldsymbol{x}) \) comes out of the expectation because it does not depend on \( \boldsymbol{h} \).
Negating both sides, rearranging, and contracting part of \( E_{\boldsymbol{h}\sim Q} \) into a KL-divergence terms yields:
</p>
<p>&nbsp;<br>
$$
\log p(\boldsymbol{x}) - \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}\vert \boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{x}\vert\boldsymbol{h})  \right] - \mathcal{D}\left[Q(\boldsymbol{h})\|P(\boldsymbol{h})\right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="rearranging">Rearranging </h2>

<p>Using Bayes rule we obtain</p>
<p>&nbsp;<br>
$$
E_{\boldsymbol{h}\sim Q}\left[\log p(y_i|\boldsymbol{h},x_i)\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{h}|y_i,x_i) - \log p(\boldsymbol{h}|x_i) + \log p(y_i|x_i) \right]
$$
<p>&nbsp;<br>

<p>Rearranging the terms and subtracting \( E_{\boldsymbol{h}\sim Q}\log Q(\boldsymbol{h}) \) from both sides gives</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
\log P(y_i|x_i) - E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h})-\log p(\boldsymbol{h}|x_i,y_i)\right]=\hspace{10em}\\
\hspace{10em}E_{\boldsymbol{h}\sim Q}\left[\log p(y_i|\boldsymbol{h},x_i)+\log p(\boldsymbol{h}|x_i)-\log Q(\boldsymbol{h})\right]
\end{array}
$$
<p>&nbsp;<br>

<p>Note that \( \boldsymbol{x} \) is fixed, and \( Q \) can be \textit{any} distribution, not
just a distribution which does a good job mapping \( \boldsymbol{x} \) to the \( \boldsymbol{h} \)'s
that can produce \( X \).
</p>
</section>

<section>
<h2 id="inferring-the-probability">Inferring the probability </h2>

<p>Since we are interested in inferring \( p(\boldsymbol{x}) \), it makes sense to
construct a \( Q \) which \textit{does} depend on \( \boldsymbol{x} \), and in particular,
one which makes \( \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}|\boldsymbol{x})\right] \) small
</p>
<p>&nbsp;<br>
$$
\log p(\boldsymbol{x}) - \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h}|\boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{x}|\boldsymbol{h})  \right] - \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h})\right].
$$
<p>&nbsp;<br>

<p>Hence, during training, it makes sense to choose a \( Q \) which will make
\( E_{\boldsymbol{h}\sim Q}[\log Q(\boldsymbol{h})- \) $\log p(\boldsymbol{h}|x_i,y_i)]$ (a
\( \mathcal{D} \)-divergence) small, such that the right hand side is a
close approximation to \( \log p(y_i|y_i) \).
</p>
</section>

<section>
<h2 id="central-equation-of-vaes">Central equation of VAEs </h2>

<p>This equation serves as the core of the variational autoencoder, and
it is worth spending some time thinking about what it means.
</p>

<ol>
<p><li> The left hand side has the quantity we want to maximize, namely \( \log p(\boldsymbol{x}) \) plus an error term.</li>
<p><li> The right hand side is something we can optimize via stochastic gradient descent given the right choice of \( Q \).</li>
</ol>
</section>

<section>
<h2 id="setting-up-sgd">Setting up SGD </h2>
<p>So how can we perform stochastic gradient descent?</p>

<p>First we need to be a bit more specific about the form that \( Q(\boldsymbol{h}|\boldsymbol{x}) \)
will take.  The usual choice is to say that
\( Q(\boldsymbol{h}|\boldsymbol{x})=\mathcal{N}(\boldsymbol{h}|\mu(\boldsymbol{x};\vartheta),\Sigma(;\vartheta)) \), where
\( \mu \) and \( \Sigma \) are arbitrary deterministic functions with
parameters \( \vartheta \) that can be learned from data (we will omit
\( \vartheta \) in later equations).  In practice, \( \mu \) and \( \Sigma \) are
again implemented via neural networks, and \( \Sigma \) is constrained to
be a diagonal matrix.
</p>
</section>

<section>
<h2 id="more-on-the-sgd">More on the SGD </h2>

<p>The name variational &quot;autoencoder&quot; comes from
the fact that \( \mu \) and \( \Sigma \) are &quot;encoding&quot; \( \boldsymbol{x} \) into the latent
space \( \boldsymbol{h} \).  The advantages of this choice are computational, as they
make it clear how to compute the right hand side.  The last
term---\( \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h})\right] \)---is now a KL-divergence
between two multivariate Gaussian distributions, which can be computed
in closed form as:
</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu_0,\Sigma_0) \| \mathcal{N}(\mu_1,\Sigma_1)] = \hspace{20em}\\
  \hspace{5em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma_1^{-1} \Sigma_0 \right) + \left( \mu_1 - \mu_0\right)^\top \Sigma_1^{-1} ( \mu_1 - \mu_0 ) - k + \log \left( \frac{ \det \Sigma_1 }{ \det \Sigma_0  } \right)  \right)
\end{array}
$$
<p>&nbsp;<br>

<p>where \( k \) is the dimensionality of the distribution.</p>
</section>

<section>
<h2 id="simplification">Simplification </h2>
<p>In our case, this simplifies to:</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu(X),\Sigma(X)) \| \mathcal{N}(0,I)] = \hspace{20em}\\
\hspace{6em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma(X) \right) + \left( \mu(X)\right)^\top ( \mu(X) ) - k - \log\det\left(  \Sigma(X)  \right)  \right).
\end{array}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="terms-to-compute">Terms to compute </h2>

<p>The first term on the right hand side is a bit more tricky.
We could use sampling to estimate \( E_{z\sim Q}\left[\log P(X|z)  \right] \), but getting a good estimate would require passing many samples of \( z \) through \( f \), which would be expensive.
Hence, as is standard in stochastic gradient descent, we take one sample of \( z \) and treat \( \log P(X|z) \) for that \( z \) as an approximation of \( E_{z\sim Q}\left[\log P(X|z)  \right] \).
After all, we are already doing stochastic gradient descent over different values of \( X \) sampled from a dataset \( D \).
The full equation we want to optimize is:
</p>

<p>&nbsp;<br>
$$
\begin{array}{c}
    E_{X\sim D}\left[\log P(X) - \mathcal{D}\left[Q(z|X)\|P(z|X)\right]\right]=\hspace{16em}\\
\hspace{10em}E_{X\sim D}\left[E_{z\sim Q}\left[\log P(X|z)  \right] - \mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
\end{array}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="computing-the-gradients">Computing the gradients </h2>

<p>If we take the gradient of this equation, the gradient symbol can be moved into the expectations.
Therefore, we can sample a single value of \( X \) and a single value of \( z \) from the distribution \( Q(z|X) \), and compute the gradient of:
</p>
<p>&nbsp;<br>
$$
\begin{equation}
 \log P(X|z)-\mathcal{D}\left[Q(z|X)\|P(z)\right].
\tag{1}
\end{equation}
$$
<p>&nbsp;<br>

<p>We can then average the gradient of this function over arbitrarily many samples of \( X \) and \( z \), and the result converges to the gradient.</p>

<p>There is, however, a significant problem
\( E_{z\sim Q}\left[\log P(X|z)  \right] \) depends not just on the parameters of \( P \), but also on the parameters of \( Q \).
</p>

<p>In order to make VAEs work, it is essential to drive \( Q \) to produce codes for \( X \) that \( P \) can reliably decode.  </p>
<p>&nbsp;<br>
$$
 E_{X\sim D}\left[E_{\epsilon\sim\mathcal{N}(0,I)}[\log P(X|z=\mu(X)+\Sigma^{1/2}(X)*\epsilon)]-\mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="motivation-from-kingma-and-welling-an-introduction-to-variational-autoencoders-url-https-arxiv-org-abs-1906-02691">Motivation from Kingma and Welling, An Introduction to Variational Autoencoders, <a href="https://arxiv.org/abs/1906.02691" target="_blank"><tt>https://arxiv.org/abs/1906.02691</tt></a> </h2>

<p><em>There are many reasons why generative modeling is attractive. First,
we can express physical laws and constraints into the generative
process while details that we don&#8217;t know or care about, i.e. nuisance
variables, are treated as noise. The resulting models are usually
highly intuitive and interpretable and by testing them against
observations we can confirm or reject our theories about how the world
works.  Another reason for trying to understand the generative process
of data is that it naturally expresses causal relations of the
world. Causal relations have the great advantage that they generalize
much better to new situations than mere correlations. For instance,
once we understand the generative process of an earthquake, we can use
that knowledge both in California and in Chile.</em>
</p>
</section>

<section>
<h2 id="mathematics-of-vaes">Mathematics of  VAEs </h2>

<p>We want to train the marginal probability with some latent varrables \( \boldsymbol{h} \)</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{x};\boldsymbol{\Theta}) = \int d\boldsymbol{h}p(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>for the continuous version (see previous slides for the discrete variant).</p>
</section>

<section>
<h2 id="using-the-kl-divergence">Using the KL divergence </h2>

<p>In practice, for most \( \boldsymbol{h} \), \( p(\boldsymbol{x}\vert \boldsymbol{h}; \boldsymbol{\Theta}) \)
will be nearly zero, and hence contributes almost nothing to our
estimate of \( p(\boldsymbol{x}) \).
</p>

<p>The key idea behind the variational autoencoder is to attempt to
sample values of \( \boldsymbol{h} \) that are likely to have produced \( \boldsymbol{x} \),
and compute \( p(\boldsymbol{x}) \) just from those.
</p>

<p>This means that we need a new function \( Q(\boldsymbol{h}|\boldsymbol{x}) \) which can
take a value of \( \boldsymbol{x} \) and give us a distribution over \( \boldsymbol{h} \)
values that are likely to produce \( \boldsymbol{x} \).  Hopefully the space of
\( \boldsymbol{h} \) values that are likely under \( Q \) will be much smaller than
the space of all \( \boldsymbol{h} \)'s that are likely under the prior
\( p(\boldsymbol{h}) \).  This lets us, for example, compute \( E_{\boldsymbol{h}\sim
Q}p(\boldsymbol{x}\vert \boldsymbol{h}) \) relatively easily. Note that we drop
\( \boldsymbol{\Theta} \) from here and for notational simplicity.
</p>
</section>

<section>
<h2 id="kullback-leibler-again">Kullback-Leibler again </h2>

<p>However, if \( \boldsymbol{h} \) is sampled from an arbitrary distribution with
PDF \( Q(\boldsymbol{h}) \), which is not \( \mathcal{N}(0,I) \), then how does that
help us optimize \( p(\boldsymbol{x}) \)?
</p>

<p>The first thing we need to do is relate
\( E_{\boldsymbol{h}\sim Q}P(\boldsymbol{x}\vert \boldsymbol{h}) \) and \( p(\boldsymbol{x}) \).  We will see where \( Q \) comes from later.
</p>

<p>The relationship between \( E_{\boldsymbol{h}\sim Q}p(\boldsymbol{x}\vert \boldsymbol{h}) \) and \( p(\boldsymbol{x}) \) is one of the cornerstones of variational Bayesian methods.
We begin with the definition of Kullback-Leibler divergence (KL divergence or \( \mathcal{D} \)) between \( p(\boldsymbol{h}\vert \boldsymbol{x}) \) and \( Q(\boldsymbol{h}) \), for some arbitrary \( Q \) (which may or may not depend on \( \boldsymbol{x} \)):
</p>
<p>&nbsp;<br>
$$
    \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}|\boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h}) - \log p(\boldsymbol{h}|\boldsymbol{x}) \right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="and-applying-bayes-rule">And applying Bayes rule </h2>

<p>We can get both \( p(\boldsymbol{x}) \) and \( p(\boldsymbol{x}\vert \boldsymbol{h}) \) into this equation by applying Bayes rule to \( p(\boldsymbol{h}|\boldsymbol{x}) \)</p>
<p>&nbsp;<br>
$$
    \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}\vert \boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h}) - \log p(\boldsymbol{x}|\boldsymbol{h}) - \log p(\boldsymbol{h}) \right] + \log p(\boldsymbol{x}).
$$
<p>&nbsp;<br>

<p>Here, \( \log p(\boldsymbol{x}) \) comes out of the expectation because it does not depend on \( \boldsymbol{h} \).
Negating both sides, rearranging, and contracting part of \( E_{\boldsymbol{h}\sim Q} \) into a KL-divergence terms yields:
</p>
<p>&nbsp;<br>
$$
\log p(\boldsymbol{x}) - \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}\vert \boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{x}\vert\boldsymbol{h})  \right] - \mathcal{D}\left[Q(\boldsymbol{h})\|P(\boldsymbol{h})\right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="rearranging">Rearranging </h2>

<p>Using Bayes rule we obtain</p>
<p>&nbsp;<br>
$$
E_{\boldsymbol{h}\sim Q}\left[\log p(y_i|\boldsymbol{h},x_i)\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{h}|y_i,x_i) - \log p(\boldsymbol{h}|x_i) + \log p(y_i|x_i) \right]
$$
<p>&nbsp;<br>

<p>Rearranging the terms and subtracting \( E_{\boldsymbol{h}\sim Q}\log Q(\boldsymbol{h}) \) from both sides gives</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
\log P(y_i|x_i) - E_{\boldsymbol{h}\sim Q}\left[\log Q(\boldsymbol{h})-\log p(\boldsymbol{h}|x_i,y_i)\right]=\hspace{10em}\\
\hspace{10em}E_{\boldsymbol{h}\sim Q}\left[\log p(y_i|\boldsymbol{h},x_i)+\log p(\boldsymbol{h}|x_i)-\log Q(\boldsymbol{h})\right]
\end{array}
$$
<p>&nbsp;<br>

<p>Note that \( \boldsymbol{x} \) is fixed, and \( Q \) can be \textit{any} distribution, not
just a distribution which does a good job mapping \( \boldsymbol{x} \) to the \( \boldsymbol{h} \)'s
that can produce \( X \).
</p>
</section>

<section>
<h2 id="inferring-the-probability">Inferring the probability </h2>

<p>Since we are interested in inferring \( p(\boldsymbol{x}) \), it makes sense to
construct a \( Q \) which \textit{does} depend on \( \boldsymbol{x} \), and in particular,
one which makes \( \mathcal{D}\left[Q(\boldsymbol{h})\|p(\boldsymbol{h}|\boldsymbol{x})\right] \) small
</p>
<p>&nbsp;<br>
$$
\log p(\boldsymbol{x}) - \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h}|\boldsymbol{x})\right]=E_{\boldsymbol{h}\sim Q}\left[\log p(\boldsymbol{x}|\boldsymbol{h})  \right] - \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h})\right].
$$
<p>&nbsp;<br>

<p>Hence, during training, it makes sense to choose a \( Q \) which will make
\( E_{\boldsymbol{h}\sim Q}[\log Q(\boldsymbol{h})- \) $\log p(\boldsymbol{h}|x_i,y_i)]$ (a
\( \mathcal{D} \)-divergence) small, such that the right hand side is a
close approximation to \( \log p(y_i|y_i) \).
</p>
</section>

<section>
<h2 id="central-equation-of-vaes">Central equation of VAEs </h2>

<p>This equation serves as the core of the variational autoencoder, and
it is worth spending some time thinking about what it means.
</p>

<ol>
<p><li> The left hand side has the quantity we want to maximize, namely \( \log p(\boldsymbol{x}) \) plus an error term.</li>
<p><li> The right hand side is something we can optimize via stochastic gradient descent given the right choice of \( Q \).</li>
</ol>
</section>

<section>
<h2 id="setting-up-sgd">Setting up SGD </h2>
<p>So how can we perform stochastic gradient descent?</p>

<p>First we need to be a bit more specific about the form that \( Q(\boldsymbol{h}|\boldsymbol{x}) \)
will take.  The usual choice is to say that
\( Q(\boldsymbol{h}|\boldsymbol{x})=\mathcal{N}(\boldsymbol{h}|\mu(\boldsymbol{x};\vartheta),\Sigma(;\vartheta)) \), where
\( \mu \) and \( \Sigma \) are arbitrary deterministic functions with
parameters \( \vartheta \) that can be learned from data (we will omit
\( \vartheta \) in later equations).  In practice, \( \mu \) and \( \Sigma \) are
again implemented via neural networks, and \( \Sigma \) is constrained to
be a diagonal matrix.
</p>
</section>

<section>
<h2 id="more-on-the-sgd">More on the SGD </h2>

<p>The name variational &quot;autoencoder&quot; comes from
the fact that \( \mu \) and \( \Sigma \) are &quot;encoding&quot; \( \boldsymbol{x} \) into the latent
space \( \boldsymbol{h} \).  The advantages of this choice are computational, as they
make it clear how to compute the right hand side.  The last
term---\( \mathcal{D}\left[Q(\boldsymbol{h}|\boldsymbol{x})\|p(\boldsymbol{h})\right] \)---is now a KL-divergence
between two multivariate Gaussian distributions, which can be computed
in closed form as:
</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu_0,\Sigma_0) \| \mathcal{N}(\mu_1,\Sigma_1)] = \hspace{20em}\\
  \hspace{5em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma_1^{-1} \Sigma_0 \right) + \left( \mu_1 - \mu_0\right)^\top \Sigma_1^{-1} ( \mu_1 - \mu_0 ) - k + \log \left( \frac{ \det \Sigma_1 }{ \det \Sigma_0  } \right)  \right)
\end{array}
$$
<p>&nbsp;<br>

<p>where \( k \) is the dimensionality of the distribution.</p>
</section>

<section>
<h2 id="simplification">Simplification </h2>
<p>In our case, this simplifies to:</p>
<p>&nbsp;<br>
$$
\begin{array}{c}
 \mathcal{D}[\mathcal{N}(\mu(X),\Sigma(X)) \| \mathcal{N}(0,I)] = \hspace{20em}\\
\hspace{6em}\frac{ 1 }{ 2 } \left( \mathrm{tr} \left( \Sigma(X) \right) + \left( \mu(X)\right)^\top ( \mu(X) ) - k - \log\det\left(  \Sigma(X)  \right)  \right).
\end{array}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="terms-to-compute">Terms to compute </h2>

<p>The first term on the right hand side is a bit more tricky.
We could use sampling to estimate \( E_{z\sim Q}\left[\log P(X|z)  \right] \), but getting a good estimate would require passing many samples of \( z \) through \( f \), which would be expensive.
Hence, as is standard in stochastic gradient descent, we take one sample of \( z \) and treat \( \log P(X|z) \) for that \( z \) as an approximation of \( E_{z\sim Q}\left[\log P(X|z)  \right] \).
After all, we are already doing stochastic gradient descent over different values of \( X \) sampled from a dataset \( D \).
The full equation we want to optimize is:
</p>

<p>&nbsp;<br>
$$
\begin{array}{c}
    E_{X\sim D}\left[\log P(X) - \mathcal{D}\left[Q(z|X)\|P(z|X)\right]\right]=\hspace{16em}\\
\hspace{10em}E_{X\sim D}\left[E_{z\sim Q}\left[\log P(X|z)  \right] - \mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
\end{array}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="computing-the-gradients">Computing the gradients </h2>

<p>If we take the gradient of this equation, the gradient symbol can be moved into the expectations.
Therefore, we can sample a single value of \( X \) and a single value of \( z \) from the distribution \( Q(z|X) \), and compute the gradient of:
</p>
<p>&nbsp;<br>
$$
\begin{equation}
 \log P(X|z)-\mathcal{D}\left[Q(z|X)\|P(z)\right].
\tag{2}
\end{equation}
$$
<p>&nbsp;<br>

<p>We can then average the gradient of this function over arbitrarily many samples of \( X \) and \( z \), and the result converges to the gradient.</p>

<p>There is, however, a significant problem
\( E_{z\sim Q}\left[\log P(X|z)  \right] \) depends not just on the parameters of \( P \), but also on the parameters of \( Q \).
</p>

<p>In order to make VAEs work, it is essential to drive \( Q \) to produce codes for \( X \) that \( P \) can reliably decode.  </p>
<p>&nbsp;<br>
$$
 E_{X\sim D}\left[E_{\epsilon\sim\mathcal{N}(0,I)}[\log P(X|z=\mu(X)+\Sigma^{1/2}(X)*\epsilon)]-\mathcal{D}\left[Q(z|X)\|P(z)\right]\right].
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="code-examples-using-keras">Code examples using Keras </h2>

<p>Code taken from  <a href="https://keras.io/examples/generative/vae/" target="_blank"><tt>https://keras.io/examples/generative/vae/</tt></a></p>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">Title: Variational AutoEncoder</span>
<span style="color: #CD5555">Author: [fchollet](https://twitter.com/fchollet)</span>
<span style="color: #CD5555">Date created: 2020/05/03</span>
<span style="color: #CD5555">Last modified: 2023/11/22</span>
<span style="color: #CD5555">Description: Convolutional Variational AutoEncoder (VAE) trained on MNIST digits.</span>
<span style="color: #CD5555">Accelerator: GPU</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Setup</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">os</span>

os.environ[<span style="color: #CD5555">&quot;KERAS_BACKEND&quot;</span>] = <span style="color: #CD5555">&quot;tensorflow&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">tensorflow</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">tf</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">keras</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">keras</span> <span style="color: #8B008B; font-weight: bold">import</span> layers

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Create a sampling layer</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Sampling</span>(layers.Layer):
    <span style="color: #CD5555">&quot;&quot;&quot;Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.&quot;&quot;&quot;</span>

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">call</span>(<span style="color: #658b00">self</span>, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[<span style="color: #B452CD">0</span>]
        dim = tf.shape(z_mean)[<span style="color: #B452CD">1</span>]
        epsilon = tf.random.normal(shape=(batch, dim))
        <span style="color: #8B008B; font-weight: bold">return</span> z_mean + tf.exp(<span style="color: #B452CD">0.5</span> * z_log_var) * epsilon


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the encoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_dim = <span style="color: #B452CD">2</span>

encoder_inputs = keras.Input(shape=(<span style="color: #B452CD">28</span>, <span style="color: #B452CD">28</span>, <span style="color: #B452CD">1</span>))
x = layers.Conv2D(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(encoder_inputs)
x = layers.Conv2D(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Flatten()(x)
x = layers.Dense(<span style="color: #B452CD">16</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(x)
z_mean = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_mean&quot;</span>)(x)
z_log_var = layers.Dense(latent_dim, name=<span style="color: #CD5555">&quot;z_log_var&quot;</span>)(x)
z = Sampling()([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=<span style="color: #CD5555">&quot;encoder&quot;</span>)
encoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Build the decoder</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(<span style="color: #B452CD">7</span> * <span style="color: #B452CD">7</span> * <span style="color: #B452CD">64</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>)(latent_inputs)
x = layers.Reshape((<span style="color: #B452CD">7</span>, <span style="color: #B452CD">7</span>, <span style="color: #B452CD">64</span>))(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
x = layers.Conv2DTranspose(<span style="color: #B452CD">32</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;relu&quot;</span>, strides=<span style="color: #B452CD">2</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder_outputs = layers.Conv2DTranspose(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">3</span>, activation=<span style="color: #CD5555">&quot;sigmoid&quot;</span>, padding=<span style="color: #CD5555">&quot;same&quot;</span>)(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name=<span style="color: #CD5555">&quot;decoder&quot;</span>)
decoder.summary()

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Define the VAE as a `Model` with a custom `train_step`</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(keras.Model):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder, **kwargs):
        <span style="color: #658b00">super</span>().<span style="color: #008b45">__init__</span>(**kwargs)
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder
        <span style="color: #658b00">self</span>.total_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;total_loss&quot;</span>)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker = keras.metrics.Mean(
            name=<span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>
        )
        <span style="color: #658b00">self</span>.kl_loss_tracker = keras.metrics.Mean(name=<span style="color: #CD5555">&quot;kl_loss&quot;</span>)

    <span style="color: #707a7c">@property</span>
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">metrics</span>(<span style="color: #658b00">self</span>):
        <span style="color: #8B008B; font-weight: bold">return</span> [
            <span style="color: #658b00">self</span>.total_loss_tracker,
            <span style="color: #658b00">self</span>.reconstruction_loss_tracker,
            <span style="color: #658b00">self</span>.kl_loss_tracker,
        ]

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">train_step</span>(<span style="color: #658b00">self</span>, data):
        <span style="color: #8B008B; font-weight: bold">with</span> tf.GradientTape() <span style="color: #8B008B; font-weight: bold">as</span> tape:
            z_mean, z_log_var, z = <span style="color: #658b00">self</span>.encoder(data)
            reconstruction = <span style="color: #658b00">self</span>.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction),
                    axis=(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>),
                )
            )
            kl_loss = -<span style="color: #B452CD">0.5</span> * (<span style="color: #B452CD">1</span> + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=<span style="color: #B452CD">1</span>))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, <span style="color: #658b00">self</span>.trainable_weights)
        <span style="color: #658b00">self</span>.optimizer.apply_gradients(<span style="color: #658b00">zip</span>(grads, <span style="color: #658b00">self</span>.trainable_weights))
        <span style="color: #658b00">self</span>.total_loss_tracker.update_state(total_loss)
        <span style="color: #658b00">self</span>.reconstruction_loss_tracker.update_state(reconstruction_loss)
        <span style="color: #658b00">self</span>.kl_loss_tracker.update_state(kl_loss)
        <span style="color: #8B008B; font-weight: bold">return</span> {
            <span style="color: #CD5555">&quot;loss&quot;</span>: <span style="color: #658b00">self</span>.total_loss_tracker.result(),
            <span style="color: #CD5555">&quot;reconstruction_loss&quot;</span>: <span style="color: #658b00">self</span>.reconstruction_loss_tracker.result(),
            <span style="color: #CD5555">&quot;kl_loss&quot;</span>: <span style="color: #658b00">self</span>.kl_loss_tracker.result(),
        }


<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Train the VAE</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()
mnist_digits = np.concatenate([x_train, x_test], axis=<span style="color: #B452CD">0</span>)
mnist_digits = np.expand_dims(mnist_digits, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
vae.fit(mnist_digits, epochs=<span style="color: #B452CD">30</span>, batch_size=<span style="color: #B452CD">128</span>)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display a grid of sampled digits</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_latent_space</span>(vae, n=<span style="color: #B452CD">30</span>, figsize=<span style="color: #B452CD">15</span>):
    <span style="color: #228B22"># display a n*n 2D manifold of digits</span>
    digit_size = <span style="color: #B452CD">28</span>
    scale = <span style="color: #B452CD">1.0</span>
    figure = np.zeros((digit_size * n, digit_size * n))
    <span style="color: #228B22"># linearly spaced coordinates corresponding to the 2D plot</span>
    <span style="color: #228B22"># of digit classes in the latent space</span>
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-<span style="color: #B452CD">1</span>]

    <span style="color: #8B008B; font-weight: bold">for</span> i, yi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_y):
        <span style="color: #8B008B; font-weight: bold">for</span> j, xi <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample, verbose=<span style="color: #B452CD">0</span>)
            digit = x_decoded[<span style="color: #B452CD">0</span>].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + <span style="color: #B452CD">1</span>) * digit_size,
                j * digit_size : (j + <span style="color: #B452CD">1</span>) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // <span style="color: #B452CD">2</span>
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, <span style="color: #B452CD">1</span>)
    sample_range_y = np.round(grid_y, <span style="color: #B452CD">1</span>)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.imshow(figure, cmap=<span style="color: #CD5555">&quot;Greys_r&quot;</span>)
    plt.show()


plot_latent_space(vae)

<span style="color: #CD5555">&quot;&quot;&quot;</span>
<span style="color: #CD5555">## Display how the latent space clusters different digit classes</span>
<span style="color: #CD5555">&quot;&quot;&quot;</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">plot_label_clusters</span>(vae, data, labels):
    <span style="color: #228B22"># display a 2D plot of the digit classes in the latent space</span>
    z_mean, _, _ = vae.encoder.predict(data, verbose=<span style="color: #B452CD">0</span>)
    plt.figure(figsize=(<span style="color: #B452CD">12</span>, <span style="color: #B452CD">10</span>))
    plt.scatter(z_mean[:, <span style="color: #B452CD">0</span>], z_mean[:, <span style="color: #B452CD">1</span>], c=labels)
    plt.colorbar()
    plt.xlabel(<span style="color: #CD5555">&quot;z[0]&quot;</span>)
    plt.ylabel(<span style="color: #CD5555">&quot;z[1]&quot;</span>)
    plt.show()


(x_train, y_train), _ = keras.datasets.mnist.load_data()
x_train = np.expand_dims(x_train, -<span style="color: #B452CD">1</span>).astype(<span style="color: #CD5555">&quot;float32&quot;</span>) / <span style="color: #B452CD">255</span>

plot_label_clusters(vae, x_train, y_train)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="code-in-pytorch-for-vaes">Code in PyTorch for VAEs </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch.autograd</span> <span style="color: #8B008B; font-weight: bold">import</span> Variable
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn.functional</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">F</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torchvision</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> <span style="color: #8B008B; font-weight: bold">import</span> transforms
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.optim</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">optim</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> nn
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch</span> <span style="color: #8B008B; font-weight: bold">import</span> distributions

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Encoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, latent_size):
        <span style="color: #658b00">super</span>(Encoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, H)
        <span style="color: #658b00">self</span>.enc_mu = torch.nn.Linear(H, latent_size)
        <span style="color: #658b00">self</span>.enc_log_sigma = torch.nn.Linear(H, latent_size)

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        x = F.relu(<span style="color: #658b00">self</span>.linear2(x))
        mu = <span style="color: #658b00">self</span>.enc_mu(x)
        log_sigma = <span style="color: #658b00">self</span>.enc_log_sigma(x)
        sigma = torch.exp(log_sigma)
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(loc=mu, scale=sigma)


<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">Decoder</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, D_in, H, D_out):
        <span style="color: #658b00">super</span>(Decoder, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.linear1 = torch.nn.Linear(D_in, H)
        <span style="color: #658b00">self</span>.linear2 = torch.nn.Linear(H, D_out)
        

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x):
        x = F.relu(<span style="color: #658b00">self</span>.linear1(x))
        mu = torch.tanh(<span style="color: #658b00">self</span>.linear2(x))
        <span style="color: #8B008B; font-weight: bold">return</span> torch.distributions.Normal(mu, torch.ones_like(mu))

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">VAE</span>(torch.nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, encoder, decoder):
        <span style="color: #658b00">super</span>(VAE, <span style="color: #658b00">self</span>).<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.encoder = encoder
        <span style="color: #658b00">self</span>.decoder = decoder

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, state):
        q_z = <span style="color: #658b00">self</span>.encoder(state)
        z = q_z.rsample()
        <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #658b00">self</span>.decoder(z), q_z


transform = transforms.Compose(
    [transforms.ToTensor(),
     <span style="color: #228B22"># Normalize the images to be -0.5, 0.5</span>
     transforms.Normalize(<span style="color: #B452CD">0.5</span>, <span style="color: #B452CD">1</span>)]
    )
mnist = torchvision.datasets.MNIST(<span style="color: #CD5555">&#39;./&#39;</span>, download=<span style="color: #8B008B; font-weight: bold">True</span>, transform=transform)

input_dim = <span style="color: #B452CD">28</span> * <span style="color: #B452CD">28</span>
batch_size = <span style="color: #B452CD">128</span>
num_epochs = <span style="color: #B452CD">100</span>
learning_rate = <span style="color: #B452CD">0.001</span>
hidden_size = <span style="color: #B452CD">512</span>
latent_size = <span style="color: #B452CD">8</span>

<span style="color: #8B008B; font-weight: bold">if</span> torch.cuda.is_available():
    device = torch.device(<span style="color: #CD5555">&#39;cuda&#39;</span>)
<span style="color: #8B008B; font-weight: bold">else</span>:
    device = torch.device(<span style="color: #CD5555">&#39;cpu&#39;</span>)

dataloader = torch.utils.data.DataLoader(
    mnist, batch_size=batch_size,
    shuffle=<span style="color: #8B008B; font-weight: bold">True</span>, 
    pin_memory=torch.cuda.is_available())

<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Number of samples: &#39;</span>, <span style="color: #658b00">len</span>(mnist))

encoder = Encoder(input_dim, hidden_size, latent_size)
decoder = Decoder(latent_size, hidden_size, input_dim)

vae = VAE(encoder, decoder).to(device)

optimizer = optim.Adam(vae.parameters(), lr=learning_rate)
<span style="color: #8B008B; font-weight: bold">for</span> epoch <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(num_epochs):
    <span style="color: #8B008B; font-weight: bold">for</span> data <span style="color: #8B008B">in</span> dataloader:
        inputs, _ = data
        inputs = inputs.view(-<span style="color: #B452CD">1</span>, input_dim).to(device)
        optimizer.zero_grad()
        p_x, q_z = vae(inputs)
        log_likelihood = p_x.log_prob(inputs).sum(-<span style="color: #B452CD">1</span>).mean()
        kl = torch.distributions.kl_divergence(
            q_z, 
            torch.distributions.Normal(<span style="color: #B452CD">0</span>, <span style="color: #B452CD">1.</span>)
        ).sum(-<span style="color: #B452CD">1</span>).mean()
        loss = -(log_likelihood - kl)
        loss.backward()
        optimizer.step()
        l = loss.item()
    <span style="color: #658b00">print</span>(epoch, l, log_likelihood.item(), kl.item())
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>



</div> <!-- class="slides" -->
</div> <!-- class="reveal" -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

  // Display navigation controls in the bottom right corner
  controls: true,

  // Display progress bar (below the horiz. slider)
  progress: true,

  // Display the page number of the current slide
  slideNumber: true,

  // Push each slide change to the browser history
  history: false,

  // Enable keyboard shortcuts for navigation
  keyboard: true,

  // Enable the slide overview mode
  overview: true,

  // Vertical centering of slides
  //center: true,
  center: false,

  // Enables touch navigation on devices with touch input
  touch: true,

  // Loop the presentation
  loop: false,

  // Change the presentation direction to be RTL
  rtl: false,

  // Turns fragments on and off globally
  fragments: true,

  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,

  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,

  // Stop auto-sliding after user input
  autoSlideStoppable: true,

  // Enable slide navigation via mouse wheel
  mouseWheel: false,

  // Hides the address bar on mobile devices
  hideAddressBar: true,

  // Opens links in an iframe preview overlay
  previewLinks: false,

  // Transition style
  transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

  // Transition speed
  transitionSpeed: 'default', // default/fast/slow

  // Transition style for full page slide backgrounds
  backgroundTransition: 'default', // default/none/slide/concave/convex/zoom

  // Number of slides away from the current that are visible
  viewDistance: 3,

  // Parallax background image
    //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

  // Parallax background size
  //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

  theme: Reveal.getQueryHash().theme, // available themes are in reveal.js/css/theme
    transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/none

});

Reveal.initialize({
  dependencies: [
      // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },

      // Interpret Markdown in <section> elements
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

      // Syntax highlight for <code> elements
      { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

      // Zoom in and out with Alt+click
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },

      // Speaker notes
      { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },

      // Remote control your reveal.js presentation using a touch device
      //{ src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } },

      // MathJax
      //{ src: 'reveal.js/plugin/math/math.js', async: true }
  ]
});

Reveal.initialize({

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 1170,  // original: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.0

});
</script>

<!-- begin footer logo
<div style="position: absolute; bottom: 0px; left: 0; margin-left: 0px">
<img src="somelogo.png">
</div>
   end footer logo -->




</body>
</html>

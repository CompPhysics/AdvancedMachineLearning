{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dbb4b5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week17.do.txt --no_mako -->\n",
    "<!-- dom:TITLE: Advanced machine learning and data analysis for the physical sciences -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a25c1f",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Advanced machine learning and data analysis for the physical sciences\n",
    "**Morten Hjorth-Jensen**, Department of Physics and Center for Computing in Science Education, University of Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **May 13, 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b0989",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Plans for the week of May 13-17, 2024\n",
    "\n",
    "**Summary of course.**\n",
    "\n",
    "We have covered \n",
    "1. Discriminative methods\n",
    "\n",
    "a. Review of neural networks\n",
    "\n",
    "b. CNNs and RNNs\n",
    "\n",
    "c. Autoencoders and Principal component analysis\n",
    "\n",
    "4. Generative methods\n",
    "\n",
    "a. Energy-based models\n",
    "\n",
    "b. Variational autoencoders\n",
    "\n",
    "c. Diffusion based models\n",
    "\n",
    "d. Generative adversarial networks\n",
    "\n",
    "5. [Video of lecture tba](https://youtu.be/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b17b39",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Types of machine learning\n",
    "\n",
    "The approaches to machine learning are many, but are often split into two main categories. \n",
    "In *supervised learning* we know the answer to a problem,\n",
    "and let the computer deduce the logic behind it. On the other hand, *unsupervised learning*\n",
    "is a method for finding patterns and relationship in data sets without any prior knowledge of the system.\n",
    "\n",
    "An emerging  third category is  *reinforcement learning*. This is a paradigm \n",
    "of learning inspired by behavioural psychology, where learning is achieved by trial-and-error, \n",
    "solely from rewards and punishment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891d38f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Main categories\n",
    "Another way to categorize machine learning tasks is to consider the desired output of a system.\n",
    "Some of the most common tasks are:\n",
    "\n",
    "  * Classification: Outputs are divided into two or more classes. The goal is to   produce a model that assigns inputs into one of these classes. An example is to identify  digits based on pictures of hand-written ones. Classification is typically supervised learning.\n",
    "\n",
    "  * Regression: Finding a functional relationship between an input data set and a reference data set.   The goal is to construct a function that maps input data to continuous output values.\n",
    "\n",
    "  * Clustering: Data are divided into groups with certain common traits, without knowing the different groups beforehand.  It is thus a form of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0fbe1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Machine learning. A simple perspective on the interface between ML and Physics\n",
    "\n",
    "<!-- dom:FIGURE: [figures/mlimage.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/mlimage.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c4fc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The plethora  of machine learning algorithms/methods\n",
    "\n",
    "1. Deep learning: Neural Networks (NN), Convolutional NN, Recurrent NN, Boltzmann machines, autoencoders and variational autoencoders  and generative adversarial networks, stable diffusion and many more generative models\n",
    "\n",
    "2. Bayesian statistics and Bayesian Machine Learning, Bayesian experimental design, Bayesian Regression models, Bayesian neural networks, Gaussian processes and much more\n",
    "\n",
    "3. Dimensionality reduction (Principal component analysis), Clustering Methods and more\n",
    "\n",
    "4. Ensemble Methods, Random forests, bagging and voting methods, gradient boosting approaches \n",
    "\n",
    "5. Linear and logistic regression, Kernel methods, support vector machines and more\n",
    "\n",
    "6. Reinforcement Learning; Transfer Learning and more \n",
    "\n",
    "Our focus has been on deep learning. But to discuss autoencoders we have also discussed PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5960de",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What Is Generative Modeling?\n",
    "\n",
    "Generative modeling can be broadly defined as follows:\n",
    "\n",
    "Generative modeling is a branch of machine learning that involves\n",
    "training a model to produce new data that is similar to a given\n",
    "dataset.\n",
    "\n",
    "What does this mean in practice? Suppose we have a dataset containing\n",
    "photos of horses. We can train a generative model on this dataset to\n",
    "capture the rules that govern the complex relationships between pixels\n",
    "in images of horses. Then we can sample from this model to create\n",
    "novel, realistic images of horses that did not exist in the original\n",
    "dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9a456",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Example of generative modeling, [taken from Generative Deep Learning by David Foster](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch01.html)\n",
    "\n",
    "<!-- dom:FIGURE: [figures/generativelearning.png, width=900 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/generativelearning.png\" width=\"900\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128293a2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Generative Modeling\n",
    "\n",
    "In order to build a generative model, we require a dataset consisting\n",
    "of many examples of the entity we are trying to generate. This is\n",
    "known as the training data, and one such data point is called an\n",
    "observation.\n",
    "\n",
    "Each observation consists of many features. For an image generation\n",
    "problem, the features are usually the individual pixel values; for a\n",
    "text generation problem, the features could be individual words or\n",
    "groups of letters. It is our goal to build a model that can generate\n",
    "new sets of features that look as if they have been created using the\n",
    "same rules as the original data. Conceptually, for image generation\n",
    "this is an incredibly difficult task, considering the vast number of\n",
    "ways that individual pixel values can be assigned and the relatively\n",
    "tiny number of such arrangements that constitute an image of the\n",
    "entity we are trying to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7386842",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Generative Versus Discriminative Modeling\n",
    "\n",
    "In order to truly understand what generative modeling aims to achieve\n",
    "and why this is important, it is useful to compare it to its\n",
    "counterpart, discriminative modeling. If you have studied machine\n",
    "learning, most problems you will have faced will have most likely been\n",
    "discriminative in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e0a6e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Example of discriminative modeling, [taken from Generative Deeep Learning by David Foster](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch01.html)\n",
    "\n",
    "<!-- dom:FIGURE: [figures/standarddeeplearning.png, width=900 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/standarddeeplearning.png\" width=\"900\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb97c8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Discriminative Modeling\n",
    "\n",
    "When performing discriminative modeling, each observation in the\n",
    "training data has a label. For a binary classification problem such as\n",
    "our data could be labeled as ones and zeros. Our model then learns how to\n",
    "discriminate between these two groups and outputs the probability that\n",
    "a new observation has label 1 or 0\n",
    "\n",
    "In contrast, generative modeling doesn’t require the dataset to be\n",
    "labeled because it concerns itself with generating entirely new\n",
    "data (for example an image), rather than trying to predict a label for say  a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54793c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Taxonomy of generative deep learning, [taken from Generative Deep Learning by David Foster](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch01.html)\n",
    "\n",
    "<!-- dom:FIGURE: [figures/generativemodels.png, width=900 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/generativemodels.png\" width=\"900\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbd683",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Good books with hands-on material and codes\n",
    "* [Sebastian Rashcka et al, Machine learning with Sickit-Learn and PyTorch](https://sebastianraschka.com/blog/2022/ml-pytorch-book.html)\n",
    "\n",
    "* [David Foster, Generative Deep Learning with TensorFlow](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/ch01.html)\n",
    "\n",
    "* [Babcock and Gavras, Generative AI with Python and TensorFlow 2](https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2)\n",
    "\n",
    "All three books have GitHub sites from where  one can download all codes. A good and more general text (2016)\n",
    "is Goodfellow, Bengio and Courville, [Deep Learning](https://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b1810",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Setting up the basic equations for neural networks\n",
    "\n",
    "Neural networks, in its so-called feed-forward form, where each\n",
    "iterations contains a feed-forward stage and a back-propgagation\n",
    "stage, consist of series of affine matrix-matrix and matrix-vector\n",
    "multiplications. The unknown parameters (the so-called biases and\n",
    "weights which deternine the architecture of a neural network), are\n",
    "uptaded iteratively using the so-called back-propagation algorithm.\n",
    "This algorithm corresponds to the so-called reverse mode of the\n",
    "automatic differentation algorithm. These algorithms will be discussed\n",
    "in more detail below.\n",
    "\n",
    "We start however first with the  definitions of the various variables which make up a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec404db",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Overarching view of a neural network\n",
    "\n",
    "The architecture of a neural network defines our model. This model\n",
    "aims at describing some function $f(\\boldsymbol{x}$ which aims at describing\n",
    "some final result (outputs or tagrget values) given a specific inpput\n",
    "$\\boldsymbol{x}$. Note that here $\\boldsymbol{y}$ and $\\boldsymbol{x}$ are not limited to be\n",
    "vectors.\n",
    "\n",
    "The architecture consists of\n",
    "1. An input and an output layer where the input layer is defined by the inputs $\\boldsymbol{x}$. The output layer produces the model ouput $\\boldsymbol{\\tilde{y}}$ which is compared with the target value $\\boldsymbol{y}$\n",
    "\n",
    "2. A given number of hidden layers and neurons/nodes/units for each layer (this may vary)\n",
    "\n",
    "3. A given activation function $\\sigma(\\boldsymbol{z})$ with arguments $\\boldsymbol{z}$ to be defined below. The activation functions may differ from layer to layer.\n",
    "\n",
    "4. The last layer, normally called **output** layer has normally an activation function tailored to the specific problem\n",
    "\n",
    "5. Finally we define a so-called cost or loss function which is used to gauge the quality of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d931c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Illustration of a single perceptron model and a multilayer FFNN\n",
    "\n",
    "<!-- dom:FIGURE: [figures/nns.png, width=600 frac=0.7]  -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/nns.png\" width=\"600\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe6452",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The optimization problem\n",
    "\n",
    "The cost function is a function of the unknown parameters\n",
    "$\\boldsymbol{\\Theta}$ where the latter is a container for all possible\n",
    "parameters needed to define a neural network\n",
    "\n",
    "If we are dealing with a regression task a typical cost/loss function\n",
    "is the mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ddc72c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "C(\\boldsymbol{\\Theta})=\\frac{1}{n}\\left\\{\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\theta}\\right)\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00940bc4",
   "metadata": {
    "editable": true
   },
   "source": [
    "This function represents one of many possible ways to define\n",
    "the so-called cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6dc39",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Weights and biases\n",
    "\n",
    "For neural networks the parameters\n",
    "$\\boldsymbol{\\Theta}$ are given by the so-called weights and biases (to be\n",
    "defined below).\n",
    "\n",
    "The weights are given by matrix elements $w_{ij}^{(l)}$ where the\n",
    "superscript indicates the layer number. The biases are typically given\n",
    "by vector elements representing each single node of a given layer,\n",
    "that is $b_j^{(l)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096ec5bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Other ingredients of a neural network\n",
    "\n",
    "Having defined the architecture of a neural network, the optimization\n",
    "of the cost function with respect to the parameters $\\boldsymbol{\\Theta}$,\n",
    "involves the calculations of gradients and their optimization. The\n",
    "gradients represent the derivatives of a multidimensional object and\n",
    "are often approximated by various gradient methods, including\n",
    "1. various quasi-Newton methods,\n",
    "\n",
    "2. plain gradient descent (GD) with a constant learning rate $\\eta$,\n",
    "\n",
    "3. GD with momentum and other approximations to the learning rates such as\n",
    "\n",
    "  * Adapative gradient (ADAgrad)\n",
    "\n",
    "  * Root mean-square propagation (RMSprop)\n",
    "\n",
    "  * Adaptive gradient with momentum (ADAM) and many other\n",
    "\n",
    "4. Stochastic gradient descent and various families of learning rate approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146402b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Other parameters\n",
    "\n",
    "In addition to the above, there are often additional hyperparamaters\n",
    "which are included in the setup of a neural network. These will be\n",
    "discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d089d1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why Feed Forward Neural Networks (FFNN)?\n",
    "\n",
    "According to the *Universal approximation theorem*, a feed-forward\n",
    "neural network with just a single hidden layer containing a finite\n",
    "number of neurons can approximate a continuous multidimensional\n",
    "function to arbitrary accuracy, assuming the activation function for\n",
    "the hidden layer is a **non-constant, bounded and\n",
    "monotonically-increasing continuous function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ea018",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Universal approximation theorem\n",
    "\n",
    "The universal approximation theorem plays a central role in deep\n",
    "learning.  [Cybenko (1989)](https://link.springer.com/article/10.1007/BF02551274) showed\n",
    "the following:\n",
    "\n",
    "Let $\\sigma$ be any continuous sigmoidal function such that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d1dfaf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma(z) = \\left\\{\\begin{array}{cc} 1 & z\\rightarrow \\infty\\\\ 0 & z \\rightarrow -\\infty \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e223142",
   "metadata": {
    "editable": true
   },
   "source": [
    "Given a continuous and deterministic function $F(\\boldsymbol{x})$ on the unit\n",
    "cube in $d$-dimensions $F\\in [0,1]^d$, $x\\in [0,1]^d$ and a parameter\n",
    "$\\epsilon >0$, there is a one-layer (hidden) neural network\n",
    "$f(\\boldsymbol{x};\\boldsymbol{\\Theta})$ with $\\boldsymbol{\\Theta}=(\\boldsymbol{W},\\boldsymbol{b})$ and $\\boldsymbol{W}\\in\n",
    "\\mathbb{R}^{m\\times n}$ and $\\boldsymbol{b}\\in \\mathbb{R}^{n}$, for which"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee9638",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\vert F(\\boldsymbol{x})-f(\\boldsymbol{x};\\boldsymbol{\\Theta})\\vert < \\epsilon \\hspace{0.1cm} \\forall \\boldsymbol{x}\\in[0,1]^d.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0eb38",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The approximation theorem in words\n",
    "\n",
    "**Any continuous function $y=F(\\boldsymbol{x})$ supported on the unit cube in\n",
    "$d$-dimensions can be approximated by a one-layer sigmoidal network to\n",
    "arbitrary accuracy.**\n",
    "\n",
    "[Hornik (1991)](https://www.sciencedirect.com/science/article/abs/pii/089360809190009T) extended the theorem by letting any non-constant, bounded activation function to be included using that the expectation value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12434922",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbb{E}[\\vert F(\\boldsymbol{x})\\vert^2] =\\int_{\\boldsymbol{x}\\in D} \\vert F(\\boldsymbol{x})\\vert^2p(\\boldsymbol{x})d\\boldsymbol{x} < \\infty.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8ec3b",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636ae1b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbb{E}[\\vert F(\\boldsymbol{x})-f(\\boldsymbol{x};\\boldsymbol{\\Theta})\\vert^2] =\\int_{\\boldsymbol{x}\\in D} \\vert F(\\boldsymbol{x})-f(\\boldsymbol{x};\\boldsymbol{\\Theta})\\vert^2p(\\boldsymbol{x})d\\boldsymbol{x} < \\epsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132732d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on the general approximation theorem\n",
    "\n",
    "None of the proofs give any insight into the relation between the\n",
    "number of of hidden layers and nodes and the approximation error\n",
    "$\\epsilon$, nor the magnitudes of $\\boldsymbol{W}$ and $\\boldsymbol{b}$.\n",
    "\n",
    "Neural networks (NNs) have what we may call a kind of universality no matter what function we want to compute.\n",
    "\n",
    "It does not mean that an NN can be used to exactly compute any function. Rather, we get an approximation that is as good as we want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af541c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Class of functions we can approximate\n",
    "\n",
    "The class of functions that can be approximated are the continuous ones.\n",
    "If the function $F(\\boldsymbol{x})$ is discontinuous, it won't in general be possible to approximate it. However, an NN may still give an approximation even if we fail in some points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922c411",
   "metadata": {
    "editable": true
   },
   "source": [
    "## NN code\n",
    "\n",
    "For an OO-code in Python for a feed-forward NN, see <https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/NNpart5code/ipynb/NNpart5code.ipynb>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9cb90b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Convolutional Neural and Recurrent networks\n",
    "\n",
    "See the lectures from weeks 6, 7 and 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b094b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Autoencoders: Overarching view\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning\n",
    "efficient representations of the input data (these representations are called codings)  without\n",
    "any supervision (i.e., the training set is unlabeled). These codings\n",
    "typically have a much lower dimensionality than the input data, making\n",
    "autoencoders useful for dimensionality reduction. \n",
    "\n",
    "Autoencoders learn to encode the\n",
    "input data into a lower-dimensional representation, and then decode it\n",
    "back to the original data. The goal of autoencoders is to minimize the\n",
    "reconstruction error, which measures how well the output matches the\n",
    "input. Autoencoders can be seen as a way of learning the latent\n",
    "features or hidden structure of the data, and they can be used for\n",
    "data compression, denoising, anomaly detection, and generative\n",
    "modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b6506",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Powerful detectors\n",
    "\n",
    "More importantly, autoencoders act as powerful feature detectors, and\n",
    "they can be used for unsupervised pretraining of deep neural networks.\n",
    "\n",
    "Lastly, they are capable of randomly generating new data that looks\n",
    "very similar to the training data; this is called a generative\n",
    "model. For example, you could train an autoencoder on pictures of\n",
    "faces, and it would then be able to generate new faces.  Surprisingly,\n",
    "autoencoders work by simply learning to copy their inputs to their\n",
    "outputs. This may sound like a trivial task, but we will see that\n",
    "constraining the network in various ways can make it rather\n",
    "difficult. For example, you can limit the size of the internal\n",
    "representation, or you can add noise to the inputs and train the\n",
    "network to recover the original inputs. These constraints prevent the\n",
    "autoencoder from trivially copying the inputs directly to the outputs,\n",
    "which forces it to learn efficient ways of representing the data. In\n",
    "short, the codings are byproducts of the autoencoder’s attempt to\n",
    "learn the identity function under some constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0f891",
   "metadata": {
    "editable": true
   },
   "source": [
    "## First introduction of AEs\n",
    "\n",
    "Autoencoders were first introduced by Rumelhart, Hinton, and Williams\n",
    "in 1986 with the goal of learning to reconstruct the input\n",
    "observations with the lowest error possible.\n",
    "\n",
    "Why would one want to learn to reconstruct the input observations? If\n",
    "you have problems imagining what that means, think of having a dataset\n",
    "made of images. An autoencoder would be an algorithm that can give as\n",
    "output an image that is as similar as possible to the input one. You\n",
    "may be confused, as there is no apparent reason of doing so. To better\n",
    "understand why autoencoders are useful we need a more informative\n",
    "(although not yet unambiguous) definition.\n",
    "\n",
    "An autoencoder is a type of algorithm with the primary purpose of learning an \"informative\" representation of the data that can be used for different applications ([see Bank, D., Koenigstein, N., and Giryes, R., Autoencoders](https://arxiv.org/abs/2003.05991)) by learning to reconstruct a set of input observations well enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b049d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Autoencoder structure\n",
    "\n",
    "Autoencoders are neural networks where the outputs are its own\n",
    "inputs. They are split into an **encoder part**\n",
    "which maps the input $\\boldsymbol{x}$ via a function $f(\\boldsymbol{x},\\boldsymbol{W})$ (this\n",
    "is the encoder part) to a **so-called code part** (or intermediate part)\n",
    "with the result $\\boldsymbol{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13445f00",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\boldsymbol{h} = f(\\boldsymbol{x},\\boldsymbol{W})),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a392b4",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\boldsymbol{W}$ are the weights to be determined.  The **decoder** parts maps, via its own parameters (weights given by the matrix $\\boldsymbol{V}$ and its own biases) to \n",
    "the final ouput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79627a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\boldsymbol{x}} = g(\\boldsymbol{h},\\boldsymbol{V})).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662f768",
   "metadata": {
    "editable": true
   },
   "source": [
    "The goal is to minimize the construction error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d17ca",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Schematic image of an Autoencoder\n",
    "\n",
    "<!-- dom:FIGURE: [figures/ae1.png, width=700 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/ae1.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e39703",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on the structure\n",
    "\n",
    "In most typical architectures, the encoder and the decoder are neural networks\n",
    "since they can be easily trained with existing software libraries such as TensorFlow or PyTorch with back propagation.\n",
    "\n",
    "In general, the encoder can be written as a function $g$ that will depend on some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d2b82",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{h}_{i} = g(\\mathbf{x}_{i}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781bdb1",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbf{h}_{i}\\in\\mathbb{R}^{q}$  (the latent feature representation) is the output of the encoder block where we evaluate\n",
    "it using the input $\\mathbf{x}_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45588cac",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Decoder part\n",
    "\n",
    "Note that we have $g:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{q}$\n",
    "The decoder and the output of the network $\\tilde{\\mathbf{x}}_{i}$ can be written then as a second generic function\n",
    "of the latent features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57749cc9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\mathbf{x}}_{i} = f\\left(\\mathbf{h}_{i}\\right) = f\\left(g\\left(\\mathbf{x}_{i}\\right)\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2c0691",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\tilde{\\mathbf{x}}_{i}\\mathbf{\\in }\\mathbb{R}^{n}$.\n",
    "\n",
    "Training an autoencoder simply means finding the functions $g(\\cdot)$ and $f(\\cdot)$\n",
    "that satisfy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dae90",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{arg}\\min_{f,g}<\\left[\\Delta (\\mathbf{x}_{i}, f(g\\left(\\mathbf{x}_{i}\\right))\\right]>.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f34f736",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Typical AEs\n",
    "\n",
    "The standard setup is done via a standard feed forward neural network (FFNN), or what is called a Feed Forward Autoencoder.\n",
    "\n",
    "A typical FFNN architecture has an odd number of layers and is symmetrical with respect to the middle layer.\n",
    "\n",
    "Typically, the first layer has a number of neurons $n_{1} = n$ which equals the size of the input observation $\\mathbf{x}_{\\mathbf{i}}$.\n",
    "\n",
    "As we move toward the center of the network, the number of neurons in each layer drops in some measure.\n",
    "The middle layer usually has the smallest number of neurons.\n",
    "The fact that the number of neurons in this layer is smaller than the size of the input, is often called the **bottleneck**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5727ee0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Feed Forward Autoencoder\n",
    "\n",
    "<!-- dom:FIGURE: [figures/ae2.png, width=700 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/ae2.png\" width=\"700\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ae01f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mirroring\n",
    "\n",
    "In almost all practical applications,\n",
    "the layers after the middle one are a mirrored version of the layers before the middle one.\n",
    "For example, an autoencoder with three layers could have the following numbers of neurons:\n",
    "\n",
    "$n_{1} = 10$, $n_{2} = 5$ and then $n_{3} = n_{1} = 10$ where the input dimension is equal to ten.\n",
    "\n",
    "All the layers up to and including the middle one, make what is called the encoder, and all the layers from and including\n",
    "the middle one (up to the output) make what is called the decoder.\n",
    "\n",
    "If the FFNN training is successful, the result will\n",
    "be a good approximation of the input $\\tilde{\\mathbf{x}}_{i}\\approx\\mathbf{x}_{i}$.\n",
    "\n",
    "What is essential to notice is that the decoder can reconstruct the\n",
    "input by using only a much smaller number of features than the input\n",
    "observations initially have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9188d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Output of middle layer\n",
    "\n",
    "The output of the middle layer\n",
    "$\\mathbf{h}_{\\mathbf{i}}$ are also called a **learned representation** of the input observation $\\mathbf{x}_{i}$.\n",
    "\n",
    "The encoder can reduce the number of dimensions of the input\n",
    "observation and create a learned representation\n",
    "$\\mathbf{h}_{\\mathbf{i}}\\mathbf{) }$ of the input that has a smaller\n",
    "dimension $q<n$.\n",
    "\n",
    "This learned representation is enough for the decoder to reconstruct\n",
    "the input accurately (if the autoencoder training was successful as\n",
    "intended)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489292f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Activation Function of the Output Layer\n",
    "\n",
    "In autoencoders based on neural networks, the output layer's\n",
    "activation function plays a particularly important role.  The most\n",
    "used functions are ReLU and Sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbcf20",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ReLU\n",
    "\n",
    "The  ReLU activation function can assume all values in the range $\\left[0,\\infty\\right]$. As a remainder, its formula is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817206a1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{ReLU}\\left(x\\right) = \\max\\left(0,x\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09a979",
   "metadata": {
    "editable": true
   },
   "source": [
    "This choice is good when the input observations \\(\\mathbf{x}_{i}\\) assume a wide range of positive values.\n",
    "If the input $\\mathbf{x}_{i}$ can assume negative values, the ReLU is, of course, a terrible choice, and the identity function is a much better choice. It is then common to replace to the ReLU with the so-called **Leaky ReLu** or just modified ReLU.\n",
    "\n",
    "The ReLU activation function for the output layer is well suited for cases when the input observations \\(\\mathbf{x}_{i}\\) assume a wide range of positive real values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ca1d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Sigmoid\n",
    "\n",
    "The sigmoid function $\\sigma$ can assume all values in the range $[0,1]$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3ae6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma\\left(x\\right) =\\frac{1}{1+e^{-x}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c91d5",
   "metadata": {
    "editable": true
   },
   "source": [
    "This activation function can only be used if the input observations\n",
    "$\\mathbf{x}_{i}$ are all in the range $[0,1]$  or if you have\n",
    "normalized them to be in that range. Consider as an example the MNIST\n",
    "dataset. Each value of the input observation $\\mathbf{x}_{i}$ (one\n",
    "image) is the gray values of the pixels that can assume any value from\n",
    "0 to 255. Normalizing the data by dividing the pixel values by 255\n",
    "would make each observation (each image) have only pixel values\n",
    "between 0 and 1. In this case, the sigmoid would be a good choice for\n",
    "the output layer's activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1744b72c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Cost/Loss Function\n",
    "\n",
    "If an autoencoder is trying to solve a regression problem, the most\n",
    "common choice as a loss function is the Mean Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708e2fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L_{\\textrm{MSE}} = \\textrm{MSE} = \\frac{1}{n}\\sum_{i = 1}^{n}\\left\\vert\\vert\\mathbf{x}_{i}-\\tilde{\\mathbf{x}}_{i}\\right\\vert\\vert^{2}_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47888c1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Binary Cross-Entropy\n",
    "\n",
    "If the activation function of the output layer of the AE is a sigmoid\n",
    "function, thus limiting neuron outputs to be between 0 and 1, and the\n",
    "input features are normalized to be between 0 and 1 we can use as loss\n",
    "function the binary cross-entropy. This cots/loss function is\n",
    "typically used in classification problems, but it works well for\n",
    "autoencoders. The formula for it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff1933",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L_{\\textrm{CE}} = -\\frac{1}{n}\\sum_{i = 1}^{n}\\sum_{j = 1}^{p}[x_{j,i} \\log\\tilde{x}_{j,i}+\\left(1-x_{j,i}\\right)\\log (1-\\tilde{x}_{j,i})].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c8f01",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Reconstruction Error\n",
    "\n",
    "The reconstruction error (RE) is a metric that gives you an indication of how good (or bad) the autoencoder was able to reconstruct\n",
    "the input observation $\\mathbf{x}_{i}$. The most typical RE used is the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8283126",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\textrm{RE}\\equiv \\textrm{MSE} = \\frac{1}{n}\\sum_{i = 1}^{n}\\left\\vert\\vert\\mathbf{x}_{i}-\\tilde{\\mathbf{x}}_{i}\\right\\vert\\vert^{2}_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc65da",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Essential elements of generative models\n",
    "\n",
    "The aim of generative methods is to train a probability distribution $p$. The methods we will focus on are:\n",
    "1. Energy based models, with the family of Boltzmann distributions as a typical example\n",
    "\n",
    "2. Variational autoencoders\n",
    "\n",
    "3. Diffusion models\n",
    "\n",
    "4. Generative adversarial networks (GANs) and\n",
    "\n",
    "5. Not covered: Autoregressive models\n",
    "\n",
    "6. Not covered: Normalizing flow models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c13be",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Probability model\n",
    "\n",
    "We define a probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19488cca",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(x_i,h_j;\\boldsymbol{\\Theta}) = \\frac{f(x_i,h_j;\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb14813",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $f(x_i,h_j;\\boldsymbol{\\Theta})$ is a function which we assume is larger or\n",
    "equal than zero and obeys all properties required for a probability\n",
    "distribution and $Z(\\boldsymbol{\\Theta})$ is a normalization constant. Inspired by\n",
    "statistical mechanics, we call it often for the partition function.\n",
    "It is defined as (assuming that we have discrete probability distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1033ff1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "Z(\\boldsymbol{\\Theta})=\\sum_{x_i\\in \\boldsymbol{X}}\\sum_{h_j\\in \\boldsymbol{H}} f(x_i,h_j;\\boldsymbol{\\Theta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce133827",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Marginal and conditional probabilities\n",
    "\n",
    "We can in turn define the marginal probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31d8e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(x_i;\\boldsymbol{\\Theta}) = \\frac{\\sum_{h_j\\in \\boldsymbol{H}}f(x_i,h_j;\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1db20",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9046f50",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(h_i;\\boldsymbol{\\Theta}) = \\frac{\\sum_{x_i\\in \\boldsymbol{X}}f(x_i,h_j;\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd953cfa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Change of notation\n",
    "\n",
    "**Note the change to a vector notation**. A variable like $\\boldsymbol{x}$\n",
    "represents now a specific **configuration**. We can generate an infinity\n",
    "of such configurations. The final partition function is then the sum\n",
    "over all such possible configurations, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcc0e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "Z(\\boldsymbol{\\Theta})=\\sum_{x_i\\in \\boldsymbol{X}}\\sum_{h_j\\in \\boldsymbol{H}} f(x_i,h_j;\\boldsymbol{\\Theta}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453f9e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "changes to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbb236",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "Z(\\boldsymbol{\\Theta})=\\sum_{\\boldsymbol{x}}\\sum_{\\boldsymbol{h}} f(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c446b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we have a binary set of variable $x_i$ and $h_j$ and $M$ values of $x_i$ and $N$ values of $h_j$ we have in total $2^M$ and $2^N$ possible $\\boldsymbol{x}$ and $\\boldsymbol{h}$ configurations, respectively.\n",
    "\n",
    "We see that even for the modest binary case, we can easily approach a\n",
    "number of configuration which is not possible to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4da83d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization problem\n",
    "\n",
    "At the end, we are not interested in the probabilities of the hidden variables. The probability we thus want to optimize is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397cf9e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{X};\\boldsymbol{\\Theta})=\\prod_{x_i\\in \\boldsymbol{X}}p(x_i;\\boldsymbol{\\Theta})=\\prod_{x_i\\in \\boldsymbol{X}}\\left(\\frac{\\sum_{h_j\\in \\boldsymbol{H}}f(x_i,h_j;\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9895e4a",
   "metadata": {
    "editable": true
   },
   "source": [
    "which we rewrite as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbb431",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{X};\\boldsymbol{\\Theta})=\\frac{1}{Z(\\boldsymbol{\\Theta})}\\prod_{x_i\\in \\boldsymbol{X}}\\left(\\sum_{h_j\\in \\boldsymbol{H}}f(x_i,h_j;\\boldsymbol{\\Theta})\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b551c8f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Further simplifications\n",
    "\n",
    "We simplify further by rewriting it as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341bf7c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{X};\\boldsymbol{\\Theta})=\\frac{1}{Z(\\boldsymbol{\\Theta})}\\prod_{x_i\\in \\boldsymbol{X}}f(x_i;\\boldsymbol{\\Theta}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a76f77",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we used $p(x_i;\\boldsymbol{\\Theta}) = \\sum_{h_j\\in \\boldsymbol{H}}f(x_i,h_j;\\boldsymbol{\\Theta})$.\n",
    "The optimization problem is then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd3aa7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "{\\displaystyle \\mathrm{arg} \\hspace{0.1cm}\\max_{\\boldsymbol{\\boldsymbol{\\Theta}}\\in {\\mathbb{R}}^{p}}} \\hspace{0.1cm}p(\\boldsymbol{X};\\boldsymbol{\\Theta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780d014",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimizing the logarithm instead\n",
    "\n",
    "Computing the derivatives with respect to the parameters $\\boldsymbol{\\Theta}$ is\n",
    "easier (and equivalent) with taking the logarithm of the\n",
    "probability. We will thus optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab7081",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "{\\displaystyle \\mathrm{arg} \\hspace{0.1cm}\\max_{\\boldsymbol{\\boldsymbol{\\Theta}}\\in {\\mathbb{R}}^{p}}} \\hspace{0.1cm}\\log{p(\\boldsymbol{X};\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94548f",
   "metadata": {
    "editable": true
   },
   "source": [
    "which leads to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22029301",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{p(\\boldsymbol{X};\\boldsymbol{\\Theta})}=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae0073",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Expression for the gradients\n",
    "\n",
    "This leads to the following equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e39783",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{p(\\boldsymbol{X};\\boldsymbol{\\Theta})}=\\nabla_{\\boldsymbol{\\Theta}}\\left(\\sum_{x_i\\in \\boldsymbol{X}}\\log{f(x_i;\\boldsymbol{\\Theta})}\\right)-\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9fc10",
   "metadata": {
    "editable": true
   },
   "source": [
    "The first term is called the positive phase and we assume that we have a model for the function $f$ from which we can sample values. Below we will develop an explicit model for this.\n",
    "The second term is called the negative phase and is the one which leads to more difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087b784",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The derivative of the partition function\n",
    "\n",
    "The partition function, defined above as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf73fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "Z(\\boldsymbol{\\Theta})=\\sum_{x_i\\in \\boldsymbol{X}}\\sum_{h_j\\in \\boldsymbol{H}} f(x_i,h_j;\\boldsymbol{\\Theta}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb968b07",
   "metadata": {
    "editable": true
   },
   "source": [
    "is in general the most problematic term. In principle both $x$ and $h$ can span large degrees of freedom, if not even infinitely many ones, and computing the partition function itself is often not desirable or even feasible. The above derivative of the partition function can however be written in terms of an expectation value which is in turn evaluated  using Monte Carlo sampling and the theory of Markov chains, popularly shortened to MCMC (or just MC$^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f7a95",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Explicit expression for the derivative\n",
    "We can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28492ded",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\frac{\\nabla_{\\boldsymbol{\\Theta}}Z(\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300962f",
   "metadata": {
    "editable": true
   },
   "source": [
    "which reads in more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a840c90",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\frac{\\nabla_{\\boldsymbol{\\Theta}} \\sum_{x_i\\in \\boldsymbol{X}}f(x_i;\\boldsymbol{\\Theta})   }{Z(\\boldsymbol{\\Theta})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf82da9",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can rewrite the function $f$ (we have assumed that is larger or\n",
    "equal than zero) as $f=\\exp{\\log{f}}$. We can then rewrite the last\n",
    "equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca776a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\frac{ \\sum_{x_i\\in \\boldsymbol{X}} \\nabla_{\\boldsymbol{\\Theta}}\\exp{\\log{f(x_i;\\boldsymbol{\\Theta})}}   }{Z(\\boldsymbol{\\Theta})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c1bbb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Final expression\n",
    "\n",
    "Taking the derivative gives us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecde4a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\frac{ \\sum_{x_i\\in \\boldsymbol{X}}f(x_i;\\boldsymbol{\\Theta}) \\nabla_{\\boldsymbol{\\Theta}}\\log{f(x_i;\\boldsymbol{\\Theta})}   }{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c09beb",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is the expectation value of $\\log{f}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c8edb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\sum_{x_i\\sim p}p(x_i;\\boldsymbol{\\Theta}) \\nabla_{\\boldsymbol{\\Theta}}\\log{f(x_i;\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca5769",
   "metadata": {
    "editable": true
   },
   "source": [
    "that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188cc30",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{Z(\\boldsymbol{\\Theta})}=\\mathbb{E}(\\log{f(x_i;\\boldsymbol{\\Theta})}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f784418",
   "metadata": {
    "editable": true
   },
   "source": [
    "This quantity is evaluated using Monte Carlo sampling, with Gibbs\n",
    "sampling as the standard sampling rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583fcc0a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Final expression for the gradients\n",
    "\n",
    "This leads to the following equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ddfe7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\boldsymbol{\\Theta}}\\log{p(\\boldsymbol{X};\\boldsymbol{\\Theta})}=\\nabla_{\\boldsymbol{\\Theta}}\\left(\\sum_{x_i\\in \\boldsymbol{X}}\\log{f(x_i;\\boldsymbol{\\Theta})}\\right)-\\mathbb{E}_{x\\sim p}(\\log{f(x_i;\\boldsymbol{\\Theta})})=0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540abd80",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Introducing the energy model\n",
    "\n",
    "As we will see below, a typical Boltzmann machines employs a probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b2903",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta}) = \\frac{f(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta})}{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469a182",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $f(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta})$ is given by a so-called energy model. If we assume that the random variables $x_i$ and $h_j$ take binary values only, for example $x_i,h_j=\\{0,1\\}$, we have a so-called binary-binary model where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3df86",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta})=-E(\\boldsymbol{x}, \\boldsymbol{h};\\boldsymbol{\\Theta}) = \\sum_{x_i\\in \\boldsymbol{X}} x_i a_i+\\sum_{h_j\\in \\boldsymbol{H}} b_j h_j + \\sum_{x_i\\in \\boldsymbol{X},h_j\\in\\boldsymbol{H}} x_i w_{ij} h_j,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba65df",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the set of parameters are given by the biases and weights $\\boldsymbol{\\Theta}=\\{\\boldsymbol{a},\\boldsymbol{b},\\boldsymbol{W}\\}$.\n",
    "**Note the vector notation** instead of $x_i$ and $h_j$ for $f$. The vectors $\\boldsymbol{x}$ and $\\boldsymbol{h}$ represent a specific instance of stochastic variables $x_i$ and $h_j$. These arrangements of $\\boldsymbol{x}$ and $\\boldsymbol{h}$ lead to a specific energy configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d2c4d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More compact notation\n",
    "\n",
    "With the above definition we can write the probability as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00edd4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{x},\\boldsymbol{h};\\boldsymbol{\\Theta}) = \\frac{\\exp{(\\boldsymbol{a}^T\\boldsymbol{x}+\\boldsymbol{b}^T\\boldsymbol{h}+\\boldsymbol{x}^T\\boldsymbol{W}\\boldsymbol{h})}}{Z(\\boldsymbol{\\Theta})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e2614",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the biases $\\boldsymbol{a}$ and $\\boldsymbol{h}$ and the weights defined by the matrix $\\boldsymbol{W}$ are the parameters we need to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8d704",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Examples of gradient expressions\n",
    "\n",
    "Since the binary-binary energy model is linear in the parameters $a_i$, $b_j$ and\n",
    "$w_{ij}$, it is easy to see that the derivatives with respect to the\n",
    "various optimization parameters yield expressions used in the\n",
    "evaluation of gradients like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c990577",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial E(\\boldsymbol{x}, \\boldsymbol{h};\\boldsymbol{\\Theta})}{\\partial w_{ij}}=-x_ih_j,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5f720",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5c995",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial E(\\boldsymbol{x}, \\boldsymbol{h};\\boldsymbol{\\Theta})}{\\partial a_i}=-x_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc462d22",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65909af8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial E(\\boldsymbol{x}, \\boldsymbol{h};\\boldsymbol{\\Theta})}{\\partial b_j}=-h_j.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc694a2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Network Elements, the energy function\n",
    "\n",
    "The function $E(\\boldsymbol{x},\\boldsymbol{h},\\boldsymbol{\\Theta})$ gives the **energy** of a\n",
    "configuration (pair of vectors) $(\\boldsymbol{x}, \\boldsymbol{h})$. The lower\n",
    "the energy of a configuration, the higher the probability of it. This\n",
    "function also depends on the parameters $\\boldsymbol{a}$, $\\boldsymbol{b}$ and\n",
    "$W$. Thus, when we adjust them during the learning procedure, we are\n",
    "adjusting the energy function to best fit our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdff959",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Defining different types of RBMs\n",
    "\n",
    "There are different variants of RBMs, and the differences lie in the types of visible and hidden units we choose as well as in the implementation of the energy function $E(\\boldsymbol{x},\\boldsymbol{h},\\boldsymbol{\\Theta})$. The connection between the nodes in the two layers is given by the weights $w_{ij}$. \n",
    "\n",
    "**Binary-Binary RBM:**\n",
    "\n",
    "RBMs were first developed using binary units in both the visible and hidden layer. The corresponding energy function is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f319bb5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\tE(\\boldsymbol{x}, \\boldsymbol{h},\\boldsymbol{\\Theta}) = - \\sum_i^M x_i a_i- \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} x_i w_{ij} h_j,\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083a1a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the binary values taken on by the nodes are most commonly 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa75f2d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Gaussian-binary RBM\n",
    "\n",
    "Another varient is the RBM where the visible units are Gaussian while the hidden units remain binary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb60c67",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\tE(\\boldsymbol{x}, \\boldsymbol{h},\\boldsymbol{\\Theta}) = \\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma_i^2} - \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma_i^2}. \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d864ba",
   "metadata": {
    "editable": true
   },
   "source": [
    "This type of RBMs are useful when we model continuous data (i.e., we wish $\\boldsymbol{x}$ to be continuous). The paramater $\\sigma_i^2$ is meant to represent a variance and is foten just set to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b75a76",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Code for RBMs using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0d3b61",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor()])\n",
    "     ),\n",
    "     batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "datasets.MNIST('./data',\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "    ),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "class RBM(nn.Module):\n",
    "   def __init__(self,\n",
    "               n_vis=784,\n",
    "               n_hin=500,\n",
    "               k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hin,n_vis)*1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hin))\n",
    "        self.k = k\n",
    "    \n",
    "   def sample_from_p(self,p):\n",
    "       return F.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "   def v_to_h(self,v):\n",
    "        p_h = F.sigmoid(F.linear(v,self.W,self.h_bias))\n",
    "        sample_h = self.sample_from_p(p_h)\n",
    "        return p_h,sample_h\n",
    "    \n",
    "   def h_to_v(self,h):\n",
    "        p_v = F.sigmoid(F.linear(h,self.W.t(),self.v_bias))\n",
    "        sample_v = self.sample_from_p(p_v)\n",
    "        return p_v,sample_v\n",
    "        \n",
    "   def forward(self,v):\n",
    "        pre_h1,h1 = self.v_to_h(v)\n",
    "        \n",
    "        h_ = h1\n",
    "        for _ in range(self.k):\n",
    "            pre_v_,v_ = self.h_to_v(h_)\n",
    "            pre_h_,h_ = self.v_to_h(v_)\n",
    "        \n",
    "        return v,v_\n",
    "    \n",
    "   def free_energy(self,v):\n",
    "        vbias_term = v.mv(self.v_bias)\n",
    "        wx_b = F.linear(v,self.W,self.h_bias)\n",
    "        hidden_term = wx_b.exp().add(1).log().sum(1)\n",
    "        return (-hidden_term - vbias_term).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rbm = RBM(k=1)\n",
    "train_op = optim.SGD(rbm.parameters(),0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_ = []\n",
    "    for _, (data,target) in enumerate(train_loader):\n",
    "        data = Variable(data.view(-1,784))\n",
    "        sample_data = data.bernoulli()\n",
    "        \n",
    "        v,v1 = rbm(sample_data)\n",
    "        loss = rbm.free_energy(v) - rbm.free_energy(v1)\n",
    "        loss_.append(loss.data)\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "\n",
    "    print(\"Training loss for {} epoch: {}\".format(epoch, np.mean(loss_)))\n",
    "\n",
    "\n",
    "def show_adn_save(file_name,img):\n",
    "    npimg = np.transpose(img.numpy(),(1,2,0))\n",
    "    f = \"./%s.png\" % file_name\n",
    "    plt.imshow(npimg)\n",
    "    plt.imsave(f,npimg)\n",
    "\n",
    "show_adn_save(\"real\",make_grid(v.view(32,1,28,28).data))\n",
    "show_adn_save(\"generate\",make_grid(v1.view(32,1,28,28).data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5c2d1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Energy-based models and Langevin sampling\n",
    "\n",
    "See discussions in Foster, chapter 7 on energy-based models at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm>\n",
    "\n",
    "That notebook is based on a recent article by Du and Mordatch, **Implicit generation and modeling with energy-based models**, see <https://arxiv.org/pdf/1903.08689.pdf.>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1bbb9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Tensor-flow examples\n",
    "\n",
    "1. To create Boltzmann machine using Keras, see Babcock and Bali chapter 4, see <https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_4/models/rbm.py>\n",
    "\n",
    "2. See also Foster, chapter 7 on energy-based models at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/07_ebm/01_ebm>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c591bc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Kullback-Leibler divergence\n",
    "\n",
    "Before we continue, we need to remind ourselves about the\n",
    "Kullback-Leibler divergence introduced earlier.\n",
    "These metrics are useful for quantifying the similarity between two probability distributions.\n",
    "\n",
    "The Kullback–Leibler (KL) divergence, labeled $D_{KL}$,   measures how one probability distribution $p$ diverges from a second expected probability distribution $q$,\n",
    "that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6bd0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "D_{KL}(p \\| q) = \\int_x p(x) \\log \\frac{p(x)}{q(x)} dx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814968d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The KL-divegernce $D_{KL}$ achieves the minimum zero when $p(x) == q(x)$ everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fba04b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## VAEs\n",
    "\n",
    "Mathematically, we can imagine the latent variables and the data we\n",
    "observe as modeled by a joint distribution $p(\\boldsymbol{x}, \\boldsymbol{h};\\boldsymbol{\\Theta})$.  Recall one\n",
    "approach of generative modeling, termed likelihood-based, is to\n",
    "learn a model to maximize the likelihood $p(\\boldsymbol{x};\\boldsymbol{\\Theta})$ of all observed\n",
    "$\\boldsymbol{x}$.  There are two ways we can manipulate this joint distribution\n",
    "to recover the likelihood of purely our observed data $p(\\boldsymbol{x};\\boldsymbol{\\Theta})$; we can\n",
    "explicitly marginalize\n",
    "out the latent variable $\\boldsymbol{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e6025",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{x}) = \\int p(\\boldsymbol{x}, \\boldsymbol{h})d\\boldsymbol{h}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad99713",
   "metadata": {
    "editable": true
   },
   "source": [
    "or, we could also appeal to the chain rule of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aaf4fd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{x}) = \\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{p(\\boldsymbol{h}|\\boldsymbol{x})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2d108",
   "metadata": {
    "editable": true
   },
   "source": [
    "We suppress here the dependence\ton the optimization parameters $\\boldsymbol{\\Theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cf3b5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Introducing the encoder function\n",
    "\n",
    "Here, $q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})$ is a flexible approximate\n",
    "variational distribution with parameters $\\boldsymbol{\\phi}$ that we seek to\n",
    "optimize.  Intuitively, it can be thought of as a parameterizable\n",
    "model that is learned to estimate the true distribution over latent\n",
    "variables for given observations $\\boldsymbol{x}$; in other words, it seeks to\n",
    "approximate true posterior $p(\\boldsymbol{h}|\\boldsymbol{x})$.  As we saw last week when we\n",
    "explored Variational Autoencoders, as we increase the lower bound\n",
    "by tuning the parameters $\\boldsymbol{\\phi}$ to maximize the ELBO, we gain\n",
    "access to components that can be used to model the true data\n",
    "distribution and sample from it, thus learning a generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b57ab4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## ELBO\n",
    "\n",
    "To better understand the relationship between the evidence and the ELBO, let us perform another derivation, this time using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc411d18",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x}) & = \\log p(\\boldsymbol{x}) \\int q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})d\\boldsymbol{h} && \\text{(Multiply by $1 = \\int q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})d\\boldsymbol{h}$)}\\\\\n",
    "          & = \\int q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})(\\log p(\\boldsymbol{x}))d\\boldsymbol{h} && \\text{(Bring evidence into integral)}\\\\\n",
    "          & = \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log p(\\boldsymbol{x})\\right] && \\text{(Definition of Expectation)}\\\\\n",
    "          & = \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{p(\\boldsymbol{h}|\\boldsymbol{x})}\\right]&& \\\\\n",
    "          & = \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}{p(\\boldsymbol{h}|\\boldsymbol{x})q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right]&& \\text{(Multiply by $1 = \\frac{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}$)}\\\\\n",
    "          & = \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right] + \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}{p(\\boldsymbol{h}|\\boldsymbol{x})}\\right] && \\text{(Split the Expectation)}\\\\\n",
    "          & = \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right] +\n",
    "\t  D_{KL}(q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})\\vert\\vert p(\\boldsymbol{h}|\\boldsymbol{x}))  && \\text{(Definition of KL Divergence)}\\\\\n",
    "          & \\geq \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right]  && \\text{(KL Divergence always $\\geq 0$)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a96748",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The VAE\n",
    "\n",
    "In the default formulation of the VAE by Kingma and Welling (2015), we directly maximize the ELBO.  This\n",
    "approach is \\textit{variational}, because we optimize for the best\n",
    "$q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})$ amongst a family of potential posterior\n",
    "distributions parameterized by $\\boldsymbol{\\phi}$.  It is called an\n",
    "\\textit{autoencoder} because it is reminiscent of a traditional\n",
    "autoencoder model, where input data is trained to predict itself after\n",
    "undergoing an intermediate bottlenecking representation step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f3cef",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Dissecting the equations\n",
    "To make\n",
    "this connection explicit, let us dissect the ELBO term further:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1221fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "{\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{x}, \\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right]}\n",
    "&= {\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h})p(\\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right]}         && {\\text{(Chain Rule of Probability)}}\\\\\n",
    "&= {\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h})\\right] + \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log\\frac{p(\\boldsymbol{h})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\right]}         && {\\text{(Split the Expectation)}}\\\\\n",
    "&= \\underbrace{{\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h})\\right]}}_\\text{reconstruction term} - \\underbrace{{D_{KL}(q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\vert\\vert{p(\\boldsymbol{h}))}}_\\text{prior matching term} && {\\text{(Definition of KL Divergence)}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa12fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Bottlenecking distribution\n",
    "\n",
    "In this case, we learn an intermediate bottlenecking distribution\n",
    "$q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})$ that can be treated as\n",
    "an \\textit{encoder}; it transforms inputs into a distribution over\n",
    "possible latents.  Simultaneously, we learn a deterministic function\n",
    "$p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h})$ to convert a given latent vector\n",
    "$\\boldsymbol{h}$ into an observation $\\boldsymbol{x}$, which can be interpreted as\n",
    "a \\textit{decoder}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e267d81",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Decoder and encoder\n",
    "The two terms in the last equation each have intuitive descriptions: the first\n",
    "term measures the reconstruction likelihood of the decoder from our\n",
    "variational distribution; this ensures that the learned distribution\n",
    "is modeling effective latents that the original data can be\n",
    "regenerated from.  The second term measures how similar the learned\n",
    "variational distribution is to a prior belief held over latent\n",
    "variables.  Minimizing this term encourages the encoder to actually\n",
    "learn a distribution rather than collapse into a Dirac delta function.\n",
    "Maximizing the ELBO is thus equivalent to maximizing its first term\n",
    "and minimizing its second term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8aa4dd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Defining feature of VAEs\n",
    "\n",
    "A defining feature of the VAE is how the ELBO is optimized jointly over parameters $\\boldsymbol{\\phi}$ and $\\boldsymbol{\\theta}$.  The encoder of the VAE is commonly chosen to model a multivariate Gaussian with diagonal covariance, and the prior is often selected to be a standard multivariate Gaussian:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19b7282",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x}) &= N(\\boldsymbol{h}; \\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\boldsymbol{x}), \\boldsymbol{\\sigma}_{\\boldsymbol{\\phi}}^2(\\boldsymbol{x})\\textbf{I})\\\\\n",
    "    p(\\boldsymbol{h}) &= N(\\boldsymbol{h}; \\boldsymbol{0}, \\textbf{I})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a4bba",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Analytical evaluation\n",
    "\n",
    "Then, the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can be approximated using a Monte Carlo estimate.  Our objective can then be rewritten as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babb84d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "  \\mathrm{argmax}_{\\boldsymbol{\\phi}, \\boldsymbol{\\theta}} \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h})\\right] - D_{KL}(q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})\\vert\\vert p(\\boldsymbol{h})) \\approx \\mathrm{argmax}_{\\boldsymbol{\\phi}, \\boldsymbol{\\theta}} \\sum_{l=1}^{L}\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h}^{(l)}) - D_{KL}(q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})\\vert\\vert p(\\boldsymbol{h}))\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5062e",
   "metadata": {
    "editable": true
   },
   "source": [
    "where latents $\\{\\boldsymbol{h}^{(l)}\\}_{l=1}^L$ are sampled from $q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}|\\boldsymbol{x})$, for every observation $\\boldsymbol{x}$ in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb7dca",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, basics\n",
    "\n",
    "Diffusion models are inspired by non-equilibrium thermodynamics. They\n",
    "define a Markov chain of diffusion steps to slowly add random noise to\n",
    "data and then learn to reverse the diffusion process to construct\n",
    "desired data samples from the noise. Unlike VAE or flow models,\n",
    "diffusion models are learned with a fixed procedure and the latent\n",
    "variable has high dimensionality (same as the original data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675858f4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Problems with probabilistic models\n",
    "\n",
    "Historically, probabilistic models suffer from a tradeoff between two\n",
    "conflicting objectives: \\textit{tractability} and\n",
    "\\textit{flexibility}. Models that are \\textit{tractable} can be\n",
    "analytically evaluated and easily fit to data (e.g. a Gaussian or\n",
    "Laplace). However, these models are unable to aptly describe structure\n",
    "in rich datasets. On the other hand, models that are \\textit{flexible}\n",
    "can be molded to fit structure in arbitrary data. For example, we can\n",
    "define models in terms of any (non-negative) function $\\phi(\\boldsymbol{x})$\n",
    "yielding the flexible distribution $p\\left(\\boldsymbol{x}\\right) =\n",
    "\\frac{\\phi\\left(\\boldsymbol{x} \\right)}{Z}$, where $Z$ is a normalization\n",
    "constant. However, computing this normalization constant is generally\n",
    "intractable. Evaluating, training, or drawing samples from such\n",
    "flexible models typically requires a very expensive Monte Carlo\n",
    "process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf6364",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models\n",
    "Diffusion models have several interesting features\n",
    "* extreme flexibility in model structure,\n",
    "\n",
    "* exact sampling,\n",
    "\n",
    "* easy multiplication with other distributions, e.g. in order to compute a posterior, and\n",
    "\n",
    "* the model log likelihood, and the probability of individual states, to be cheaply evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcc894",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Original idea\n",
    "\n",
    "In the original formulation, one uses a Markov chain to gradually\n",
    "convert one distribution into another, an idea used in non-equilibrium\n",
    "statistical physics and sequential Monte Carlo. Diffusion models build\n",
    "a generative Markov chain which converts a simple known distribution\n",
    "(e.g. a Gaussian) into a target (data) distribution using a diffusion\n",
    "process. Rather than use this Markov chain to approximately evaluate a\n",
    "model which has been otherwise defined, one can  explicitly define the\n",
    "probabilistic model as the endpoint of the Markov chain. Since each\n",
    "step in the diffusion chain has an analytically evaluable probability,\n",
    "the full chain can also be analytically evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669ecff5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion learning\n",
    "\n",
    "Learning in this framework involves estimating small perturbations to\n",
    "a diffusion process. Estimating small, analytically tractable,\n",
    "perturbations is more tractable than explicitly describing the full\n",
    "distribution with a single, non-analytically-normalizable, potential\n",
    "function.  Furthermore, since a diffusion process exists for any\n",
    "smooth target distribution, this method can capture data distributions\n",
    "of arbitrary form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3390d2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mathematics of diffusion models\n",
    "\n",
    "Let us go back our discussions of the variational autoencoders from\n",
    "last week, see\n",
    "<https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb>. As\n",
    "a first attempt at understanding diffusion models, we can think of\n",
    "these as stacked VAEs, or better, recursive VAEs.\n",
    "\n",
    "Let us try to see why. As an intermediate step, we consider so-called\n",
    "hierarchical VAEs, which can be seen as a generalization of VAEs that\n",
    "include multiple hierarchies of latent spaces.\n",
    "\n",
    "**Note**: Many of the derivations and figures here are inspired and borrowed from the excellent exposition of diffusion models by Calvin Luo at <https://arxiv.org/abs/2208.11970>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8c759",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Chains of VAEs\n",
    "\n",
    "Markovian\n",
    "VAEs represent a  generative process where we use  Markov chain to build a hierarchy of VAEs.\n",
    "\n",
    "Each transition down the hierarchy is Markovian, where we decode each\n",
    "latent set of variables $\\boldsymbol{h}_t$ in terms of the previous latent variable $\\boldsymbol{h}_{t-1}$.\n",
    "Intuitively, and visually, this can be seen as simply stacking VAEs on\n",
    "top of each other (see figure next slide).\n",
    "\n",
    "One can think of such a model as a recursive VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb873f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mathematical representation\n",
    "\n",
    "Mathematically, we represent the joint distribution and the posterior\n",
    "of a Markovian VAE as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f0791",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T}) &= p(\\boldsymbol{h}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{h}_{t-1}|\\boldsymbol{h}_{t})\\\\\n",
    "    q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x}) &= q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_1|\\boldsymbol{x})\\prod_{t=2}^{T}q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{t}|\\boldsymbol{h}_{t-1})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62f491",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models for hierarchical VAE, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "A Markovian hierarchical Variational Autoencoder with $T$ hierarchical\n",
    "latents.  The generative process is modeled as a Markov chain, where\n",
    "each latent $\\boldsymbol{h}_t$ is generated only from the previous latent\n",
    "$\\boldsymbol{h}_{t+1}$. Here $\\boldsymbol{z}$ is our latent variable $\\boldsymbol{h}$.\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure1.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure1.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804bfc1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Equation for the Markovian hierarchical VAE\n",
    "\n",
    "We obtain then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4d040",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\right]\n",
    "&= \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{h}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{h}_{t-1}|\\boldsymbol{h}_{t})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_1|\\boldsymbol{x})\\prod_{t=2}^{T}q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{t}|\\boldsymbol{h}_{t-1})}\\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f162d",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will modify this equation when we discuss what are normally called Variational Diffusion Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226efeb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Variational Diffusion Models\n",
    "\n",
    "The easiest way to think of a Variational Diffusion Model (VDM) is as a Markovian Hierarchical Variational Autoencoder with three key restrictions:\n",
    "\n",
    "1. The latent dimension is exactly equal to the data dimension\n",
    "\n",
    "2. The structure of the latent encoder at each timestep is not learned; it is pre-defined as a linear Gaussian model.  In other words, it is a Gaussian distribution centered around the output of the previous timestep\n",
    "\n",
    "3. The Gaussian parameters of the latent encoders vary over time in such a way that the distribution of the latent at final timestep $T$ is a standard Gaussian\n",
    "\n",
    "The VDM posterior is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4c20e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0) = \\prod_{t = 1}^{T}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2f750",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Second assumption\n",
    "\n",
    "The distribution of each latent variable in the encoder is a Gaussian centered around its previous hierarchical latent.\n",
    "Here then, the structure of the encoder at each timestep $t$ is not learned; it\n",
    "is fixed as a linear Gaussian model, where the mean and standard\n",
    "deviation can be set beforehand as hyperparameters, or learned as\n",
    "parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09d46db",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Parameterizing Gaussian encoder\n",
    "\n",
    "We parameterize the Gaussian encoder with mean $\\boldsymbol{\\mu}_t(\\boldsymbol{x}_t) =\n",
    "\\sqrt{\\alpha_t} \\boldsymbol{x}_{t-1}$, and variance $\\boldsymbol{\\Sigma}_t(\\boldsymbol{x}_t) =\n",
    "(1 - \\alpha_t) \\textbf{I}$, where the form of the coefficients are\n",
    "chosen such that the variance of the latent variables stay at a\n",
    "similar scale; in other words, the encoding process is\n",
    "variance-preserving.\n",
    "\n",
    "Note that alternate Gaussian parameterizations\n",
    "are allowed, and lead to similar derivations.  The main takeaway is\n",
    "that $\\alpha_t$ is a (potentially learnable) coefficient that can vary\n",
    "with the hierarchical depth $t$, for flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea62cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Encoder transitions\n",
    "\n",
    "Mathematically, the encoder transitions are defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd04f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:27\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1}) = \\mathcal{N}(\\boldsymbol{x}_{t} ; \\sqrt{\\alpha_t} \\boldsymbol{x}_{t-1}, (1 - \\alpha_t) \\textbf{I}) \\label{eq:27} \\tag{1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295a8b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Third assumption\n",
    "\n",
    "From the third assumption, we know that $\\alpha_t$ evolves over time\n",
    "according to a fixed or learnable schedule structured such that the\n",
    "distribution of the final latent $p(\\boldsymbol{x}_T)$ is a standard Gaussian.\n",
    "We can then update the joint distribution of a Markovian VAE to write\n",
    "the joint distribution for a VDM as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d8023",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "p(\\boldsymbol{x}_{0:T}) &= p(\\boldsymbol{x}_T)\\prod_{t=1}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t) \\\\\n",
    "\\text{where,}&\\nonumber\\\\\n",
    "p(\\boldsymbol{x}_T) &= \\mathcal{N}(\\boldsymbol{x}_T; \\boldsymbol{0}, \\textbf{I})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e9b5c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Noisification\n",
    "\n",
    "Collectively, what this set of assumptions describes is a steady\n",
    "noisification of an image input over time. We progressively corrupt an\n",
    "image by adding Gaussian noise until eventually it becomes completely\n",
    "identical to pure Gaussian noise.  See figure on next slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87a7d5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure2.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure2.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06863ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Gaussian modeling\n",
    "\n",
    "Note that our encoder distributions $q(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})$ are no\n",
    "longer parameterized by $\\boldsymbol{\\phi}$, as they are completely modeled as\n",
    "Gaussians with defined mean and variance parameters at each timestep.\n",
    "Therefore, in a VDM, we are only interested in learning conditionals\n",
    "$p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_{t})$, so that we can simulate\n",
    "new data.  After optimizing the VDM, the sampling procedure is as\n",
    "simple as sampling Gaussian noise from $p(\\boldsymbol{x}_T)$ and iteratively\n",
    "running the denoising transitions\n",
    "$p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_{t})$ for $T$ steps to generate a\n",
    "novel $\\boldsymbol{x}_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d2333",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimizing the variational diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5f9f1f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x})\n",
    "&= \\log \\int p(\\boldsymbol{x}_{0:T}) d\\boldsymbol{x}_{1:T}\\\\\n",
    "&= \\log \\int \\frac{p(\\boldsymbol{x}_{0:T})q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)} d\\boldsymbol{x}_{1:T}\\\\\n",
    "&= \\log \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\frac{p(\\boldsymbol{x}_{0:T})}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\right]\\\\\n",
    "&\\geq {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_{0:T})}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)\\prod_{t=1}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t)}{\\prod_{t = 1}^{T}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\prod_{t = 1}^{T-1}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\prod_{t=1}^{T-1}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\prod_{t = 1}^{T-1}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\prod_{t = 1}^{T-1}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcefa42",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Continues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f34d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x})\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\prod_{t = 1}^{T-1}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[ \\sum_{t=1}^{T-1} \\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\sum_{t=1}^{T-1}\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[ \\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{T-1}, \\boldsymbol{x}_T|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\sum_{t=1}^{T-1}\\mathbb{E}_{q(\\boldsymbol{x}_{t-1}, \\boldsymbol{x}_t, \\boldsymbol{x}_{t+1}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eea74",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Interpretations\n",
    "\n",
    "These equations can be interpreted as\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{1}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right]$ can be interpreted as a **reconstruction term**, predicting the log probability of the original data sample given the first-step latent.  This term also appears in a vanilla VAE, and can be trained similarly.\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{T-1}|\\boldsymbol{x}_0)}\\left[D_{KL}(q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\vert\\vert p(\\boldsymbol{x}_T))\\right]$ is a **prior matching term**; it is minimized when the final latent distribution matches the Gaussian prior.  This term requires no optimization, as it has no trainable parameters; furthermore, as we have assumed a large enough $T$ such that the final distribution is Gaussian, this term effectively becomes zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d389cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The last term\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{t-1}, \\boldsymbol{x}_{t+1}|\\boldsymbol{x}_0)}\\left[D_{KL}(q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})\\vert\\vert p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1}))\\right]$ is a \\textit{consistency term}; it endeavors to make the distribution at $\\boldsymbol{x}_t$ consistent, from both forward and backward processes.  That is, a denoising step from a noisier image should match the corresponding noising step from a cleaner image, for every intermediate timestep; this is reflected mathematically by the KL Divergence.  This term is minimized when we train $p_{\\theta}(\\boldsymbol{x}_t|\\boldsymbol{x}_{t+1})$ to match the Gaussian distribution $q(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8fde2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, part 2, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure3.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure3.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9834b4c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization cost\n",
    "\n",
    "The cost of optimizing a VDM is primarily dominated by the third term, since we must optimize over all timesteps $t$.\n",
    "\n",
    "Under this derivation, all three terms are computed as expectations,\n",
    "and can therefore be approximated using Monte Carlo estimates.\n",
    "However, actually optimizing the ELBO using the terms we just derived\n",
    "might be suboptimal; because the consistency term is computed as an\n",
    "expectation over two random variables $\\left\\{\\boldsymbol{x}_{t-1},\n",
    "\\boldsymbol{x}_{t+1}\\right\\}$ for every timestep, the variance of its Monte\n",
    "Carlo estimate could potentially be higher than a term that is\n",
    "estimated using only one random variable per timestep.  As it is\n",
    "computed by summing up $T-1$ consistency terms, the final estimated\n",
    "value may have high variance for large $T$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0b910",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More details\n",
    "\n",
    "For more details and implementations, see Calvin Luo at <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- FIGURE: [figures/figure4.png, width=800 frac=1.0] -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b065d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What is a GAN?\n",
    "\n",
    "A GAN is a deep neural network which consists of two networks, a\n",
    "so-called generator network and a discriminating network, or just\n",
    "discriminator. Through several iterations of generation and\n",
    "discrimination, the idea is that these networks will train each other,\n",
    "while also trying to outsmart each other.\n",
    "\n",
    "In its simplest version, the two networks could be two standard neural networks with a given number of hidden of hidden layers and parameters to train.\n",
    "The generator we have trained can then be used to produce new images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d8e5f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Labeling the networks\n",
    "\n",
    "For a GAN we have: \n",
    "1. a discriminator $D$ estimates the probability of a given sample coming from the real dataset. It attempts at discriminating the trained data by the generator and is optimized to tell the fake samples from the real ones (our data set). We say a  discriminator tries to distinguish between real data and those generated by the abovementioned generator.\n",
    "\n",
    "2. a generator $G$ outputs synthetic samples given a noise variable input $z$ ($z$ brings in potential output diversity). It is trained to capture the real data distribution in order to generate samples that can be as real as possible, or in other words, can trick the discriminator to offer a high probability.\n",
    "\n",
    "At the end of the training, the generator can be used to generate for\n",
    "example new images. In this sense we have trained a model which can\n",
    "produce new samples. We say that we have implicitely defined a\n",
    "probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162af48c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Which data?\n",
    "\n",
    "**GANs are generally a form of unsupervised machine learning**, although\n",
    "they also incorporate aspects of supervised learning. Internally the\n",
    "discriminator sets up a supervised learning problem. Its goal is to\n",
    "learn to distinguish between the two classes of generated data and\n",
    "original data. The generator then considers this classification\n",
    "problem and tries to find adversarial examples, that is  samples which\n",
    "will be misclassified by the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9f587",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Semi-supervised learning\n",
    "\n",
    "One can also design GAN architectures which work in a\n",
    "semi-supervised learning setting. A semi-supervised learning environment includes both labeled and unlabeled data.\n",
    "See <https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf> for a further discussion.\n",
    "\n",
    "Thus, GANs can be used both on labeled and on unlabeled data and are used in three most commonly used contexts, that is\n",
    "1. with labeled data (supervised training)\n",
    "\n",
    "2. with unlabeled data (unsupervised learning)\n",
    "\n",
    "3. a with a mix labed and unlabeled  data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba620a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Improving functionalities\n",
    "\n",
    "These two models compete against each other during the training\n",
    "process: the generator $G$ is trying hard to trick the discriminator,\n",
    "while the critic model $D$ is trying hard not to be cheated. This\n",
    "interesting zero-sum game between two models motivates both to improve\n",
    "their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90969ce",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Setup of the GAN\n",
    "\n",
    "We define a probability $p_{\\boldsymbol{h}}$ which is used by the\n",
    "generator. Usually it is given by a uniform distribution over the\n",
    "input $\\boldsymbol{h}$. Thereafter we define the distribution of the\n",
    "generator which we want to train, $p_{g}$ This is the generator's\n",
    "distribution over the data $\\boldsymbol{x}$. Finally, we have the distribution\n",
    "$p_{r}$ over the real sample $\\boldsymbol{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9523e8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization part\n",
    "\n",
    "On one hand, we want to make sure the discriminator $D$'s decisions\n",
    "over real data are accurate by maximizing $\\mathbb{E}_{\\boldsymbol{x} \\sim\n",
    "p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})]$. Meanwhile, given a fake sample $G(\\boldsymbol{h}), \\boldsymbol{h} \\sim\n",
    "p_{\\boldsymbol{h}}(\\boldsymbol{h})$, the discriminator is expected to output a probability,\n",
    "$D(G(\\boldsymbol{h}))$, close to zero by maximizing $\\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})}\n",
    "[\\log (1 - D(G(\\boldsymbol{h})))]$.\n",
    "\n",
    "On the other hand, the generator is trained to increase the chances of\n",
    "$D$ producing a high probability for a fake example, thus to minimize\n",
    "$\\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})} [\\log (1 - D(G(\\boldsymbol{h})))]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ebca7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Minimax game\n",
    "\n",
    "When combining both aspects together, $D$ and $G$ are playing a **minimax game** in which we should optimize the following loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6888ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_G \\max_D L(D, G) \n",
    "& = \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})] + \\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})} [\\log(1 - D(G(\\boldsymbol{h})))] \\\\\n",
    "& = \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})] + \\mathbb{E}_{\\boldsymbol{x} \\sim p_g(\\boldsymbol{x})} [\\log(1 - D(\\boldsymbol{x})]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b668323",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})]$ has no impact on $G$ during gradient descent updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7308286",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimal value for $D$\n",
    "\n",
    "Now we have a well-defined loss function. Let's first examine what is the best value for $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ed8bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L(G, D) = \\int_{\\boldsymbol{x}} \\bigg( p_{r}(\\boldsymbol{x}) \\log(D(\\boldsymbol{x})) + p_g (\\boldsymbol{x}) \\log(1 - D(\\boldsymbol{x})) \\bigg) d\\boldsymbol{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5281910",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Best value of $D$\n",
    "Since we are interested in what is the best value of $D(\\boldsymbol{x})$ to maximize $L(G, D)$, let us label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7041f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\boldsymbol{x}} = D(\\boldsymbol{x}), \n",
    "A=p_{r}(\\boldsymbol{x}), \n",
    "B=p_g(\\boldsymbol{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a80e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Integral evaluation\n",
    "\n",
    "The integral (we can safely ignore the integral because $\\boldsymbol{x}$ is sampled over all the possible values) is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d12cd3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "f(\\tilde{\\boldsymbol{x}}) \n",
    "& = A \\log{\\tilde{\\boldsymbol{x}}} + B \\log{(1-\\tilde{\\boldsymbol{x}})} \\\\\n",
    "\\frac{d f(\\tilde{\\boldsymbol{x}})}{d \\tilde{\\boldsymbol{x}}} & = A \\frac{1}{\\tilde{\\boldsymbol{x}}} - B\\frac{1}{1 - \\tilde{\\boldsymbol{x}}} \\\\\n",
    "& = \\frac{A - (A + B)\\tilde{\\boldsymbol{x}}} {\\tilde{\\boldsymbol{x}} (1 - \\tilde{\\boldsymbol{x}})}. \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460b3cc",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Best values\n",
    "\n",
    "If we set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5bf194",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{d f(\\tilde{\\boldsymbol{x}})}{d \\tilde{\\boldsymbol{x}}} = 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef0a38",
   "metadata": {
    "editable": true
   },
   "source": [
    "we get\n",
    "the best value of the discriminator:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86772906",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "D^*(\\boldsymbol{x}) = \\tilde{\\boldsymbol{x}}^* =\\frac{A}{A + B} = \\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x}) + p_g(\\boldsymbol{x})}\n",
    "\\in [0, 1].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99361c",
   "metadata": {
    "editable": true
   },
   "source": [
    "Once the generator is trained to its optimal, $p_g$ gets\n",
    "very close to $p_{r}$. When $p_g = p_{r}$, $D^*(\\boldsymbol{x})$ becomes\n",
    "$1/2$. We will observe this when running the code from last week (see jupyter-notebook from week 15)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47463a7a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## At their optimal values\n",
    "\n",
    "When both $G$ and $D$ are at their optimal values, we have $p_g = p_{r}$ and $D^*(\\boldsymbol{x}) = 1/2$, the loss function becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d653ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "L(G, D^*) \n",
    "&= \\int_{\\boldsymbol{x}} \\bigg( p_{r}(\\boldsymbol{x}) \\log(D^*(\\boldsymbol{x})) + p_g (\\boldsymbol{x}) \\log(1 - D^*(\\boldsymbol{x})) \\bigg) d\\boldsymbol{x} \\\\\n",
    "&= \\log \\frac{1}{2} \\int_{\\boldsymbol{h}} p_{r}(\\boldsymbol{x}) d\\boldsymbol{x} + \\log \\frac{1}{2} \\int_{\\boldsymbol{x}} p_g(\\boldsymbol{x}) d\\boldsymbol{x} \\\\\n",
    "&= -2\\log2\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185eb5f5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What does the Loss Function Represent?\n",
    "\n",
    "The JS divergence between $p_{r}$ and $p_g$ can be computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba1379",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "D_{JS}(p_{r} \\| p_g) \n",
    "=& \\frac{1}{2} D_{KL}(p_{r} || \\frac{p_{r} + p_g}{2}) + \\frac{1}{2} D_{KL}(p_{g} || \\frac{p_{r} + p_g}{2}) \\\\\n",
    "=& \\frac{1}{2} \\bigg( \\log2 + \\int_x p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{r} + p_g(\\boldsymbol{x})} d\\boldsymbol{x} \\bigg) + \\\\& \\frac{1}{2} \\bigg( \\log2 + \\int_x p_g(\\boldsymbol{x}) \\log \\frac{p_g(\\boldsymbol{x})}{p_{r} + p_g(\\boldsymbol{x})} d\\boldsymbol{x} \\bigg) \\\\\n",
    "=& \\frac{1}{2} \\bigg( \\log4 + L(G, D^*) \\bigg)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d09cfa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What does the loss function quantify?\n",
    "\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436c162",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L(G, D^*) = 2D_{JS}(p_{r} \\| p_g) - 2\\log2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e27986",
   "metadata": {
    "editable": true
   },
   "source": [
    "The loss function of GANs quantifies the similarity between\n",
    "the generative data distribution $p_g$ and the real sample\n",
    "distribution $p_{r}$ by the so-called JS divergence when the discriminator is\n",
    "optimal. The best $G^*$ that replicates the real data distribution\n",
    "leads to the minimum $L(G^*, D^*) = -2\\log2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5498fb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Problems with GANs\n",
    "\n",
    "Although GANs have achieved  great success in the generation of realistic images, the training is not easy; The process is known to be slow and unstable.\n",
    "\n",
    "**Hard to reach equilibrium.**\n",
    "\n",
    "Two models are trained simultaneously to an equilibrium to a\n",
    "two-player non-cooperative game. However, each model updates its cost\n",
    "independently with no respect to another player in the game. Updating\n",
    "the gradient of both models concurrently cannot guarantee a\n",
    "convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2fc95",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Vanishing Gradient\n",
    "\n",
    "When the discriminator is perfect, we are guaranteed with\n",
    "$D(\\boldsymbol{x}) = 1, \\forall \\boldsymbol{x} \\in p_r$ and $D(\\boldsymbol{x}) = 0, \\forall \\boldsymbol{x} \\in p_g$.\n",
    "\n",
    "Then, the\n",
    "loss function $L$ falls to zero and we end up with no gradient to\n",
    "update the loss during learning iterations. One can encouter situations where \n",
    "the discriminator gets better and the gradient vanishes fast.\n",
    "\n",
    "As a result, training GANs may face the following problems \n",
    "1. If the discriminator behaves badly, the generator does not have accurate feedback and the loss function cannot represent the real data\n",
    "\n",
    "2. If the discriminator does a great job, the gradient of the loss function drops down to close to zero and the learning can become slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031da7ca",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Improved GANs\n",
    "\n",
    "One of the solutions to improved GANs training, is the introduction of\n",
    "what is called the Wasserstein diatance, which is a way to compute the\n",
    "difference/distance between two probability distribitions. For those\n",
    "interested in reading more, we recommend for example chapter 17 of\n",
    "Rashcka's et al textbook,\n",
    "Machine Learning with PyTorch and Scikit-Learn, chapter 17, see <https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17>\n",
    "\n",
    "For a definition of the Wasserstein distance, see for example <https://arxiv.org/pdf/2103.01678>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

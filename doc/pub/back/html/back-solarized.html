<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html back.do.txt --pygments_html_style=perldoc --html_style=solarized3 --html_links_in_new_window --html_output=back-solarized --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>
<link href="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/css/solarized_light_code.css" rel="stylesheet" type="text/css" title="light"/>
<script src="https://cdn.rawgit.com/doconce/doconce/master/bundled/html_styles/style_solarized_box/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<link href="https://thomasf.github.io/solarized-css/solarized-light.min.css" rel="stylesheet">
<style type="text/css">
h1 {color: #b58900;}  /* yellow */
/* h1 {color: #cb4b16;}  orange */
/* h1 {color: #d33682;}  magenta, the original choice of thomasf */
code { padding: 0px; background-color: inherit; }
pre {
  border: 0pt solid #93a1a1;
  box-shadow: none;
}
div { text-align: justify; text-justify: inter-word; }
.tab {
  padding-left: 1.5em;
}
div.toc p,a {
  line-height: 1.3;
  margin-top: 1.1;
  margin-bottom: 1.1;
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Imports and Utilities', 2, None, 'imports-and-utilities')]}
end of tocinfo -->

<body>
<!-- ------------------- main content ---------------------- -->
<center>
<h1>Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> 
</center>
<!-- institution -->
<center>
<b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<br>
<center>
<h4>May 8, 2025</h4>
</center> <!-- date -->
<br>

<!-- !split --><br><br><br><br><br><br><br><br><br><br>
<h2 id="imports-and-utilities">Imports and Utilities </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">nn</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn.functional</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">F</span>
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> <span style="color: #8B008B; font-weight: bold">import</span> datasets, transforms
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch.utils.data</span> <span style="color: #8B008B; font-weight: bold">import</span> DataLoader
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">math</span>

device = <span style="color: #CD5555">&#39;cuda&#39;</span> <span style="color: #8B008B; font-weight: bold">if</span> torch.cuda.is_available() <span style="color: #8B008B; font-weight: bold">else</span> <span style="color: #CD5555">&#39;cpu&#39;</span>

<span style="color: #228B22"># Training settings</span>
batch_size = <span style="color: #B452CD">128</span>
epochs     = <span style="color: #B452CD">5</span>
lr         = <span style="color: #B452CD">2e-4</span>
img_size   = <span style="color: #B452CD">28</span>
channels   = <span style="color: #B452CD">1</span>

<span style="color: #228B22"># Diffusion hyperparameters</span>
T = <span style="color: #B452CD">300</span>  <span style="color: #228B22"># number of diffusion steps  [oai_citation:5‡Medium](https://papers-100-lines.medium.com/diffusion-models-from-scratch-mnist-data-tutorial-in-100-lines-of-pytorch-code-a609e1558cee?utm_source=chatgpt.com)</span>
beta_start, beta_end = <span style="color: #B452CD">1e-4</span>, <span style="color: #B452CD">0.02</span>
betas = torch.linspace(beta_start, beta_end, T, device=device)  <span style="color: #228B22"># linear schedule  [oai_citation:6‡Medium](https://medium.com/data-science/diffusion-model-from-scratch-in-pytorch-ddpm-9d9760528946?utm_source=chatgpt.com)</span>
alphas = <span style="color: #B452CD">1.</span> - betas
alphas_cumprod = torch.cumprod(alphas, dim=<span style="color: #B452CD">0</span>)

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((<span style="color: #B452CD">0.5</span>,), (<span style="color: #B452CD">0.5</span>,)),
])

train_ds = datasets.MNIST(<span style="color: #CD5555">&#39;.&#39;</span>, train=<span style="color: #8B008B; font-weight: bold">True</span>, download=<span style="color: #8B008B; font-weight: bold">True</span>, transform=transform)
train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=<span style="color: #8B008B; font-weight: bold">True</span>)

<span style="color: #8B008B; font-weight: bold">class</span> <span style="color: #008b45; font-weight: bold">SimpleUNet</span>(nn.Module):
    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">__init__</span>(<span style="color: #658b00">self</span>, c):
        <span style="color: #658b00">super</span>().<span style="color: #008b45">__init__</span>()
        <span style="color: #658b00">self</span>.enc1 = nn.Conv2d(c, <span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, padding=<span style="color: #B452CD">1</span>)
        <span style="color: #658b00">self</span>.enc2 = nn.Conv2d(<span style="color: #B452CD">64</span>, <span style="color: #B452CD">128</span>, <span style="color: #B452CD">3</span>, padding=<span style="color: #B452CD">1</span>)
        <span style="color: #658b00">self</span>.dec1 = nn.ConvTranspose2d(<span style="color: #B452CD">128</span>, <span style="color: #B452CD">64</span>, <span style="color: #B452CD">3</span>, padding=<span style="color: #B452CD">1</span>)
        <span style="color: #658b00">self</span>.dec2 = nn.ConvTranspose2d(<span style="color: #B452CD">64</span>, c, <span style="color: #B452CD">3</span>, padding=<span style="color: #B452CD">1</span>)
        <span style="color: #658b00">self</span>.act  = nn.ReLU()
        <span style="color: #228B22"># timestep embedding to condition on t</span>
        <span style="color: #658b00">self</span>.time_mlp = nn.Sequential(
            nn.Linear(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">128</span>), <span style="color: #228B22"># Changed from 64 to 128</span>
            nn.ReLU(),
            nn.Linear(<span style="color: #B452CD">128</span>, <span style="color: #B452CD">128</span>), <span style="color: #228B22"># Changed from 64 to 128</span>
        )

    <span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">forward</span>(<span style="color: #658b00">self</span>, x, t):
        <span style="color: #228B22"># x: [B, C, H, W], t: [B]</span>
        h = <span style="color: #658b00">self</span>.act(<span style="color: #658b00">self</span>.enc1(x))
        h = <span style="color: #658b00">self</span>.act(<span style="color: #658b00">self</span>.enc2(h))
        <span style="color: #228B22"># add time embedding</span>
        t = t.unsqueeze(-<span style="color: #B452CD">1</span>)                             
        temb = <span style="color: #658b00">self</span>.time_mlp(t)
        temb = temb.view(-<span style="color: #B452CD">1</span>, <span style="color: #B452CD">128</span>, <span style="color: #B452CD">1</span>, <span style="color: #B452CD">1</span>) <span style="color: #228B22"># Changed from 64 to 128</span>
        h = h + temb
        h = <span style="color: #658b00">self</span>.act(<span style="color: #658b00">self</span>.dec1(h))
        <span style="color: #8B008B; font-weight: bold">return</span> <span style="color: #658b00">self</span>.dec2(h)
	
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">q_sample</span>(x0, t, noise=<span style="color: #8B008B; font-weight: bold">None</span>):
    <span style="color: #CD5555">&quot;&quot;&quot;Add noise to x0 at timestep t.&quot;&quot;&quot;</span>
    <span style="color: #8B008B; font-weight: bold">if</span> noise <span style="color: #8B008B">is</span> <span style="color: #8B008B; font-weight: bold">None</span>:
        noise = torch.randn_like(x0)
    sqrt_acp = alphas_cumprod[t]**<span style="color: #B452CD">0.5</span>
    sqrt_1macp = (<span style="color: #B452CD">1</span> - alphas_cumprod[t])**<span style="color: #B452CD">0.5</span>
    <span style="color: #8B008B; font-weight: bold">return</span> sqrt_acp.view(-<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>)*x0 + sqrt_1macp.view(-<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>)*noise

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">diffusion_loss</span>(model, x0):
    <span style="color: #CD5555">&quot;&quot;&quot;Compute MSE between predicted noise and true noise.&quot;&quot;&quot;</span>
    B = x0.size(<span style="color: #B452CD">0</span>)
    t = torch.randint(<span style="color: #B452CD">0</span>, T, (B,), device=device).long()
    noise = torch.randn_like(x0)
    x_noisy = q_sample(x0, t, noise)
    pred_noise = model(x_noisy, t.float()/T)
    <span style="color: #8B008B; font-weight: bold">return</span> F.mse_loss(pred_noise, noise)

model = SimpleUNet(channels).to(device)
opt   = torch.optim.Adam(model.parameters(), lr=lr)

<span style="color: #8B008B; font-weight: bold">for</span> epoch <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(epochs):
    total_loss = <span style="color: #B452CD">0</span>
    <span style="color: #8B008B; font-weight: bold">for</span> x, _ <span style="color: #8B008B">in</span> train_loader:
        x = x.to(device)
        loss = diffusion_loss(model, x)
        opt.zero_grad()
        loss.backward()
        opt.step()
        total_loss += loss.item()
    <span style="color: #658b00">print</span>(<span style="color: #CD5555">f&quot;Epoch {</span>epoch+<span style="color: #B452CD">1</span><span style="color: #CD5555">}/{</span>epochs<span style="color: #CD5555">}, Loss: {</span>total_loss/<span style="color: #658b00">len</span>(train_loader)<span style="color: #CD5555">:.4f}&quot;</span>)

<span style="color: #707a7c">@torch</span>.no_grad()
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">p_sample_loop</span>(model, shape):
    x = torch.randn(shape, device=device)
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">reversed</span>(<span style="color: #658b00">range</span>(T)):
        t = torch.full((shape[<span style="color: #B452CD">0</span>],), i, device=device).float()/T
        eps_pred = model(x, t)
        beta_t = betas[i]
        alpha_t = alphas[i]
        acp_t   = alphas_cumprod[i]
        coef1 = <span style="color: #B452CD">1</span> / alpha_t.sqrt()
        coef2 = beta_t / ( (<span style="color: #B452CD">1</span> - acp_t).sqrt() )
        x = coef1*(x - coef2*eps_pred)
        <span style="color: #8B008B; font-weight: bold">if</span> i &gt; <span style="color: #B452CD">0</span>:
            z = torch.randn_like(x)
            sigma = beta_t.sqrt()
            x = x + sigma*z
    <span style="color: #8B008B; font-weight: bold">return</span> x

<span style="color: #228B22"># Generate samples</span>
samples = p_sample_loop(model, (<span style="color: #B452CD">16</span>, channels, img_size, img_size))
samples = samples.clamp(-<span style="color: #B452CD">1</span>,<span style="color: #B452CD">1</span>).cpu()
grid = torchvision.utils.make_grid(samples, nrow=<span style="color: #B452CD">4</span>, normalize=<span style="color: #8B008B; font-weight: bold">True</span>)
plt.figure(figsize=(<span style="color: #B452CD">5</span>,<span style="color: #B452CD">5</span>))
plt.imshow(grid.permute(<span style="color: #B452CD">1</span>,<span style="color: #B452CD">2</span>,<span style="color: #B452CD">0</span>))
plt.axis(<span style="color: #CD5555">&#39;off&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<!-- ------------------- end of main content --------------- -->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2025, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>


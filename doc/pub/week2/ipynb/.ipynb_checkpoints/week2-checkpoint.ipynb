{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492c73a9",
   "metadata": {},
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week2.do.txt --no_mako -->\n",
    "<!-- dom:TITLE: January 30-February 3: Advanced machine learning and data analysis for the physical sciences -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35b946",
   "metadata": {},
   "source": [
    "# January 30-February 3: Advanced machine learning and data analysis for the physical sciences\n",
    "**Morten Hjorth-Jensen**, Department of Physics and Center for Computing in Science Education, University of Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **Feb 1, 2023**\n",
    "\n",
    "Copyright 1999-2023, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d70d00",
   "metadata": {},
   "source": [
    "## Overview of second  week\n",
    "\n",
    "1. Review of deep learning, basics of neural networks, see whiteboard notes today\n",
    "\n",
    "2. Discussion of paths for projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a169119",
   "metadata": {},
   "source": [
    "## Practicalities and possible projects\n",
    "\n",
    "1. Although the course is defined as a self-study course, we can have weekly lectures with small weekly exercise assignments\n",
    "\n",
    "2. We plan to work on two projects which will define the content of the course, the format can be agreed upon by the participants but the following topics could define an outline for possible projects and machine learning topics\n",
    "\n",
    " * Deep learning with the aim to develop a code for CNNs and/or RNNs and study data of relevance for own research ([Higgs challenge for example](https://github.com/CompPhysics/AdvancedMachineLearning/tree/main/doc/EarlierProjects/2022))\n",
    "\n",
    " * Study autoencoders and variational autoencoders with application to own data\n",
    "\n",
    " * GANs and applications to own data\n",
    "\n",
    " * Solve quantum/or classical many-body problems with deep learning methods (overlaps with FYS4411)\n",
    "\n",
    " * Physics informed Machine Learning, applications to for example solution of Navier-Stokes equations\n",
    "\n",
    " * Bayesian Machine Learning and Gaussian processes\n",
    "\n",
    " * and many other research paths and topics\n",
    "\n",
    "3. Final oral examination to be agreed upon\n",
    "\n",
    "4. All info at the GitHub address <https://github.com/CompPhysics/AdvancedMachineLearning>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ed754",
   "metadata": {},
   "source": [
    "## Deep learning methods covered\n",
    "\n",
    "1. Feed forward neural networks (NNs)\n",
    "\n",
    "2. Convolutional neural networks (CNNs)\n",
    "\n",
    "3. Recurrent neural networks (RNNs)\n",
    "\n",
    "4. Autoencoders (AEs) and variational autoencoders (VAEe)\n",
    "\n",
    "5. Generative Adversarial Networks (GANs)\n",
    "\n",
    "The [lecture notes](https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/intro.html) contain a more in depth discussion of these methods, in particular on neural networks, CNNs and RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db211a1",
   "metadata": {},
   "source": [
    "## [Autoencoders and Variational Autoencoders](https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/Autoencoders/ipynb/Autoencoders.ipynb)\n",
    "\n",
    "Autoencoders are artificial neural networks capable of learning\n",
    "efficient representations of the input data (these representations are\n",
    "called codings) without any supervision (i.e., the training set is\n",
    "unlabeled). These codings typically have a much lower dimensionality\n",
    "than the input data, making autoencoders useful for dimensionality\n",
    "reduction.\n",
    "\n",
    "More importantly, autoencoders act as powerful feature detectors, and\n",
    "they can be used for unsupervised pretraining of deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0a1db",
   "metadata": {},
   "source": [
    "## [GANs](https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/GenerativeAdversarialNetworks/ipynb/GenerativeAdversarialNetworks.ipynb)\n",
    "\n",
    "Generative modeling is an unsupervised learning task in machine\n",
    "learning that involves automatically discovering and learning the\n",
    "regularities or patterns in input data in such a way that the model\n",
    "can be used to generate or output new examples that plausibly could\n",
    "have been drawn from the original dataset.\n",
    "\n",
    "**Generative models** describe a class of statistical models that are a contrast\n",
    "to **discriminative models**. Informally we say that generative models can\n",
    "generate new data instances while discriminative models discriminate between\n",
    "different kinds of data instances. A generative model could generate new photos\n",
    "of animals that look like 'real' animals while a discriminative model could tell\n",
    "a dog from a cat. More formally, given a data set $x$ and a set of labels /\n",
    "targets $y$. Generative models capture the joint probability $p(x, y)$, or\n",
    "just $p(x)$ if there are no labels, while discriminative models capture the\n",
    "conditional probability $p(y | x)$. Discriminative models generally try to draw\n",
    "boundaries in the data space (often high dimensional), while generative models\n",
    "try to model how data is placed throughout the space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b548638",
   "metadata": {},
   "source": [
    "## [Kernel regression (Gaussian processes) and Bayesian statistics](https://jenfb.github.io/bkmr/overview.html)\n",
    "\n",
    "Kernel machine regression (KMR), also called Gaussian process\n",
    "regression, is a popular tool in the machine learning literature. The\n",
    "main idea behind KMR is to flexibly model the relationship between a\n",
    "large number of variables and a particular outcome (dependent\n",
    "variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a85f0c",
   "metadata": {},
   "source": [
    "## [Physics informed machine learning](https://github.com/maziarraissi/PINNs)\n",
    "\n",
    "Here we can discuss neural networks that are trained to solve\n",
    "supervised learning tasks while respecting any given law of physics\n",
    "described by general nonlinear partial differential equations. \n",
    "\n",
    "The following website is also interesting on [physics-based deep learning](https://physicsbaseddeeplearning.org/intro.html).\n",
    "\n",
    "See also <https://arxiv.org/abs/2211.08064>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

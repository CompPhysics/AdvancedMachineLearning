<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week15.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week15-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week15.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week15-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for the week of April 29- May 3, 2024',
               2,
               None,
               'plans-for-the-week-of-april-29-may-3-2024'),
              ('Readings', 2, None, 'readings'),
              ('Summary of Variational Autoencoders (VAEs)',
               2,
               None,
               'summary-of-variational-autoencoders-vaes'),
              ('Boltzmann machines and energy-based models and contrastive '
               'optimization',
               2,
               None,
               'boltzmann-machines-and-energy-based-models-and-contrastive-optimization'),
              ('The Kullback-Leibler divergence',
               2,
               None,
               'the-kullback-leibler-divergence'),
              ('What is a GAN?', 2, None, 'what-is-a-gan'),
              ('What is a generator network?',
               2,
               None,
               'what-is-a-generator-network'),
              ('And what is a discriminator network?',
               2,
               None,
               'and-what-is-a-discriminator-network'),
              ('Appplications of GANs', 2, None, 'appplications-of-gans'),
              ('Generative Adversarial Networks',
               2,
               None,
               'generative-adversarial-networks'),
              ('Discriminator', 2, None, 'discriminator'),
              ('Zero-sum game', 2, None, 'zero-sum-game'),
              ('Maximizing reward', 2, None, 'maximizing-reward'),
              ('Progression in training', 2, None, 'progression-in-training'),
              ('Deafault choice', 2, None, 'deafault-choice'),
              ('Design of GANs', 2, None, 'design-of-gans'),
              ('More references', 2, None, 'more-references'),
              ('Writing Our First Generative Adversarial Network',
               2,
               None,
               'writing-our-first-generative-adversarial-network'),
              ('Setting up the GAN', 2, None, 'setting-up-the-gan'),
              ('Printing the model', 2, None, 'printing-the-model'),
              ('Defining the training set',
               2,
               None,
               'defining-the-training-set'),
              ('Defining the training set',
               2,
               None,
               'defining-the-training-set'),
              ('Defining the training set',
               2,
               None,
               'defining-the-training-set'),
              ('Training the GAN', 2, None, 'training-the-gan'),
              ('Defining the training set',
               2,
               None,
               'defining-the-training-set'),
              ('Visualizing', 2, None, 'visualizing'),
              ('Diffusion models, basics', 2, None, 'diffusion-models-basics'),
              ('Mathematics of diffusion models',
               2,
               None,
               'mathematics-of-diffusion-models')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "AMS"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week15-bs.html">Advanced machine learning and data analysis for the physical sciences</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="#plans-for-the-week-of-april-29-may-3-2024" style="font-size: 80%;">Plans for the week of April 29- May 3, 2024</a></li>
     <!-- navigation toc: --> <li><a href="#readings" style="font-size: 80%;">Readings</a></li>
     <!-- navigation toc: --> <li><a href="#summary-of-variational-autoencoders-vaes" style="font-size: 80%;">Summary of Variational Autoencoders (VAEs)</a></li>
     <!-- navigation toc: --> <li><a href="#boltzmann-machines-and-energy-based-models-and-contrastive-optimization" style="font-size: 80%;">Boltzmann machines and energy-based models and contrastive optimization</a></li>
     <!-- navigation toc: --> <li><a href="#the-kullback-leibler-divergence" style="font-size: 80%;">The Kullback-Leibler divergence</a></li>
     <!-- navigation toc: --> <li><a href="#what-is-a-gan" style="font-size: 80%;">What is a GAN?</a></li>
     <!-- navigation toc: --> <li><a href="#what-is-a-generator-network" style="font-size: 80%;">What is a generator network?</a></li>
     <!-- navigation toc: --> <li><a href="#and-what-is-a-discriminator-network" style="font-size: 80%;">And what is a discriminator network?</a></li>
     <!-- navigation toc: --> <li><a href="#appplications-of-gans" style="font-size: 80%;">Appplications of GANs</a></li>
     <!-- navigation toc: --> <li><a href="#generative-adversarial-networks" style="font-size: 80%;">Generative Adversarial Networks</a></li>
     <!-- navigation toc: --> <li><a href="#discriminator" style="font-size: 80%;">Discriminator</a></li>
     <!-- navigation toc: --> <li><a href="#zero-sum-game" style="font-size: 80%;">Zero-sum game</a></li>
     <!-- navigation toc: --> <li><a href="#maximizing-reward" style="font-size: 80%;">Maximizing reward</a></li>
     <!-- navigation toc: --> <li><a href="#progression-in-training" style="font-size: 80%;">Progression in training</a></li>
     <!-- navigation toc: --> <li><a href="#deafault-choice" style="font-size: 80%;">Deafault choice</a></li>
     <!-- navigation toc: --> <li><a href="#design-of-gans" style="font-size: 80%;">Design of GANs</a></li>
     <!-- navigation toc: --> <li><a href="#more-references" style="font-size: 80%;">More references</a></li>
     <!-- navigation toc: --> <li><a href="#writing-our-first-generative-adversarial-network" style="font-size: 80%;">Writing Our First Generative Adversarial Network</a></li>
     <!-- navigation toc: --> <li><a href="#setting-up-the-gan" style="font-size: 80%;">Setting up the GAN</a></li>
     <!-- navigation toc: --> <li><a href="#printing-the-model" style="font-size: 80%;">Printing the model</a></li>
     <!-- navigation toc: --> <li><a href="#defining-the-training-set" style="font-size: 80%;">Defining the training set</a></li>
     <!-- navigation toc: --> <li><a href="#defining-the-training-set" style="font-size: 80%;">Defining the training set</a></li>
     <!-- navigation toc: --> <li><a href="#defining-the-training-set" style="font-size: 80%;">Defining the training set</a></li>
     <!-- navigation toc: --> <li><a href="#training-the-gan" style="font-size: 80%;">Training the GAN</a></li>
     <!-- navigation toc: --> <li><a href="#defining-the-training-set" style="font-size: 80%;">Defining the training set</a></li>
     <!-- navigation toc: --> <li><a href="#visualizing" style="font-size: 80%;">Visualizing</a></li>
     <!-- navigation toc: --> <li><a href="#diffusion-models-basics" style="font-size: 80%;">Diffusion models, basics</a></li>
     <!-- navigation toc: --> <li><a href="#mathematics-of-diffusion-models" style="font-size: 80%;">Mathematics of diffusion models</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<!-- ------------------- main content ---------------------- -->
<div class="jumbotron">
<center>
<h1>Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA</b>
</center>
<br>
<center>
<h4>April 30, 2024</h4>
</center> <!-- date -->
<br>


</div> <!-- end jumbotron -->
<h2 id="plans-for-the-week-of-april-29-may-3-2024" class="anchor">Plans for the week of April 29- May 3, 2024  </h2>

<div class="panel panel-default">
<div class="panel-body">
<!-- subsequent paragraphs come in larger fonts, so start with a paragraph -->
<ol>
<li> Summary of Variational Autoencoders</li>
<li> Generative Adversarial Networks (GANs)</li>
<li> Discussion of diffusion models
<!-- o <a href="https://youtu.be/rw-NBN293o4" target="_self">Video of lecture</a> -->
<!-- o <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesApril30.pdf" target="_self">Whiteboard notes</a> --></li>
</ol>
</div>
</div>


<!-- !split -->
<h2 id="readings" class="anchor">Readings </h2>
<div class="panel panel-default">
<div class="panel-body">
<!-- subsequent paragraphs come in larger fonts, so start with a paragraph -->
<ol>
<li> Reading recommendation: Goodfellow et al, for GANs see sections 20.10-20.11</li>
<li> For codes and background, see Raschka et al, Machine with PyTorch and Scikit-Learn, chapter 17, see <a href="https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17" target="_self"><tt>https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17</tt></a> for codes</li>
<li> Babcock and Bali, Generative AI with Python and TensorFlow2, chapter 6 and codes at <a href="https://github.com/raghavbali/generative_ai_with_tensorflow/blob/master/Chapter_6/conditional_gan.ipynb" target="_self"><tt>https://github.com/raghavbali/generative_ai_with_tensorflow/blob/master/Chapter_6/conditional_gan.ipynb</tt></a></li>
</ol>
</div>
</div>


<!-- !split -->
<h2 id="summary-of-variational-autoencoders-vaes" class="anchor">Summary of Variational Autoencoders (VAEs) </h2>

<p>In our short summary of VAes, we will also remind you about the
mathematics of Boltzmann machines and the Kullback-Leibler divergence,
leading to used ways to optimize the probability
distributions, namely what is called 
</p>
<ul>
<li> Contrastive optimization</li>
</ul>
<p>We will also discuss what is called</p>
<ul>
<li> Score-based models</li>
</ul>
<!-- !split -->
<h2 id="boltzmann-machines-and-energy-based-models-and-contrastive-optimization" class="anchor">Boltzmann machines and energy-based models and contrastive optimization </h2>

<p>Text to be added here</p>

<!-- !split -->
<h2 id="the-kullback-leibler-divergence" class="anchor">The Kullback-Leibler divergence </h2>

<!-- !split -->
<h2 id="what-is-a-gan" class="anchor">What is a GAN? </h2>

<p>A GAN is a deep neural network which consists of two networks, a
so-called generator network and a discriminating network, or just
discriminator. Through several iterations of generation and
discrimination, the idea is that these networks will train each other,
while also trying to outsmart each other.
</p>

<!-- !split -->
<h2 id="what-is-a-generator-network" class="anchor">What is a generator network? </h2>

<p>A generator network is often a deep network which uses existing data
to generate new data (from for example simulations of physical
systems, imagesm video, audio and more) from randomly generated
inputs, the so-called latent space. Training the network allows us to
generate say new data, images etc. As an example a generator network
could for example be a Boltzmann machine as discussed earlier. This
machine is trained to produce for example a quantum mechanical
probability distribution.
</p>

<p>It can be a simple neural network with an input layer and an output layer and a given number of hidden layers.</p>

<!-- !split -->
<h2 id="and-what-is-a-discriminator-network" class="anchor">And what is a discriminator network? </h2>

<p>A discriminator tries to distinguish between real data and those generated by the abovementioned generator.</p>

<!-- !split -->
<h2 id="appplications-of-gans" class="anchor">Appplications of GANs </h2>

<p>There are exteremely many applications of GANs</p>
<ol>
<li> Image generation</li>
<li> Text-to-image analysis</li>
<li> Face-aging</li>
<li> Image-to-image translation</li>
<li> Video synthesis</li>
<li> High-resolution image generation</li>
<li> Completing missing parts of images and much more</li>
</ol>
<!-- !split -->
<h2 id="generative-adversarial-networks" class="anchor">Generative Adversarial Networks </h2>

<p><b>Generative Adversarial Networks</b> are a type of unsupervised machine learning
algorithm proposed by Goodfellow et. al, see <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_self"><tt>https://arxiv.org/pdf/1406.2661.pdf</tt></a>
in 2014 (Read the paper first it's only 6 pages). The simplest formulation of
the model is based on a game theoretic approach, <em>zero sum game</em>, where we pit
two neural networks against one another. We define two rival networks, one
generator \( g \), and one discriminator \( d \). The generator directly produces
samples
</p>
$$
    x = g(z; \theta^{(g)}).
$$


<!-- !split -->
<h2 id="discriminator" class="anchor">Discriminator </h2>

<p>The discriminator attempts to distinguish between samples drawn from the
training data and samples drawn from the generator. In other words, it tries to
tell the difference between the fake data produced by \( g \) and the actual data
samples we want to do prediction on. The discriminator outputs a probability
value given by
</p>

$$
    d(x; \theta^{(d)}).
$$

<p>indicating the probability that \( x \) is a real training example rather than a
fake sample the generator has generated.
</p>

<!-- !split -->
<h2 id="zero-sum-game" class="anchor">Zero-sum game </h2>

<p>The simplest way to formulate the
learning process in a generative adversarial network is a zero-sum game, in
which a function
</p>

$$
    v(\theta^{(g)}, \theta^{(d)}),
$$

<p>determines the reward for the discriminator, while the generator gets the
conjugate reward
</p>

$$
    -v(\theta^{(g)}, \theta^{(d)})
$$


<!-- !split -->
<h2 id="maximizing-reward" class="anchor">Maximizing reward </h2>

<p>During learning both of the networks maximize their own reward function, so that
the generator gets better and better at tricking the discriminator, while the
discriminator gets better and better at telling the difference between the fake
and real data. The generator and discriminator alternate on which one trains at
one time (i.e. for one epoch). In other words, we keep the generator constant
and train the discriminator, then we keep the discriminator constant to train
the generator and repeat. It is this back and forth dynamic which lets GANs
tackle otherwise intractable generative problems. As the generator improves with
 training, the discriminator's performance gets worse because it cannot easily
 tell the difference between real and fake. If the generator ends up succeeding
 perfectly, the the discriminator will do no better than random guessing i.e.
 50\%.
</p>

<!-- !split -->
<h2 id="progression-in-training" class="anchor">Progression in training </h2>

<p>This progression in the training poses a problem for the convergence
 criteria for GANs. The discriminator feedback gets less meaningful over time,
 if we continue training after this point then the generator is effectively
 training on junk data which can undo the learning up to that point. Therefore,
 we stop training when the discriminator starts outputting \( 1/2 \) everywhere.
 At convergence we have
</p>

$$
    g^* = \underset{g}{\mathrm{argmin}}\hspace{2pt}
          \underset{d}{\mathrm{max}}v(\theta^{(g)}, \theta^{(d)}),
$$


<!-- !split -->
<h2 id="deafault-choice" class="anchor">Deafault choice </h2>
<p>The default choice for \( v \) is</p>
$$
    v(\theta^{(g)}, \theta^{(d)}) = \mathbb{E}_{x\sim p_\mathrm{data}}\log d(x)
                                  + \mathbb{E}_{x\sim p_\mathrm{model}}
                                  \log (1 - d(x)).
$$


<!-- !split -->
<h2 id="design-of-gans" class="anchor">Design of GANs </h2>
<p>The main motivation for the design of GANs is that the learning process requires
neither approximate inference (variational autoencoders for example) nor
approximation of a partition function. In the case where
</p>
$$
    \underset{d}{\mathrm{max}}v(\theta^{(g)}, \theta^{(d)})
$$

<p>is convex in \( \theta^{(g)} \) then the procedure is guaranteed to converge and is
asymptotically consistent
( <a href="https://arxiv.org/pdf/1804.09139.pdf" target="_self">Seth Lloyd on QuGANs</a>  ). This is in
general not the case and it is possible to get situations where the training
process never converges because the generator and discriminator chase one
another around in the parameter space indefinitely.
</p>

<!-- !split -->
<h2 id="more-references" class="anchor">More references </h2>

<p>A much deeper discussion on
the currently open research problem of GAN convergence is available
from <a href="https://www.deeplearningbook.org/contents/generative_models.html" target="_self"><tt>https://www.deeplearningbook.org/contents/generative_models.html</tt></a>. To
anyone interested in learning more about GANs it is a highly recommended read.
Direct quote: <b>In this best-performing formulation, the generator aims to
increase the log probability that the discriminator makes a mistake, rather than
aiming to decrease the log probability that the discriminator makes the correct
prediction.</b> Another interesting read can be found at <a href="https://arxiv.org/abs/1701.00160" target="_self"><tt>https://arxiv.org/abs/1701.00160</tt></a>.
</p>

<!-- !split -->
<h2 id="writing-our-first-generative-adversarial-network" class="anchor">Writing Our First Generative Adversarial Network </h2>

<p>This part is best seen using the jupyter-notebook. We follow here
closely the code developed by Raschka et al from chapter 17 of their
textbook, see <a href="https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17" target="_self"><tt>https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17</tt></a> for codes.
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">torch</span>
<span style="color: #008000">print</span>(torch<span style="color: #666666">.</span>__version__)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;GPU Available:&quot;</span>, torch<span style="color: #666666">.</span>cuda<span style="color: #666666">.</span>is_available())

<span style="color: #008000; font-weight: bold">if</span> torch<span style="color: #666666">.</span>cuda<span style="color: #666666">.</span>is_available():
    device <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>device(<span style="color: #BA2121">&quot;cuda:0&quot;</span>)
<span style="color: #008000; font-weight: bold">else</span>:
    device <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;cpu&quot;</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">torch.nn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">nn</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="setting-up-the-gan" class="anchor">Setting up the GAN </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic">## define a function for the generator:</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">make_generator_network</span>(
        input_size<span style="color: #666666">=20</span>,
        num_hidden_layers<span style="color: #666666">=1</span>,
        num_hidden_units<span style="color: #666666">=100</span>,
        num_output_units<span style="color: #666666">=784</span>):
    model <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>Sequential()
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_hidden_layers):
        model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;fc_g</span><span style="color: #BB6688; font-weight: bold">{</span>i<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                         nn<span style="color: #666666">.</span>Linear(input_size, 
                                   num_hidden_units)) 
        model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;relu_g</span><span style="color: #BB6688; font-weight: bold">{</span>i<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                         nn<span style="color: #666666">.</span>LeakyReLU())     
        input_size <span style="color: #666666">=</span> num_hidden_units
    model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;fc_g</span><span style="color: #BB6688; font-weight: bold">{</span>num_hidden_layers<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                    nn<span style="color: #666666">.</span>Linear(input_size, num_output_units))   
    model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">&#39;tanh_g&#39;</span>, nn<span style="color: #666666">.</span>Tanh())      
    <span style="color: #008000; font-weight: bold">return</span> model

<span style="color: #408080; font-style: italic">## define a function for the discriminator:</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">make_discriminator_network</span>(
        input_size,
        num_hidden_layers<span style="color: #666666">=1</span>,
        num_hidden_units<span style="color: #666666">=100</span>,
        num_output_units<span style="color: #666666">=1</span>):
    model <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>Sequential()
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(num_hidden_layers):
        model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;fc_d</span><span style="color: #BB6688; font-weight: bold">{</span>i<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                 nn<span style="color: #666666">.</span>Linear(input_size, 
                           num_hidden_units, bias<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)) 
        model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;relu_d</span><span style="color: #BB6688; font-weight: bold">{</span>i<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                         nn<span style="color: #666666">.</span>LeakyReLU())  
        model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">&#39;dropout&#39;</span>, nn<span style="color: #666666">.</span>Dropout(p<span style="color: #666666">=0.5</span>))
        input_size <span style="color: #666666">=</span> num_hidden_units
    model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">f&#39;fc_d</span><span style="color: #BB6688; font-weight: bold">{</span>num_hidden_layers<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>, 
                     nn<span style="color: #666666">.</span>Linear(input_size, num_output_units))   
    model<span style="color: #666666">.</span>add_module(<span style="color: #BA2121">&#39;sigmoid&#39;</span>, nn<span style="color: #666666">.</span>Sigmoid())
    <span style="color: #008000; font-weight: bold">return</span> model
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="printing-the-model" class="anchor">Printing the model </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">image_size <span style="color: #666666">=</span> (<span style="color: #666666">28</span>, <span style="color: #666666">28</span>)
z_size <span style="color: #666666">=</span> <span style="color: #666666">20</span>

gen_hidden_layers <span style="color: #666666">=</span> <span style="color: #666666">1</span>
gen_hidden_size <span style="color: #666666">=</span> <span style="color: #666666">100</span>
disc_hidden_layers <span style="color: #666666">=</span> <span style="color: #666666">1</span>
disc_hidden_size <span style="color: #666666">=</span> <span style="color: #666666">100</span>

torch<span style="color: #666666">.</span>manual_seed(<span style="color: #666666">1</span>)

gen_model <span style="color: #666666">=</span> make_generator_network(
    input_size<span style="color: #666666">=</span>z_size,
    num_hidden_layers<span style="color: #666666">=</span>gen_hidden_layers, 
    num_hidden_units<span style="color: #666666">=</span>gen_hidden_size,
    num_output_units<span style="color: #666666">=</span>np<span style="color: #666666">.</span>prod(image_size))
 
<span style="color: #008000">print</span>(gen_model)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">disc_model <span style="color: #666666">=</span> make_discriminator_network(
    input_size<span style="color: #666666">=</span>np<span style="color: #666666">.</span>prod(image_size),
    num_hidden_layers<span style="color: #666666">=</span>disc_hidden_layers,
    num_hidden_units<span style="color: #666666">=</span>disc_hidden_size)

<span style="color: #008000">print</span>(disc_model)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="defining-the-training-set" class="anchor">Defining the training set </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="defining-the-training-set" class="anchor">Defining the training set </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">torchvision</span> 
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">torchvision</span> <span style="color: #008000; font-weight: bold">import</span> transforms 


image_path <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;./&#39;</span>
transform <span style="color: #666666">=</span> transforms<span style="color: #666666">.</span>Compose([
    transforms<span style="color: #666666">.</span>ToTensor(),
    transforms<span style="color: #666666">.</span>Normalize(mean<span style="color: #666666">=</span>(<span style="color: #666666">0.5</span>), std<span style="color: #666666">=</span>(<span style="color: #666666">0.5</span>)),
])
mnist_dataset <span style="color: #666666">=</span> torchvision<span style="color: #666666">.</span>datasets<span style="color: #666666">.</span>MNIST(root<span style="color: #666666">=</span>image_path, 
                                           train<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, 
                                           transform<span style="color: #666666">=</span>transform, 
                                           download<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)

example, label <span style="color: #666666">=</span> <span style="color: #008000">next</span>(<span style="color: #008000">iter</span>(mnist_dataset))
<span style="color: #008000">print</span>(<span style="color: #BA2121">f&#39;Min: </span><span style="color: #BB6688; font-weight: bold">{</span>example<span style="color: #666666">.</span>min()<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121"> Max: </span><span style="color: #BB6688; font-weight: bold">{</span>example<span style="color: #666666">.</span>max()<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>)
<span style="color: #008000">print</span>(example<span style="color: #666666">.</span>shape)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="defining-the-training-set" class="anchor">Defining the training set </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">create_noise</span>(batch_size, z_size, mode_z):
    <span style="color: #008000; font-weight: bold">if</span> mode_z <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;uniform&#39;</span>:
        input_z <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>rand(batch_size, z_size)<span style="color: #666666">*2</span> <span style="color: #666666">-</span> <span style="color: #666666">1</span> 
    <span style="color: #008000; font-weight: bold">elif</span> mode_z <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;normal&#39;</span>:
        input_z <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>randn(batch_size, z_size)
    <span style="color: #008000; font-weight: bold">return</span> input_z


<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">torch.utils.data</span> <span style="color: #008000; font-weight: bold">import</span> DataLoader


batch_size <span style="color: #666666">=</span> <span style="color: #666666">32</span>
dataloader <span style="color: #666666">=</span> DataLoader(mnist_dataset, batch_size, shuffle<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)
input_real, label <span style="color: #666666">=</span> <span style="color: #008000">next</span>(<span style="color: #008000">iter</span>(dataloader))
input_real <span style="color: #666666">=</span> input_real<span style="color: #666666">.</span>view(batch_size, <span style="color: #666666">-1</span>)

torch<span style="color: #666666">.</span>manual_seed(<span style="color: #666666">1</span>)
mode_z <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;uniform&#39;</span>  <span style="color: #408080; font-style: italic"># &#39;uniform&#39; vs. &#39;normal&#39;</span>
input_z <span style="color: #666666">=</span> create_noise(batch_size, z_size, mode_z)

<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;input-z -- shape:&#39;</span>, input_z<span style="color: #666666">.</span>shape)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;input-real -- shape:&#39;</span>, input_real<span style="color: #666666">.</span>shape)

g_output <span style="color: #666666">=</span> gen_model(input_z)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Output of G -- shape:&#39;</span>, g_output<span style="color: #666666">.</span>shape)

d_proba_real <span style="color: #666666">=</span> disc_model(input_real)
d_proba_fake <span style="color: #666666">=</span> disc_model(g_output)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Disc. (real) -- shape:&#39;</span>, d_proba_real<span style="color: #666666">.</span>shape)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Disc. (fake) -- shape:&#39;</span>, d_proba_fake<span style="color: #666666">.</span>shape)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="training-the-gan" class="anchor">Training the GAN </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">loss_fn <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>BCELoss()

<span style="color: #408080; font-style: italic">## Loss for the Generator</span>
g_labels_real <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>ones_like(d_proba_fake)
g_loss <span style="color: #666666">=</span> loss_fn(d_proba_fake, g_labels_real)
<span style="color: #008000">print</span>(<span style="color: #BA2121">f&#39;Generator Loss: </span><span style="color: #BB6688; font-weight: bold">{</span>g_loss<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>)

<span style="color: #408080; font-style: italic">## Loss for the Discriminator</span>
d_labels_real <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>ones_like(d_proba_real)
d_labels_fake <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>zeros_like(d_proba_fake)

d_loss_real <span style="color: #666666">=</span> loss_fn(d_proba_real, d_labels_real)
d_loss_fake <span style="color: #666666">=</span> loss_fn(d_proba_fake, d_labels_fake)
<span style="color: #008000">print</span>(<span style="color: #BA2121">f&#39;Discriminator Losses: Real </span><span style="color: #BB6688; font-weight: bold">{</span>d_loss_real<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121"> Fake </span><span style="color: #BB6688; font-weight: bold">{</span>d_loss_fake<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="defining-the-training-set" class="anchor">Defining the training set </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">batch_size <span style="color: #666666">=</span> <span style="color: #666666">64</span>

torch<span style="color: #666666">.</span>manual_seed(<span style="color: #666666">1</span>)
np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">1</span>)

<span style="color: #408080; font-style: italic">## Set up the dataset</span>
mnist_dl <span style="color: #666666">=</span> DataLoader(mnist_dataset, batch_size<span style="color: #666666">=</span>batch_size, 
                      shuffle<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, drop_last<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>)
 
<span style="color: #408080; font-style: italic">## Set up the models</span>
gen_model <span style="color: #666666">=</span> make_generator_network(
    input_size<span style="color: #666666">=</span>z_size,
    num_hidden_layers<span style="color: #666666">=</span>gen_hidden_layers, 
    num_hidden_units<span style="color: #666666">=</span>gen_hidden_size,
    num_output_units<span style="color: #666666">=</span>np<span style="color: #666666">.</span>prod(image_size))<span style="color: #666666">.</span>to(device)
 
disc_model <span style="color: #666666">=</span> make_discriminator_network(
    input_size<span style="color: #666666">=</span>np<span style="color: #666666">.</span>prod(image_size),
    num_hidden_layers<span style="color: #666666">=</span>disc_hidden_layers,
    num_hidden_units<span style="color: #666666">=</span>disc_hidden_size)<span style="color: #666666">.</span>to(device)
 
<span style="color: #408080; font-style: italic">## Loss function and optimizers:</span>
loss_fn <span style="color: #666666">=</span> nn<span style="color: #666666">.</span>BCELoss()
g_optimizer <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>optim<span style="color: #666666">.</span>Adam(gen_model<span style="color: #666666">.</span>parameters())
d_optimizer <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>optim<span style="color: #666666">.</span>Adam(disc_model<span style="color: #666666">.</span>parameters())

<span style="color: #408080; font-style: italic">## Train the discriminator</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">d_train</span>(x):
    disc_model<span style="color: #666666">.</span>zero_grad()

    <span style="color: #408080; font-style: italic"># Train discriminator with a real batch</span>
    batch_size <span style="color: #666666">=</span> x<span style="color: #666666">.</span>size(<span style="color: #666666">0</span>)
    x <span style="color: #666666">=</span> x<span style="color: #666666">.</span>view(batch_size, <span style="color: #666666">-1</span>)<span style="color: #666666">.</span>to(device)
    d_labels_real <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>ones(batch_size, <span style="color: #666666">1</span>, device<span style="color: #666666">=</span>device)

    d_proba_real <span style="color: #666666">=</span> disc_model(x)
    d_loss_real <span style="color: #666666">=</span> loss_fn(d_proba_real, d_labels_real)

    <span style="color: #408080; font-style: italic"># Train discriminator on a fake batch</span>
    input_z <span style="color: #666666">=</span> create_noise(batch_size, z_size, mode_z)<span style="color: #666666">.</span>to(device)
    g_output <span style="color: #666666">=</span> gen_model(input_z)
    
    d_proba_fake <span style="color: #666666">=</span> disc_model(g_output)
    d_labels_fake <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>zeros(batch_size, <span style="color: #666666">1</span>, device<span style="color: #666666">=</span>device)
    d_loss_fake <span style="color: #666666">=</span> loss_fn(d_proba_fake, d_labels_fake)

    <span style="color: #408080; font-style: italic"># gradient backprop &amp; optimize ONLY D&#39;s parameters</span>
    d_loss <span style="color: #666666">=</span> d_loss_real <span style="color: #666666">+</span> d_loss_fake
    d_loss<span style="color: #666666">.</span>backward()
    d_optimizer<span style="color: #666666">.</span>step()
  
    <span style="color: #008000; font-weight: bold">return</span> d_loss<span style="color: #666666">.</span>data<span style="color: #666666">.</span>item(), d_proba_real<span style="color: #666666">.</span>detach(), d_proba_fake<span style="color: #666666">.</span>detach()

<span style="color: #408080; font-style: italic">## Train the generator</span>
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">g_train</span>(x):
    gen_model<span style="color: #666666">.</span>zero_grad()
    
    batch_size <span style="color: #666666">=</span> x<span style="color: #666666">.</span>size(<span style="color: #666666">0</span>)
    input_z <span style="color: #666666">=</span> create_noise(batch_size, z_size, mode_z)<span style="color: #666666">.</span>to(device)
    g_labels_real <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>ones(batch_size, <span style="color: #666666">1</span>, device<span style="color: #666666">=</span>device)

    g_output <span style="color: #666666">=</span> gen_model(input_z)
    d_proba_fake <span style="color: #666666">=</span> disc_model(g_output)
    g_loss <span style="color: #666666">=</span> loss_fn(d_proba_fake, g_labels_real)

    <span style="color: #408080; font-style: italic"># gradient backprop &amp; optimize ONLY G&#39;s parameters</span>
    g_loss<span style="color: #666666">.</span>backward()
    g_optimizer<span style="color: #666666">.</span>step()
        
    <span style="color: #008000; font-weight: bold">return</span> g_loss<span style="color: #666666">.</span>data<span style="color: #666666">.</span>item()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">fixed_z <span style="color: #666666">=</span> create_noise(batch_size, z_size, mode_z)<span style="color: #666666">.</span>to(device)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">create_samples</span>(g_model, input_z):
    g_output <span style="color: #666666">=</span> g_model(input_z)
    images <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>reshape(g_output, (batch_size, <span style="color: #666666">*</span>image_size))    
    <span style="color: #008000; font-weight: bold">return</span> (images<span style="color: #666666">+1</span>)<span style="color: #666666">/2.0</span>

epoch_samples <span style="color: #666666">=</span> []

all_d_losses <span style="color: #666666">=</span> []
all_g_losses <span style="color: #666666">=</span> []

all_d_real <span style="color: #666666">=</span> []
all_d_fake <span style="color: #666666">=</span> []

num_epochs <span style="color: #666666">=</span> <span style="color: #666666">100</span>
torch<span style="color: #666666">.</span>manual_seed(<span style="color: #666666">1</span>)
<span style="color: #008000; font-weight: bold">for</span> epoch <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">1</span>, num_epochs<span style="color: #666666">+1</span>):
    d_losses, g_losses <span style="color: #666666">=</span> [], []
    d_vals_real, d_vals_fake <span style="color: #666666">=</span> [], []
    <span style="color: #008000; font-weight: bold">for</span> i, (x, _) <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(mnist_dl):
        d_loss, d_proba_real, d_proba_fake <span style="color: #666666">=</span> d_train(x)
        d_losses<span style="color: #666666">.</span>append(d_loss)
        g_losses<span style="color: #666666">.</span>append(g_train(x))
        
        d_vals_real<span style="color: #666666">.</span>append(d_proba_real<span style="color: #666666">.</span>mean()<span style="color: #666666">.</span>cpu())
        d_vals_fake<span style="color: #666666">.</span>append(d_proba_fake<span style="color: #666666">.</span>mean()<span style="color: #666666">.</span>cpu())
        
    all_d_losses<span style="color: #666666">.</span>append(torch<span style="color: #666666">.</span>tensor(d_losses)<span style="color: #666666">.</span>mean())
    all_g_losses<span style="color: #666666">.</span>append(torch<span style="color: #666666">.</span>tensor(g_losses)<span style="color: #666666">.</span>mean())
    all_d_real<span style="color: #666666">.</span>append(torch<span style="color: #666666">.</span>tensor(d_vals_real)<span style="color: #666666">.</span>mean())
    all_d_fake<span style="color: #666666">.</span>append(torch<span style="color: #666666">.</span>tensor(d_vals_fake)<span style="color: #666666">.</span>mean())
    <span style="color: #008000">print</span>(<span style="color: #BA2121">f&#39;Epoch </span><span style="color: #BB6688; font-weight: bold">{</span>epoch<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">03d</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121"> | Avg Losses &gt;&gt;&#39;</span>
          <span style="color: #BA2121">f&#39; G/D </span><span style="color: #BB6688; font-weight: bold">{</span>all_g_losses[<span style="color: #666666">-1</span>]<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">/</span><span style="color: #BB6688; font-weight: bold">{</span>all_d_losses[<span style="color: #666666">-1</span>]<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>
          <span style="color: #BA2121">f&#39; [D-Real: </span><span style="color: #BB6688; font-weight: bold">{</span>all_d_real[<span style="color: #666666">-1</span>]<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121"> D-Fake: </span><span style="color: #BB6688; font-weight: bold">{</span>all_d_fake[<span style="color: #666666">-1</span>]<span style="color: #BB6688; font-weight: bold">:</span><span style="color: #BA2121">.4f</span><span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">]&#39;</span>)
    epoch_samples<span style="color: #666666">.</span>append(
        create_samples(gen_model, fixed_z)<span style="color: #666666">.</span>detach()<span style="color: #666666">.</span>cpu()<span style="color: #666666">.</span>numpy())
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="visualizing" class="anchor">Visualizing </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">itertools</span>


fig <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">16</span>, <span style="color: #666666">6</span>))

<span style="color: #408080; font-style: italic">## Plotting the losses</span>
ax <span style="color: #666666">=</span> fig<span style="color: #666666">.</span>add_subplot(<span style="color: #666666">1</span>, <span style="color: #666666">2</span>, <span style="color: #666666">1</span>)
 
plt<span style="color: #666666">.</span>plot(all_g_losses, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Generator loss&#39;</span>)
half_d_losses <span style="color: #666666">=</span> [all_d_loss<span style="color: #666666">/2</span> <span style="color: #008000; font-weight: bold">for</span> all_d_loss <span style="color: #AA22FF; font-weight: bold">in</span> all_d_losses]
plt<span style="color: #666666">.</span>plot(half_d_losses, label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Discriminator loss&#39;</span>)
plt<span style="color: #666666">.</span>legend(fontsize<span style="color: #666666">=20</span>)
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&#39;Iteration&#39;</span>, size<span style="color: #666666">=15</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&#39;Loss&#39;</span>, size<span style="color: #666666">=15</span>)

<span style="color: #408080; font-style: italic">## Plotting the outputs of the discriminator</span>
ax <span style="color: #666666">=</span> fig<span style="color: #666666">.</span>add_subplot(<span style="color: #666666">1</span>, <span style="color: #666666">2</span>, <span style="color: #666666">2</span>)
plt<span style="color: #666666">.</span>plot(all_d_real, label<span style="color: #666666">=</span><span style="color: #BA2121">r&#39;Real: $D(\mathbf</span><span style="color: #BB6688; font-weight: bold">{x}</span><span style="color: #BA2121">)$&#39;</span>)
plt<span style="color: #666666">.</span>plot(all_d_fake, label<span style="color: #666666">=</span><span style="color: #BA2121">r&#39;Fake: $D(G(\mathbf</span><span style="color: #BB6688; font-weight: bold">{z}</span><span style="color: #BA2121">))$&#39;</span>)
plt<span style="color: #666666">.</span>legend(fontsize<span style="color: #666666">=20</span>)
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&#39;Iteration&#39;</span>, size<span style="color: #666666">=15</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&#39;Discriminator output&#39;</span>, size<span style="color: #666666">=15</span>)

<span style="color: #408080; font-style: italic">#plt.savefig(&#39;figures/ch17-gan-learning-curve.pdf&#39;)</span>
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">selected_epochs <span style="color: #666666">=</span> [<span style="color: #666666">1</span>, <span style="color: #666666">2</span>, <span style="color: #666666">4</span>, <span style="color: #666666">10</span>, <span style="color: #666666">50</span>, <span style="color: #666666">100</span>]
fig <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>, <span style="color: #666666">14</span>))
<span style="color: #008000; font-weight: bold">for</span> i,e <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(selected_epochs):
    <span style="color: #008000; font-weight: bold">for</span> j <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">5</span>):
        ax <span style="color: #666666">=</span> fig<span style="color: #666666">.</span>add_subplot(<span style="color: #666666">6</span>, <span style="color: #666666">5</span>, i<span style="color: #666666">*5+</span>j<span style="color: #666666">+1</span>)
        ax<span style="color: #666666">.</span>set_xticks([])
        ax<span style="color: #666666">.</span>set_yticks([])
        <span style="color: #008000; font-weight: bold">if</span> j <span style="color: #666666">==</span> <span style="color: #666666">0</span>:
            ax<span style="color: #666666">.</span>text(
                <span style="color: #666666">-0.06</span>, <span style="color: #666666">0.5</span>, <span style="color: #BA2121">f&#39;Epoch </span><span style="color: #BB6688; font-weight: bold">{</span>e<span style="color: #BB6688; font-weight: bold">}</span><span style="color: #BA2121">&#39;</span>,
                rotation<span style="color: #666666">=90</span>, size<span style="color: #666666">=18</span>, color<span style="color: #666666">=</span><span style="color: #BA2121">&#39;red&#39;</span>,
                horizontalalignment<span style="color: #666666">=</span><span style="color: #BA2121">&#39;right&#39;</span>,
                verticalalignment<span style="color: #666666">=</span><span style="color: #BA2121">&#39;center&#39;</span>, 
                transform<span style="color: #666666">=</span>ax<span style="color: #666666">.</span>transAxes)
        
        image <span style="color: #666666">=</span> epoch_samples[e<span style="color: #666666">-1</span>][j]
        ax<span style="color: #666666">.</span>imshow(image, cmap<span style="color: #666666">=</span><span style="color: #BA2121">&#39;gray_r&#39;</span>)
    
<span style="color: #408080; font-style: italic">#plt.savefig(&#39;figures/ch17-vanila-gan-samples.pdf&#39;)</span>
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #666666">=====</span> Calculating scores <span style="color: #666666">=====</span>

<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">math</span>


<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">distance</span>(X, Y, sqrt):
    nX <span style="color: #666666">=</span> X<span style="color: #666666">.</span>size(<span style="color: #666666">0</span>)
    nY <span style="color: #666666">=</span> Y<span style="color: #666666">.</span>size(<span style="color: #666666">0</span>)
    X <span style="color: #666666">=</span> X<span style="color: #666666">.</span>view(nX,<span style="color: #666666">-1</span>)<span style="color: #666666">.</span>cuda()
    X2 <span style="color: #666666">=</span> (X<span style="color: #666666">*</span>X)<span style="color: #666666">.</span>sum(<span style="color: #666666">1</span>)<span style="color: #666666">.</span>resize_(nX,<span style="color: #666666">1</span>)
    Y <span style="color: #666666">=</span> Y<span style="color: #666666">.</span>view(nY,<span style="color: #666666">-1</span>)<span style="color: #666666">.</span>cuda()
    Y2 <span style="color: #666666">=</span> (Y<span style="color: #666666">*</span>Y)<span style="color: #666666">.</span>sum(<span style="color: #666666">1</span>)<span style="color: #666666">.</span>resize_(nY,<span style="color: #666666">1</span>)

    M <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>zeros(nX, nY)
    M<span style="color: #666666">.</span>copy_(X2<span style="color: #666666">.</span>expand(nX,nY) <span style="color: #666666">+</span> Y2<span style="color: #666666">.</span>expand(nY,nX)<span style="color: #666666">.</span>transpose(<span style="color: #666666">0</span>,<span style="color: #666666">1</span>) <span style="color: #666666">-</span> <span style="color: #666666">2*</span>torch<span style="color: #666666">.</span>mm(X,Y<span style="color: #666666">.</span>transpose(<span style="color: #666666">0</span>,<span style="color: #666666">1</span>)))

    <span style="color: #008000; font-weight: bold">del</span> X, X2, Y, Y2
    
    <span style="color: #008000; font-weight: bold">if</span> sqrt:
        M <span style="color: #666666">=</span> ((M<span style="color: #666666">+</span>M<span style="color: #666666">.</span>abs())<span style="color: #666666">/2</span>)<span style="color: #666666">.</span>sqrt()
    
    <span style="color: #008000; font-weight: bold">return</span> M

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">mmd</span>(Mxx, Mxy, Myy, sigma) :
    scale <span style="color: #666666">=</span> Mxx<span style="color: #666666">.</span>mean()
    Mxx <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>exp(<span style="color: #666666">-</span>Mxx<span style="color: #666666">/</span>(scale<span style="color: #666666">*2*</span>sigma<span style="color: #666666">*</span>sigma))
    Mxy <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>exp(<span style="color: #666666">-</span>Mxy<span style="color: #666666">/</span>(scale<span style="color: #666666">*2*</span>sigma<span style="color: #666666">*</span>sigma))
    Myy <span style="color: #666666">=</span> torch<span style="color: #666666">.</span>exp(<span style="color: #666666">-</span>Myy<span style="color: #666666">/</span>(scale<span style="color: #666666">*2*</span>sigma<span style="color: #666666">*</span>sigma))
    a <span style="color: #666666">=</span> Mxx<span style="color: #666666">.</span>mean()<span style="color: #666666">+</span>Myy<span style="color: #666666">.</span>mean()<span style="color: #666666">-2*</span>Mxy<span style="color: #666666">.</span>mean()
    mmd <span style="color: #666666">=</span> math<span style="color: #666666">.</span>sqrt(<span style="color: #008000">max</span>(a, <span style="color: #666666">0</span>))

    <span style="color: #008000; font-weight: bold">return</span> mmd

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">compute_score</span>(fake, real , k<span style="color: #666666">=1</span>, sigma<span style="color: #666666">=1</span>, sqrt<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>):

    Mxx <span style="color: #666666">=</span> distance(real, real, <span style="color: #008000; font-weight: bold">False</span>)
    Mxy <span style="color: #666666">=</span> distance(real, fake, <span style="color: #008000; font-weight: bold">False</span>)
    Myy <span style="color: #666666">=</span> distance(fake, fake, <span style="color: #008000; font-weight: bold">False</span>)

 
    <span style="color: #008000">print</span>(mmd(Mxx, Mxy, Myy, sigma))

whole_dl <span style="color: #666666">=</span> DataLoader(mnist_dataset, batch_size<span style="color: #666666">=10000</span>, 
                      shuffle<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, drop_last<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>) 
real_image <span style="color: #666666">=</span> <span style="color: #008000">next</span>(<span style="color: #008000">iter</span>(whole_dl))[<span style="color: #666666">0</span>]
compute_score(torch<span style="color: #666666">.</span>from_numpy(epoch_samples[<span style="color: #666666">-1</span>]), real_image)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<!-- !split -->
<h2 id="diffusion-models-basics" class="anchor">Diffusion models, basics </h2>

<p>Diffusion models are inspired by non-equilibrium thermodynamics. They
define a Markov chain of diffusion steps to slowly add random noise to
data and then learn to reverse the diffusion process to construct
desired data samples from the noise. Unlike VAE or flow models,
diffusion models are learned with a fixed procedure and the latent
variable has high dimensionality (same as the original data).
</p>

<!-- !split -->
<h2 id="mathematics-of-diffusion-models" class="anchor">Mathematics of diffusion models </h2>

<p>More text will be added here.</p>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2024, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</body>
</html>


<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week15-reveal.html week15-reveal reveal --html_slide_theme=beige
-->
<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>

<!-- reveal.js: https://lab.hakim.se/reveal-js/ -->

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<!--
<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/beigesmall.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/serif.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/moon.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/darkgray.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/default.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/cbc.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simula.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/league.css" id="theme">
-->

<!-- For syntax highlighting -->
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<style type="text/css">
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.reveal .alert-text-small   { font-size: 80%;  }
.reveal .alert-text-large   { font-size: 130%; }
.reveal .alert-text-normal  { font-size: 90%;  }
.reveal .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
  -webkit-border-radius: 14px; -moz-border-radius: 14px;
  border-radius:14px;
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.reveal .alert-block {padding-top:14px; padding-bottom:14px}
.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
/*.reveal .alert li {margin-top: 1em}*/
.reveal .alert-block p+p {margin-top:5px}
/*.reveal .alert-notice { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_notice.png); }
.reveal .alert-summary  { background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_summary.png); }
.reveal .alert-warning { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_warning.png); }
.reveal .alert-question {background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_question.png); } */
/* Override reveal.js table border */
.reveal table td {
  border: 0;
}

<style type="text/css">
/* Override h1, h2, ... styles */
h1 { font-size: 2.8em; }
h2 { font-size: 1.5em; }
h3 { font-size: 1.4em; }
h4 { font-size: 1.3em; }
h1, h2, h3, h4 { font-weight: bold; line-height: 1.2; }
body { overflow: auto; } /* vertical scrolling */
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.slide .alert-text-small   { font-size: 80%;  }
.slide .alert-text-large   { font-size: 130%; }
.slide .alert-text-normal  { font-size: 90%;  }
.slide .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
    -webkit-border-radius:14px; -moz-border-radius:14px;
  border-radius:14px
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.slide .alert-block {padding-top:14px; padding-bottom:14px}
.slide .alert-block > p, .alert-block > ul {margin-bottom:0}
/*.slide .alert li {margin-top: 1em}*/
.deck .alert-block p+p {margin-top:5px}
/*.slide .alert-notice { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_notice.png); }
.slide .alert-summary  { background-image:url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_summary.png); }
.slide .alert-warning { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_warning.png); }
.slide .alert-question {background-image:url(https://hplgit.github.io/doconce/
bundled/html_images/small_gray_question.png); } */
.dotable table, .dotable th, .dotable tr, .dotable tr td {
  border: 2px solid black;
  border-collapse: collapse;
  padding: 2px;
}
</style>


<!-- Styles for table layout of slides -->
<style type="text/css">
td.padding {
  padding-top:20px;
  padding-bottom:20px;
  padding-right:50px;
  padding-left:50px;
}
</style>

</head>


<body>
<div class="reveal">
<div class="slides">





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




<section>
<!-- ------------------- main content ---------------------- -->
<center>
<h1 style="text-align: center;">Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA</b>
</center>
<br>
<center>
<h4>April 30, 2024</h4>
</center> <!-- date -->
<br>


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2024, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</section>

<section>
<h2 id="plans-for-the-week-of-april-29-may-3-2024">Plans for the week of April 29- May 3, 2024  </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Deep generative models</b>
<p>
<ol>
<p><li> Summary of Variational Autoencoders</li>
<p><li> Generative Adversarial Networks (GANs), see <a href="https://lilianweng.github.io/posts/2017-08-20-gan/" target="_blank"><tt>https://lilianweng.github.io/posts/2017-08-20-gan/</tt></a> for nice overview</li>
<p><li> Start discussion of diffusion models, motivation</li>
<p><li> <a href="https://youtu.be/Cg8n9aWwHuU" target="_blank">Video of lecture</a></li>
<p><li> <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesApril30.pdf" target="_blank">Whiteboard notes</a></li>
</ol>
</div>
</section>

<section>
<h2 id="readings">Readings </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b></b>
<p>
<ol>
<p><li> Reading recommendation: Goodfellow et al, for GANs see sections 20.10-20.11</li>
<p><li> For codes and background, see Raschka et al, Machine with PyTorch and Scikit-Learn, chapter 17, see <a href="https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17" target="_blank"><tt>https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17</tt></a> for codes</li>
<p><li> Babcock and Bali, Generative AI with Python and TensorFlow2, chapter 6 and codes at <a href="https://github.com/raghavbali/generative_ai_with_tensorflow/blob/master/Chapter_6/conditional_gan.ipynb" target="_blank"><tt>https://github.com/raghavbali/generative_ai_with_tensorflow/blob/master/Chapter_6/conditional_gan.ipynb</tt></a></li>
</ol>
</div>
</section>

<section>
<h2 id="summary-of-variational-autoencoders-vaes">Summary of Variational Autoencoders (VAEs) </h2>

<p>In our short summary of VAes, we will also remind you about the
mathematics of Boltzmann machines and the Kullback-Leibler divergence,
leading to used ways to optimize the probability
distributions, namely what is called 
</p>
<ul>
<p><li> Contrastive optimization</li>
</ul>
</section>

<section>
<h2 id="boltzmann-machines-and-energy-based-models-and-contrastive-optimization">Boltzmann machines and energy-based models and contrastive optimization </h2>
</section>

<section>
<h2 id="energy-models">Energy models </h2>

<p>For Boltzmann machines  we defined a domain \( \boldsymbol{X} \) of stochastic variables \( \boldsymbol{X}= \{x_0,x_1, \dots , x_{n-1}\} \) with a pertinent probability distribution</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X})=\prod_{x_i\in \boldsymbol{X}}p(x_i),
$$
<p>&nbsp;<br>

<p>where we have assumed that the random varaibles \( x_i \) are all independent and identically distributed (iid).</p>
</section>

<section>
<h2 id="probability-model">Probability model </h2>

<p>We defined a probability</p>
<p>&nbsp;<br>
$$
p(x_i,h_j;\boldsymbol{\Theta}) = \frac{f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>where \( f(x_i,h_j;\boldsymbol{\Theta}) \) is a function which we assume is larger or
equal than zero and obeys all properties required for a probability
distribution and \( Z(\boldsymbol{\Theta}) \) is a normalization constant. Inspired by
statistical mechanics, we call it often for the partition function.
It is defined as (assuming that we have discrete probability distributions)
</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="marginal-and-conditional-probabilities">Marginal and conditional probabilities </h2>

<p>We can in turn define the marginal probabilities</p>
<p>&nbsp;<br>
$$
p(x_i;\boldsymbol{\Theta}) = \frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>and </p>
<p>&nbsp;<br>
$$
p(h_i;\boldsymbol{\Theta}) = \frac{\sum_{x_i\in \boldsymbol{X}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="partition-function">Partition function  </h2>

<p><b>Note the change to a vector notation</b>. A variable like \( \boldsymbol{x} \)
represents now a specific <b>configuration</b>. We can generate an infinity
of such configurations. The final partition function is then the sum
over all such possible configurations, that is
</p>

<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>changes to</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{\boldsymbol{x}}\sum_{\boldsymbol{h}} f(\boldsymbol{x},\boldsymbol{h};\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>

<p>If we have a binary set of variable \( x_i \) and \( h_j \) and \( M \) values of \( x_i \) and \( N \) values of \( h_j \) we have in total \( 2^M \) and \( 2^N \) possible \( \boldsymbol{x} \) and \( \boldsymbol{h} \) configurations, respectively.</p>

<p>We see that even for the modest binary case, we can easily approach a
number of configuration which is not possible to deal with.
</p>
</section>

<section>
<h2 id="optimization-problem">Optimization problem </h2>

<p>At the end, we are not interested in the probabilities of the hidden variables. The probability we thus want to optimize is </p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta})=\prod_{x_i\in \boldsymbol{X}}\left(\frac{\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})}\right),
$$
<p>&nbsp;<br>

<p>which we rewrite as</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}\left(\sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta})\right).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="further-simplifications">Further simplifications </h2>

<p>We simplify further by rewriting it as</p>
<p>&nbsp;<br>
$$
p(\boldsymbol{X};\boldsymbol{\Theta})=\frac{1}{Z(\boldsymbol{\Theta})}\prod_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>where we used \( p(x_i;\boldsymbol{\Theta}) = \sum_{h_j\in \boldsymbol{H}}f(x_i,h_j;\boldsymbol{\Theta}) \).
The optimization problem is then
</p>
<p>&nbsp;<br>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}p(\boldsymbol{X};\boldsymbol{\Theta}).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="optimizing-the-logarithm-instead">Optimizing the logarithm instead </h2>

<p>Computing the derivatives with respect to the parameters \( \boldsymbol{\Theta} \) is
easier (and equivalent) with taking the logarithm of the
probability. We will thus optimize
</p>
<p>&nbsp;<br>
$$
{\displaystyle \mathrm{arg} \hspace{0.1cm}\max_{\boldsymbol{\boldsymbol{\Theta}}\in {\mathbb{R}}^{p}}} \hspace{0.1cm}\log{p(\boldsymbol{X};\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>which leads to</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=0.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="expression-for-the-gradients">Expression for the gradients </h2>

<p>This leads to the following equation</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{p(\boldsymbol{X};\boldsymbol{\Theta})}=\nabla_{\boldsymbol{\Theta}}\left(\sum_{x_i\in \boldsymbol{X}}\log{f(x_i;\boldsymbol{\Theta})}\right)-\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=0.
$$
<p>&nbsp;<br>

<p>The first term is called the positive phase and we assume that we have a model for the function \( f \) from which we can sample values. Below we will develop an explicit model for this.
The second term is called the negative phase and is the one which leads to more difficulties.
</p>
</section>

<section>
<h2 id="contrastive-optimization">Contrastive optimization </h2>
<p>The evaluation of these two terms leads to what in the literature is called contrastive optimization.</p>

<p>If we optimize the negative <b>log</b> of the PDF, the aboves phases simply change sign.</p>

<p>For a further discussion of energy-based models, see the notes by Philip Lippe at <a href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html" target="_blank"><tt>https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html</tt></a></p>
</section>

<section>
<h2 id="the-derivative-of-the-partition-function">The derivative of the partition function </h2>

<p>The partition function, defined above as</p>
<p>&nbsp;<br>
$$
Z(\boldsymbol{\Theta})=\sum_{x_i\in \boldsymbol{X}}\sum_{h_j\in \boldsymbol{H}} f(x_i,h_j;\boldsymbol{\Theta}),
$$
<p>&nbsp;<br>

<p>is in general the most problematic term. In principle both \( x \) and \( h \) can span large degrees of freedom, if not even infinitely many ones, and computing the partition function itself is often not desirable or even feasible. The above derivative of the partition function can however be written in terms of an expectation value which is in turn evaluated  using Monte Carlo sampling and the theory of Markov chains, popularly shortened to MCMC (or just MC$^2$).</p>
</section>

<section>
<h2 id="explicit-expression-for-the-derivative">Explicit expression for the derivative </h2>
<p>We can rewrite</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}}Z(\boldsymbol{\Theta})}{Z(\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>which reads in more detail</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{\nabla_{\boldsymbol{\Theta}} \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta})   }{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>

<p>We can rewrite the function \( f \) (we have assumed that is larger or
equal than zero) as \( f=\exp{\log{f}} \). We can then reqrite the last
equation as
</p>

<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}} \nabla_{\boldsymbol{\Theta}}\exp{\log{f(x_i;\boldsymbol{\Theta})}}   }{Z(\boldsymbol{\Theta})}.
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="final-expression">Final expression </h2>

<p>Taking the derivative gives us</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\frac{ \sum_{x_i\in \boldsymbol{X}}f(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})}   }{Z(\boldsymbol{\Theta})}, 
$$
<p>&nbsp;<br>

<p>which is the expectation value of \( \log{f} \)</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\sum_{x_i\in \boldsymbol{X}}p(x_i;\boldsymbol{\Theta}) \nabla_{\boldsymbol{\Theta}}\log{f(x_i;\boldsymbol{\Theta})},
$$
<p>&nbsp;<br>

<p>that is</p>
<p>&nbsp;<br>
$$
\nabla_{\boldsymbol{\Theta}}\log{Z(\boldsymbol{\Theta})}=\mathbb{E}(\log{f(x_i;\boldsymbol{\Theta})}).
$$
<p>&nbsp;<br>

<p>This quantity is evaluated using Monte Carlo sampling, with Gibbs
sampling as the standard sampling rule.  
</p>
</section>

<section>
<h2 id="kullback-leibler-divergence">Kullback-Leibler divergence </h2>

<p>Before we continue, we need to remind ourselves about the
Kullback-Leibler divergence introduced earlier. This will also allow
us to introduce another measure used in connection with the training
of Generative Adversarial Networks, the so-called Jensen-Shannon divergence..
These metrics are useful for quantifying the similarity between two probability distributions.
</p>

<p>The Kullback&#8211;Leibler (KL) divergence, labeled \( D_{KL} \),   measures how one probability distribution \( p \) diverges from a second expected probability distribution \( q \),
that is
</p>
<p>&nbsp;<br>
$$
D_{KL}(p \| q) = \int_x p(x) \log \frac{p(x)}{q(x)} dx.
$$
<p>&nbsp;<br>

<p>The KL-divegrnece \( D_{KL} \) achieves the minimum zero when \( p(x) == q(x) \) everywhere.</p>

<p>Note that the KL divergence is asymmetric. In cases where \( p(x) \) is
close to zero, but \( q(x) \) is significantly non-zero, the \( q \)'s effect
is disregarded. It could cause buggy results when we just want to
measure the similarity between two equally important distributions.
</p>
</section>

<section>
<h2 id="jensen-shannon-divergence">Jensen-Shannon divergence </h2>

<p>The Jensen&#8211;Shannon (JS) divergence is another measure of similarity between
two probability distributions, bounded by \( [0, 1] \). The JS-divergence is
symmetric and more smooth than the KL-divergence.
It is defined as
</p>
<p>&nbsp;<br>
$$
D_{JS}(p \| q) = \frac{1}{2} D_{KL}(p \| \frac{p + q}{2}) + \frac{1}{2} D_{KL}(q \| \frac{p + q}{2})
$$
<p>&nbsp;<br>

<p>Many practitioners believe that one reason behind GANs' big success is
switching the loss function from asymmetric KL-divergence in
traditional maximum-likelihood approach to symmetric JS-divergence.
</p>
</section>

<section>
<h2 id="generative-model-basic-overview-borrowed-from-rashcka-et-al">Generative model,  basic overview (Borrowed from Rashcka et al) </h2>

<br/><br/>
<center>
<p><img src="figures/figure1.png" width="900" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="reminder-on-vaes">Reminder on VAEs </h2>

<p>Mathematically, we can imagine the latent variables and the data we
observe as modeled by a joint distribution \( p(\boldsymbol{x}, \boldsymbol{h};\boldsymbol{\Theta}) \).  Recall one
approach of generative modeling, termed likelihood-based, is to
learn a model to maximize the likelihood \( p(\boldsymbol{x};\boldsymbol{\Theta}) \) of all observed
\( \boldsymbol{x} \).  There are two ways we can manipulate this joint distribution
to recover the likelihood of purely our observed data \( p(\boldsymbol{x};\boldsymbol{\Theta}) \); we can
explicitly marginalize
out the latent variable \( \boldsymbol{h} \)
</p>
<p>&nbsp;<br>
$$
\begin{equation*}
p(\boldsymbol{x}) = \int p(\boldsymbol{x}, \boldsymbol{h})d\boldsymbol{h}
\end{equation*}
$$
<p>&nbsp;<br>

<p>or, we could also appeal to the chain rule of probability</p>
<p>&nbsp;<br>
$$
\begin{equation*}
p(\boldsymbol{x}) = \frac{p(\boldsymbol{x}, \boldsymbol{h})}{p(\boldsymbol{h}|\boldsymbol{x})}
\end{equation*}
$$
<p>&nbsp;<br>

<p>We suppress here the dependence	on the optimization parameters \( \boldsymbol{\Theta} \).</p>
</section>

<section>
<h2 id="evidence-lower-bound">Evidence Lower Bound </h2>
<p>Directly computing and maximizing the likelihood \( p(\boldsymbol{x}) \) is
difficult because it either involves integrating out all latent
variables \( \boldsymbol{h} \), which is intractable for
complex models, or it involves having access to a ground truth latent
encoder \( p(\boldsymbol{h}|\boldsymbol{x}) \).
</p>

<p>Using the last  two equations, we can derive a term called the Evidence Lower Bound (ELBO), which as its name suggests, is a lower
  bound of the evidence.  The evidence is quantified in this case as
the log likelihood of the observed data.  Then, maximizing the ELBO
becomes a proxy objective with which to optimize a latent variable
model; in the best case, when the ELBO is powerfully parameterized and
perfectly optimized, it becomes exactly equivalent to the evidence.
</p>
</section>

<section>
<h2 id="elbo-equations">ELBO equations </h2>
<p>Formally, the equation of the ELBO is</p>
<p>&nbsp;<br>
$$
\begin{equation*}
\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]
\end{equation*}
$$
<p>&nbsp;<br>

<p>To make the relationship with the evidence explicit, we can mathematically write:</p>
<p>&nbsp;<br>
$$
\begin{equation*}
\log p(\boldsymbol{x}) \geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]
\end{equation*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="introducing-the-encoder-function">Introducing the encoder function </h2>

<p>Here, \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) is a flexible approximate
variational distribution with parameters \( \boldsymbol{\phi} \) that we seek to
optimize.  Intuitively, it can be thought of as a parameterizable
model that is learned to estimate the true distribution over latent
variables for given observations \( \boldsymbol{x} \); in other words, it seeks to
approximate true posterior \( p(\boldsymbol{h}|\boldsymbol{x}) \).  As we saw last week when we
explored Variational Autoencoders, as we increase the lower bound
by tuning the parameters \( \boldsymbol{\phi} \) to maximize the ELBO, we gain
access to components that can be used to model the true data
distribution and sample from it, thus learning a generative model.
</p>
</section>

<section>
<h2 id="the-derivation-from-last-week">The derivation from last week </h2>

<p>To better understand the relationship between the evidence and the ELBO, let us perform another derivation, this time using</p>

$$
\begin{align*}
\log p(\boldsymbol{x}) & = \log p(\boldsymbol{x}) \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})dh && \text{(Multiply by $1 = \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})d\boldsymbol{h}$)}\\
          & = \int q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})(\log p(\boldsymbol{x}))dh && \text{(Bring evidence into integral)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p(\boldsymbol{x})\right] && \text{(Definition of Expectation)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{p(\boldsymbol{h}|\boldsymbol{x})}\right]&& \\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{p(\boldsymbol{h}|\boldsymbol{x})q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]&& \text{(Multiply by $1 = \frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}$)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right] + \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}{p(\boldsymbol{h}|\boldsymbol{x})}\right] && \text{(Split the Expectation)}\\
          & = \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right] +
	  D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h}|\boldsymbol{x}))  && \text{(Definition of KL Divergence)}\\
          & \geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]  && \text{(KL Divergence always $\geq 0$)}
\end{align*}
$$
</section>

<section>
<h2 id="analysis">Analysis </h2>

<p>From this derivation, we clearly observe from the last equation
that the evidence is equal to the ELBO plus the KL Divergence between
the approximate posterior \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) and the true
posterior \( p(\boldsymbol{h}|\boldsymbol{x}) \).  Understanding this term is the
key to understanding not only the relationship between the ELBO and
the evidence, but also the reason why optimizing the ELBO is an
appropriate objective at all.
</p>
</section>

<section>
<h2 id="the-vae">The VAE </h2>

<p>In the default formulation of the VAE by Kingma and Welling (2015), we directly maximize the ELBO.  This
approach is \textit{variational}, because we optimize for the best
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) amongst a family of potential posterior
distributions parameterized by \( \boldsymbol{\phi} \).  It is called an
\textit{autoencoder} because it is reminiscent of a traditional
autoencoder model, where input data is trained to predict itself after
undergoing an intermediate bottlenecking representation step.
</p>
</section>

<section>
<h2 id="dissecting-the-equations">Dissecting the equations </h2>
<p>To make
this connection explicit, let us dissect the ELBO term further:
</p>

<p>&nbsp;<br>
$$
\begin{align*}
{\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x}, \boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}
&= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})p(\boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}         && {\text{(Chain Rule of Probability)}}\\
&= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right] + \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{h})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\right]}         && {\text{(Split the Expectation)}}\\
&= \underbrace{{\mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right]}}_\text{reconstruction term} - \underbrace{{D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\vert\vert{p(\boldsymbol{h}))}}_\text{prior matching term} && {\text{(Definition of KL Divergence)}}
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="bottlenecking-distribution">Bottlenecking distribution </h2>

<p>In this case, we learn an intermediate bottlenecking distribution
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) that can be treated as
an \textit{encoder}; it transforms inputs into a distribution over
possible latents.  Simultaneously, we learn a deterministic function
\( p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}) \) to convert a given latent vector
\( \boldsymbol{h} \) into an observation \( \boldsymbol{x} \), which can be interpreted as
a \textit{decoder}.
</p>
</section>

<section>
<h2 id="decoder-and-encoder">Decoder and encoder </h2>
<p>The two terms in the last equation each have intuitive descriptions: the first
term measures the reconstruction likelihood of the decoder from our
variational distribution; this ensures that the learned distribution
is modeling effective latents that the original data can be
regenerated from.  The second term measures how similar the learned
variational distribution is to a prior belief held over latent
variables.  Minimizing this term encourages the encoder to actually
learn a distribution rather than collapse into a Dirac delta function.
Maximizing the ELBO is thus equivalent to maximizing its first term
and minimizing its second term.
</p>
</section>

<section>
<h2 id="defining-feature-of-vaes">Defining feature of VAEs </h2>

<p>A defining feature of the VAE is how the ELBO is optimized jointly over parameters \( \boldsymbol{\phi} \) and \( \boldsymbol{\theta} \).  The encoder of the VAE is commonly chosen to model a multivariate Gaussian with diagonal covariance, and the prior is often selected to be a standard multivariate Gaussian: </p>
<p>&nbsp;<br>
$$
\begin{align*}
    q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) &= N(\boldsymbol{h}; \boldsymbol{\mu}_{\boldsymbol{\phi}}(\boldsymbol{x}), \boldsymbol{\sigma}_{\boldsymbol{\phi}}^2(\boldsymbol{x})\textbf{I})\\
    p(\boldsymbol{h}) &= N(\boldsymbol{h}; \boldsymbol{0}, \textbf{I})
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="analytical-evaluation">Analytical evaluation </h2>

<p>Then, the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can be approximated using a Monte Carlo estimate.  Our objective can then be rewritten as:</p>
<p>&nbsp;<br>
$$
\begin{align*}
  \mathrm{argmax}_{\boldsymbol{\phi}, \boldsymbol{\theta}} \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})}\left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h})\right] - D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h})) \approx \mathrm{argmax}_{\boldsymbol{\phi}, \boldsymbol{\theta}} \sum_{l=1}^{L}\log p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}^{(l)}) - D_{KL}(q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x})\vert\vert p(\boldsymbol{h}))
\end{align*}
$$
<p>&nbsp;<br>

<p>where latents \( \{\boldsymbol{h}^{(l)}\}_{l=1}^L \) are sampled from \( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \), for every observation \( \boldsymbol{x} \) in the dataset.</p>
</section>

<section>
<h2 id="reparameterization-trick">Reparameterization trick </h2>

<p>However, a problem arises in this default setup: each \( \boldsymbol{h}^{(l)} \)
that our loss is computed on is generated by a stochastic sampling
procedure, which is generally non-differentiable.  Fortunately, this
can be addressed via the \textit{reparameterization trick} when
\( q_{\boldsymbol{\phi}}(\boldsymbol{h}|\boldsymbol{x}) \) is designed to model certain
distributions, including the multivariate Gaussian.
</p>
</section>

<section>
<h2 id="actual-implementation">Actual implementation </h2>

<p>The reparameterization trick rewrites a random variable as a
deterministic function of a noise variable; this allows for the
optimization of the non-stochastic terms through gradient descent.
For example, samples from a normal distribution
\( x \sim N(x;\mu, \sigma^2) \) with arbitrary mean \( \mu \) and
variance \( \sigma^2 \) can be rewritten as
</p>

<p>&nbsp;<br>
$$
\begin{align*}
    x &= \mu + \sigma\epsilon \quad \text{with } \epsilon \sim N(\epsilon; 0, \boldsymbol{I})
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="interpretation">Interpretation </h2>
<p>An arbitrary Gaussian distributions can be interpreted as
standard Gaussians (of which \( \epsilon \) is a sample) that have their
mean shifted from zero to the target mean \( \mu \) by addition, and their
variance stretched by the target variance \( \sigma^2 \).  Therefore, by
the reparameterization trick, sampling from an arbitrary Gaussian
distribution can be performed by sampling from a standard Gaussian,
scaling the result by the target standard deviation, and shifting it
by the target mean.
</p>
</section>

<section>
<h2 id="deterministic-function">Deterministic function  </h2>

<p>In a VAE, each \( \boldsymbol{h} \) is thus computed as a deterministic function of input \( \boldsymbol{x} \) and auxiliary noise variable \( \boldsymbol{\epsilon} \):</p>
<p>&nbsp;<br>
$$
\begin{align*}
    \boldsymbol{h} &= \boldsymbol{\mu}_{\boldsymbol{\phi}}(\boldsymbol{x}) + \boldsymbol{\sigma}_{\boldsymbol{\phi}}(\boldsymbol{x})\odot\boldsymbol{\epsilon} \quad \text{with } \boldsymbol{\epsilon} \sim N(\boldsymbol{\epsilon};\boldsymbol{0}, \textbf{I})
\end{align*}
$$
<p>&nbsp;<br>

<p>where \( \odot \) represents an element-wise product.  Under this
reparameterized version of \( \boldsymbol{h} \), gradients can then be computed
with respect to \( \boldsymbol{\phi} \) as desired, to optimize
\( \boldsymbol{\mu}_{\boldsymbol{\phi}} \) and \( \boldsymbol{\sigma}_{\boldsymbol{\phi}} \).  The VAE
therefore utilizes the reparameterization trick and Monte Carlo
estimates to optimize the ELBO jointly over \( \boldsymbol{\phi} \) and
\( \boldsymbol{\theta} \).
</p>
</section>

<section>
<h2 id="after-training">After training </h2>

<p>After training a VAE, generating new data can be performed by sampling
directly from the latent space \( p(\boldsymbol{h}) \) and then running it through
the decoder.  Variational Autoencoders are particularly interesting
when the dimensionality of \( \boldsymbol{h} \) is less than that of input
\( \boldsymbol{x} \), as we might then be learning compact, useful
representations.  Furthermore, when a semantically meaningful latent
space is learned, latent vectors can be edited before being passed to
the decoder to more precisely control the data generated.
</p>
</section>

<section>
<h2 id="what-is-a-gan">What is a GAN? </h2>

<p>A GAN is a deep neural network which consists of two networks, a
so-called generator network and a discriminating network, or just
discriminator. Through several iterations of generation and
discrimination, the idea is that these networks will train each other,
while also trying to outsmart each other.
</p>

<p>In its simplest version, the two networks could be two standard neural networks with a given number of hidden of hidden layers and parameters to train.</p>
</section>

<section>
<h2 id="what-is-a-generator-network">What is a generator network? </h2>

<p>A generator network is often a deep network which uses existing data
to generate new data (from for example simulations of physical
systems, imagesm video, audio and more) from randomly generated
inputs, the so-called latent space. Training the network allows us to
generate say new data, images etc. As an example a generator network
could for example be a Boltzmann machine as discussed earlier. This
machine is trained to produce for example a quantum mechanical
probability distribution.
</p>

<p>It can be a simple neural network with an input layer and an output layer and a given number of hidden layers.</p>
</section>

<section>
<h2 id="and-what-is-a-discriminator-network">And what is a discriminator network? </h2>

<p>A discriminator tries to distinguish between real data and those generated by the abovementioned generator.</p>
</section>

<section>
<h2 id="appplications-of-gans">Appplications of GANs </h2>

<p>There are exteremely many applications of GANs</p>
<ol>
<p><li> Image generation</li>
<p><li> Text-to-image analysis</li>
<p><li> Face-aging</li>
<p><li> Image-to-image translation</li>
<p><li> Video synthesis</li>
<p><li> High-resolution image generation</li>
<p><li> Completing missing parts of images and much more</li>
</ol>
</section>

<section>
<h2 id="discriminator-versus-generator-borrowed-from-rashcka-et-al">Discriminator versus generator  (Borrowed from Rashcka et al) </h2>

<br/><br/>
<center>
<p><img src="figures/figure2.png" width="900" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="generative-adversarial-networks">Generative Adversarial Networks </h2>

<p><b>Generative Adversarial Networks</b> are a type of unsupervised machine learning
algorithm proposed by Goodfellow et. al, see <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank"><tt>https://arxiv.org/pdf/1406.2661.pdf</tt></a>
in 2014 (Read the paper first it's only 6 pages). The simplest formulation of
the model is based on a game theoretic approach, <em>zero sum game</em>, where we pit
two neural networks against one another. We define two rival networks, one
generator \( g \), and one discriminator \( d \). The generator directly produces
samples
</p>
<p>&nbsp;<br>
$$
    x = g(z; \theta^{(g)}).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="discriminator">Discriminator </h2>

<p>The discriminator attempts to distinguish between samples drawn from the
training data and samples drawn from the generator. In other words, it tries to
tell the difference between the fake data produced by \( g \) and the actual data
samples we want to do prediction on. The discriminator outputs a probability
value given by
</p>

<p>&nbsp;<br>
$$
    d(x; \theta^{(d)}).
$$
<p>&nbsp;<br>

<p>indicating the probability that \( x \) is a real training example rather than a
fake sample the generator has generated.
</p>
</section>

<section>
<h2 id="zero-sum-game">Zero-sum game </h2>

<p>The simplest way to formulate the
learning process in a generative adversarial network is a zero-sum game, in
which a function
</p>

<p>&nbsp;<br>
$$
    v(\theta^{(g)}, \theta^{(d)}),
$$
<p>&nbsp;<br>

<p>determines the reward for the discriminator, while the generator gets the
conjugate reward
</p>

<p>&nbsp;<br>
$$
    -v(\theta^{(g)}, \theta^{(d)})
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="maximizing-reward">Maximizing reward </h2>

<p>During learning both of the networks maximize their own reward function, so that
the generator gets better and better at tricking the discriminator, while the
discriminator gets better and better at telling the difference between the fake
and real data. The generator and discriminator alternate on which one trains at
one time (i.e. for one epoch). In other words, we keep the generator constant
and train the discriminator, then we keep the discriminator constant to train
the generator and repeat. It is this back and forth dynamic which lets GANs
tackle otherwise intractable generative problems. As the generator improves with
 training, the discriminator's performance gets worse because it cannot easily
 tell the difference between real and fake. If the generator ends up succeeding
 perfectly, the the discriminator will do no better than random guessing i.e.
 50\%.
</p>
</section>

<section>
<h2 id="progression-in-training">Progression in training </h2>

<p>This progression in the training poses a problem for the convergence
 criteria for GANs. The discriminator feedback gets less meaningful over time,
 if we continue training after this point then the generator is effectively
 training on junk data which can undo the learning up to that point. Therefore,
 we stop training when the discriminator starts outputting \( 1/2 \) everywhere.
 At convergence we have
</p>

<p>&nbsp;<br>
$$
    g^* = \underset{g}{\mathrm{argmin}}\hspace{2pt}
          \underset{d}{\mathrm{max}}v(\theta^{(g)}, \theta^{(d)}),
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="deafault-choice">Deafault choice </h2>
<p>The default choice for \( v \) is</p>
<p>&nbsp;<br>
$$
    v(\theta^{(g)}, \theta^{(d)}) = \mathbb{E}_{x\sim p_\mathrm{data}}\log d(x)
                                  + \mathbb{E}_{x\sim p_\mathrm{model}}
                                  \log (1 - d(x)).
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="design-of-gans">Design of GANs </h2>
<p>The main motivation for the design of GANs is that the learning process requires
neither approximate inference (variational autoencoders for example) nor
approximation of a partition function. In the case where
</p>
<p>&nbsp;<br>
$$
    \underset{d}{\mathrm{max}}v(\theta^{(g)}, \theta^{(d)})
$$
<p>&nbsp;<br>

<p>is convex in \( \theta^{(g)} \) then the procedure is guaranteed to converge and is
asymptotically consistent
( <a href="https://arxiv.org/pdf/1804.09139.pdf" target="_blank">Seth Lloyd on QuGANs</a>  ). This is in
general not the case and it is possible to get situations where the training
process never converges because the generator and discriminator chase one
another around in the parameter space indefinitely.
</p>
</section>

<section>
<h2 id="steps-in-building-a-gan-borrowed-from-rashcka-et-al">Steps in building a GAN  (Borrowed from Rashcka et al) </h2>

<br/><br/>
<center>
<p><img src="figures/figure3.png" width="900" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="generative-adversarial-networks">Generative Adversarial Networks </h2>
<p>Generative adversarial networks (GANs) have shown great results in
many generative tasks to replicate the real-world rich content such as
images, human language, and music. It is inspired by game theory: two
models, a generator and a discriminator, are competing with each other while
making each other stronger at the same time. However, it is rather
challenging to train a GANs model, 
training instability or failure to converge.
</p>

<p>Generative adversarial networks  consist  of two models (in their simplest form as two opposing feed forward neural networks)</p>
<ol>
<p><li> A discriminator \( D \) estimates the probability of a given sample coming from the real dataset. It works as a critic and is optimized to tell the fake samples from the realo ones</li>
<p><li> A generator \( G \) outputs synthetic samples given a noise variable input \( z \) (\( z \) brings in potential output diversity). It is trained to capture the real data distribution in order to generate samples that can be as real as possible, or in other words, can trick the discriminator to offer a high probability.</li>
</ol>
<p>
<p>At the end of the training, the generator can be used to generate for
example new images. In this sense we have trained a model which can
produce new samples. We say that we have implicitely defined a
probability.
</p>

<p>These two models compete against each other during the training
process: the generator \( G \) is trying hard to trick the discriminator,
while the critic model \( D \) is trying hard not to be cheated. This
interesting zero-sum game between two models motivates both to improve
their functionalities.
</p>

<!-- Given, -->

<!-- \( p_{z} \)  Data distribution over noise input \( z \)  Usually, just uniform. -->
<!-- \( p_{g} \)  The generator's distribution over data \( x \) -->
<!-- \( p_{r} \)   Data distribution over real sample \( x \) -->

<p>On one hand, we want to make sure the discriminator \( D \)'s decisions
over real data are accurate by maximizing \( \mathbb{E}_{x \sim
p_{r}(x)} [\log D(x)] \). Meanwhile, given a fake sample \( G(z), z \sim
p_z(z) \), the discriminator is expected to output a probability,
\( D(G(z)) \), close to zero by maximizing \( \mathbb{E}_{z \sim p_{z}(z)}
[\log (1 - D(G(z)))] \).
</p>

<p>On the other hand, the generator is trained to increase the chances of
\( D \) producing a high probability for a fake example, thus to minimize
\( \mathbb{E}_{z \sim p_{z}(z)} [\log (1 - D(G(z)))] \).
</p>

<p>When combining both aspects together, \( D \) and \( G \) are playing a \textit{minimax game} in which we should optimize the following loss function:</p>

<p>&nbsp;<br>
$$
\begin{aligned}
\min_G \max_D L(D, G) 
& = \mathbb{E}_{x \sim p_{r}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_z(z)} [\log(1 - D(G(z)))] \\
& = \mathbb{E}_{x \sim p_{r}(x)} [\log D(x)] + \mathbb{E}_{x \sim p_g(x)} [\log(1 - D(x)]
\end{aligned}
$$
<p>&nbsp;<br>

<p>where \( \mathbb{E}_{x \sim p_{r}(x)} [\log D(x)] \) has no impact on \( G \) during gradient descent updates.</p>
</section>

<section>
<h2 id="optimal-value-for-d">Optimal value for \( D \) </h2>

<p>Now we have a well-defined loss function. Let's first examine what is the best value for \( D \).</p>

<p>&nbsp;<br>
$$
L(G, D) = \int_x \bigg( p_{r}(x) \log(D(x)) + p_g (x) \log(1 - D(x)) \bigg) dx
$$
<p>&nbsp;<br>

<p>Since we are interested in what is the best value of \( D(x) \) to maximize \( L(G, D) \), let us label </p>

<p>&nbsp;<br>
$$
\tilde{x} = D(x), 
A=p_{r}(x), 
B=p_g(x)
$$
<p>&nbsp;<br>

<p>And then what is inside the integral (we can safely ignore the integral because \( x \) is sampled over all the possible values) is:</p>

<p>&nbsp;<br>
$$
\begin{align*}
f(\tilde{x}) 
& = A log\tilde{x} + B log(1-\tilde{x}) \\
\frac{d f(\tilde{x})}{d \tilde{x}}
& = A \frac{1}{ln10} \frac{1}{\tilde{x}} - B \frac{1}{ln10} \frac{1}{1 - \tilde{x}} \\
& = \frac{1}{ln10} (\frac{A}{\tilde{x}} - \frac{B}{1-\tilde{x}}) \\
& = \frac{1}{ln10} \frac{A - (A + B)\tilde{x}}{\tilde{x} (1 - \tilde{x})} \\
\end{align*}
$$
<p>&nbsp;<br>

<p>Thus, set \( \frac{d f(\tilde{x})}{d \tilde{x}} = 0 \), we get the best value of the discriminator: \( D^*(x) = \tilde{x}^* = \frac{A}{A + B} = \frac{p_{r}(x)}{p_{r}(x) + p_g(x)} \in [0, 1] \).
Once the generator is trained to its optimal, \( p_g \) gets very close to \( p_{r} \). When \( p_g = p_{r} \), \( D^*(x) \) becomes \( 1/2 \).
</p>

<p>When both \( G \) and \( D \) are at their optimal values, we have \( p_g = p_{r} \) and \( D^*(x) = 1/2 \) and the loss function becomes:</p>

<p>&nbsp;<br>
$$
\begin{align*}
L(G, D^*) 
&= \int_x \bigg( p_{r}(x) \log(D^*(x)) + p_g (x) \log(1 - D^*(x)) \bigg) dx \\
&= \log \frac{1}{2} \int_x p_{r}(x) dx + \log \frac{1}{2} \int_x p_g(x) dx \\
&= -2\log2
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="what-does-the-loss-function-represent">What does the Loss Function Represent? </h2>

<p>The JS divergence between \( p_{r} \) and \( p_g \) can be computed as:</p>

<p>&nbsp;<br>
$$
\begin{align*}
D_{JS}(p_{r} \| p_g) 
=& \frac{1}{2} D_{KL}(p_{r} || \frac{p_{r} + p_g}{2}) + \frac{1}{2} D_{KL}(p_{g} || \frac{p_{r} + p_g}{2}) \\
=& \frac{1}{2} \bigg( \log2 + \int_x p_{r}(x) \log \frac{p_{r}(x)}{p_{r} + p_g(x)} dx \bigg) + \\& \frac{1}{2} \bigg( \log2 + \int_x p_g(x) \log \frac{p_g(x)}{p_{r} + p_g(x)} dx \bigg) \\
=& \frac{1}{2} \bigg( \log4 + L(G, D^*) \bigg)
\end{align*}
$$
<p>&nbsp;<br>

<p>Thus, </p>

<p>&nbsp;<br>
$$
L(G, D^*) = 2D_{JS}(p_{r} \| p_g) - 2\log2
$$
<p>&nbsp;<br>

<p>Essentially the loss function of GAN quantifies the similarity between
the generative data distribution \( p_g \) and the real sample
distribution \( p_{r} \) by JS divergence when the discriminator is
optimal. The best \( G^* \) that replicates the real data distribution
leads to the minimum \( L(G^*, D^*) = -2\log2 \) which is aligned with
equations above.
</p>
</section>

<section>
<h2 id="more-references">More references </h2>

<p>A much deeper discussion on
the currently open research problem of GAN convergence is available
from <a href="https://www.deeplearningbook.org/contents/generative_models.html" target="_blank"><tt>https://www.deeplearningbook.org/contents/generative_models.html</tt></a>. To
anyone interested in learning more about GANs it is a highly recommended read.
Direct quote: <b>In this best-performing formulation, the generator aims to
increase the log probability that the discriminator makes a mistake, rather than
aiming to decrease the log probability that the discriminator makes the correct
prediction.</b> Another interesting read can be found at <a href="https://arxiv.org/abs/1701.00160" target="_blank"><tt>https://arxiv.org/abs/1701.00160</tt></a>.
</p>
</section>

<section>
<h2 id="writing-our-first-generative-adversarial-network">Writing Our First Generative Adversarial Network </h2>

<p>This part is best seen using the jupyter-notebook. We follow here
closely the code developed by Raschka et al from chapter 17 of their
textbook, see <a href="https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17" target="_blank"><tt>https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17</tt></a> for codes.
</p>
</section>

<section>
<h2 id="implementing-the-networks-borrowed-from-rashcka-et-al">Implementing the networks   (Borrowed from Rashcka et al) </h2>

<br/><br/>
<center>
<p><img src="figures/figure4.png" width="900" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="code-elements">Code elements </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch</span>
<span style="color: #658b00">print</span>(torch.__version__)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">&quot;GPU Available:&quot;</span>, torch.cuda.is_available())

<span style="color: #8B008B; font-weight: bold">if</span> torch.cuda.is_available():
    device = torch.device(<span style="color: #CD5555">&quot;cuda:0&quot;</span>)
<span style="color: #8B008B; font-weight: bold">else</span>:
    device = <span style="color: #CD5555">&quot;cpu&quot;</span>

<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torch.nn</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">nn</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="setting-up-the-gan">Setting up the GAN </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #228B22">## define a function for the generator:</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">make_generator_network</span>(
        input_size=<span style="color: #B452CD">20</span>,
        num_hidden_layers=<span style="color: #B452CD">1</span>,
        num_hidden_units=<span style="color: #B452CD">100</span>,
        num_output_units=<span style="color: #B452CD">784</span>):
    model = nn.Sequential()
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(num_hidden_layers):
        model.add_module(<span style="color: #CD5555">f&#39;fc_g{</span>i<span style="color: #CD5555">}&#39;</span>, 
                         nn.Linear(input_size, 
                                   num_hidden_units)) 
        model.add_module(<span style="color: #CD5555">f&#39;relu_g{</span>i<span style="color: #CD5555">}&#39;</span>, 
                         nn.LeakyReLU())     
        input_size = num_hidden_units
    model.add_module(<span style="color: #CD5555">f&#39;fc_g{</span>num_hidden_layers<span style="color: #CD5555">}&#39;</span>, 
                    nn.Linear(input_size, num_output_units))   
    model.add_module(<span style="color: #CD5555">&#39;tanh_g&#39;</span>, nn.Tanh())      
    <span style="color: #8B008B; font-weight: bold">return</span> model

<span style="color: #228B22">## define a function for the discriminator:</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">make_discriminator_network</span>(
        input_size,
        num_hidden_layers=<span style="color: #B452CD">1</span>,
        num_hidden_units=<span style="color: #B452CD">100</span>,
        num_output_units=<span style="color: #B452CD">1</span>):
    model = nn.Sequential()
    <span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(num_hidden_layers):
        model.add_module(<span style="color: #CD5555">f&#39;fc_d{</span>i<span style="color: #CD5555">}&#39;</span>, 
                 nn.Linear(input_size, 
                           num_hidden_units, bias=<span style="color: #8B008B; font-weight: bold">False</span>)) 
        model.add_module(<span style="color: #CD5555">f&#39;relu_d{</span>i<span style="color: #CD5555">}&#39;</span>, 
                         nn.LeakyReLU())  
        model.add_module(<span style="color: #CD5555">&#39;dropout&#39;</span>, nn.Dropout(p=<span style="color: #B452CD">0.5</span>))
        input_size = num_hidden_units
    model.add_module(<span style="color: #CD5555">f&#39;fc_d{</span>num_hidden_layers<span style="color: #CD5555">}&#39;</span>, 
                     nn.Linear(input_size, num_output_units))   
    model.add_module(<span style="color: #CD5555">&#39;sigmoid&#39;</span>, nn.Sigmoid())
    <span style="color: #8B008B; font-weight: bold">return</span> model
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="printing-the-model">Printing the model </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">image_size = (<span style="color: #B452CD">28</span>, <span style="color: #B452CD">28</span>)
z_size = <span style="color: #B452CD">20</span>

gen_hidden_layers = <span style="color: #B452CD">1</span>
gen_hidden_size = <span style="color: #B452CD">100</span>
disc_hidden_layers = <span style="color: #B452CD">1</span>
disc_hidden_size = <span style="color: #B452CD">100</span>

torch.manual_seed(<span style="color: #B452CD">1</span>)

gen_model = make_generator_network(
    input_size=z_size,
    num_hidden_layers=gen_hidden_layers, 
    num_hidden_units=gen_hidden_size,
    num_output_units=np.prod(image_size))
 
<span style="color: #658b00">print</span>(gen_model)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">disc_model = make_discriminator_network(
    input_size=np.prod(image_size),
    num_hidden_layers=disc_hidden_layers,
    num_hidden_units=disc_hidden_size)

<span style="color: #658b00">print</span>(disc_model)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="defining-the-training-set">Defining the training set </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> 
<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torchvision</span> <span style="color: #8B008B; font-weight: bold">import</span> transforms 


image_path = <span style="color: #CD5555">&#39;./&#39;</span>
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=(<span style="color: #B452CD">0.5</span>), std=(<span style="color: #B452CD">0.5</span>)),
])
mnist_dataset = torchvision.datasets.MNIST(root=image_path, 
                                           train=<span style="color: #8B008B; font-weight: bold">True</span>, 
                                           transform=transform, 
                                           download=<span style="color: #8B008B; font-weight: bold">True</span>)

example, label = <span style="color: #658b00">next</span>(<span style="color: #658b00">iter</span>(mnist_dataset))
<span style="color: #658b00">print</span>(<span style="color: #CD5555">f&#39;Min: {</span>example.min()<span style="color: #CD5555">} Max: {</span>example.max()<span style="color: #CD5555">}&#39;</span>)
<span style="color: #658b00">print</span>(example.shape)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="defining-the-training-set-part-2">Defining the training set, part 2 </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">create_noise</span>(batch_size, z_size, mode_z):
    <span style="color: #8B008B; font-weight: bold">if</span> mode_z == <span style="color: #CD5555">&#39;uniform&#39;</span>:
        input_z = torch.rand(batch_size, z_size)*<span style="color: #B452CD">2</span> - <span style="color: #B452CD">1</span> 
    <span style="color: #8B008B; font-weight: bold">elif</span> mode_z == <span style="color: #CD5555">&#39;normal&#39;</span>:
        input_z = torch.randn(batch_size, z_size)
    <span style="color: #8B008B; font-weight: bold">return</span> input_z


<span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">torch.utils.data</span> <span style="color: #8B008B; font-weight: bold">import</span> DataLoader


batch_size = <span style="color: #B452CD">32</span>
dataloader = DataLoader(mnist_dataset, batch_size, shuffle=<span style="color: #8B008B; font-weight: bold">False</span>)
input_real, label = <span style="color: #658b00">next</span>(<span style="color: #658b00">iter</span>(dataloader))
input_real = input_real.view(batch_size, -<span style="color: #B452CD">1</span>)

torch.manual_seed(<span style="color: #B452CD">1</span>)
mode_z = <span style="color: #CD5555">&#39;uniform&#39;</span>  <span style="color: #228B22"># &#39;uniform&#39; vs. &#39;normal&#39;</span>
input_z = create_noise(batch_size, z_size, mode_z)

<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;input-z -- shape:&#39;</span>, input_z.shape)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;input-real -- shape:&#39;</span>, input_real.shape)

g_output = gen_model(input_z)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Output of G -- shape:&#39;</span>, g_output.shape)

d_proba_real = disc_model(input_real)
d_proba_fake = disc_model(g_output)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Disc. (real) -- shape:&#39;</span>, d_proba_real.shape)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">&#39;Disc. (fake) -- shape:&#39;</span>, d_proba_fake.shape)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="training-the-gan">Training the GAN </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">loss_fn = nn.BCELoss()

<span style="color: #228B22">## Loss for the Generator</span>
g_labels_real = torch.ones_like(d_proba_fake)
g_loss = loss_fn(d_proba_fake, g_labels_real)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">f&#39;Generator Loss: {</span>g_loss<span style="color: #CD5555">:.4f}&#39;</span>)

<span style="color: #228B22">## Loss for the Discriminator</span>
d_labels_real = torch.ones_like(d_proba_real)
d_labels_fake = torch.zeros_like(d_proba_fake)

d_loss_real = loss_fn(d_proba_real, d_labels_real)
d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)
<span style="color: #658b00">print</span>(<span style="color: #CD5555">f&#39;Discriminator Losses: Real {</span>d_loss_real<span style="color: #CD5555">:.4f} Fake {</span>d_loss_fake<span style="color: #CD5555">:.4f}&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="more-on-training">More on training  </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">batch_size = <span style="color: #B452CD">64</span>

torch.manual_seed(<span style="color: #B452CD">1</span>)
np.random.seed(<span style="color: #B452CD">1</span>)

<span style="color: #228B22">## Set up the dataset</span>
mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size, 
                      shuffle=<span style="color: #8B008B; font-weight: bold">True</span>, drop_last=<span style="color: #8B008B; font-weight: bold">True</span>)
 
<span style="color: #228B22">## Set up the models</span>
gen_model = make_generator_network(
    input_size=z_size,
    num_hidden_layers=gen_hidden_layers, 
    num_hidden_units=gen_hidden_size,
    num_output_units=np.prod(image_size)).to(device)
 
disc_model = make_discriminator_network(
    input_size=np.prod(image_size),
    num_hidden_layers=disc_hidden_layers,
    num_hidden_units=disc_hidden_size).to(device)
 
<span style="color: #228B22">## Loss function and optimizers:</span>
loss_fn = nn.BCELoss()
g_optimizer = torch.optim.Adam(gen_model.parameters())
d_optimizer = torch.optim.Adam(disc_model.parameters())

<span style="color: #228B22">## Train the discriminator</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">d_train</span>(x):
    disc_model.zero_grad()

    <span style="color: #228B22"># Train discriminator with a real batch</span>
    batch_size = x.size(<span style="color: #B452CD">0</span>)
    x = x.view(batch_size, -<span style="color: #B452CD">1</span>).to(device)
    d_labels_real = torch.ones(batch_size, <span style="color: #B452CD">1</span>, device=device)

    d_proba_real = disc_model(x)
    d_loss_real = loss_fn(d_proba_real, d_labels_real)

    <span style="color: #228B22"># Train discriminator on a fake batch</span>
    input_z = create_noise(batch_size, z_size, mode_z).to(device)
    g_output = gen_model(input_z)
    
    d_proba_fake = disc_model(g_output)
    d_labels_fake = torch.zeros(batch_size, <span style="color: #B452CD">1</span>, device=device)
    d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)

    <span style="color: #228B22"># gradient backprop &amp; optimize ONLY D&#39;s parameters</span>
    d_loss = d_loss_real + d_loss_fake
    d_loss.backward()
    d_optimizer.step()
  
    <span style="color: #8B008B; font-weight: bold">return</span> d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()

<span style="color: #228B22">## Train the generator</span>
<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">g_train</span>(x):
    gen_model.zero_grad()
    
    batch_size = x.size(<span style="color: #B452CD">0</span>)
    input_z = create_noise(batch_size, z_size, mode_z).to(device)
    g_labels_real = torch.ones(batch_size, <span style="color: #B452CD">1</span>, device=device)

    g_output = gen_model(input_z)
    d_proba_fake = disc_model(g_output)
    g_loss = loss_fn(d_proba_fake, g_labels_real)

    <span style="color: #228B22"># gradient backprop &amp; optimize ONLY G&#39;s parameters</span>
    g_loss.backward()
    g_optimizer.step()
        
    <span style="color: #8B008B; font-weight: bold">return</span> g_loss.data.item()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">fixed_z = create_noise(batch_size, z_size, mode_z).to(device)

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">create_samples</span>(g_model, input_z):
    g_output = g_model(input_z)
    images = torch.reshape(g_output, (batch_size, *image_size))    
    <span style="color: #8B008B; font-weight: bold">return</span> (images+<span style="color: #B452CD">1</span>)/<span style="color: #B452CD">2.0</span>

epoch_samples = []

all_d_losses = []
all_g_losses = []

all_d_real = []
all_d_fake = []

num_epochs = <span style="color: #B452CD">100</span>
torch.manual_seed(<span style="color: #B452CD">1</span>)
<span style="color: #8B008B; font-weight: bold">for</span> epoch <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #B452CD">1</span>, num_epochs+<span style="color: #B452CD">1</span>):
    d_losses, g_losses = [], []
    d_vals_real, d_vals_fake = [], []
    <span style="color: #8B008B; font-weight: bold">for</span> i, (x, _) <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(mnist_dl):
        d_loss, d_proba_real, d_proba_fake = d_train(x)
        d_losses.append(d_loss)
        g_losses.append(g_train(x))
        
        d_vals_real.append(d_proba_real.mean().cpu())
        d_vals_fake.append(d_proba_fake.mean().cpu())
        
    all_d_losses.append(torch.tensor(d_losses).mean())
    all_g_losses.append(torch.tensor(g_losses).mean())
    all_d_real.append(torch.tensor(d_vals_real).mean())
    all_d_fake.append(torch.tensor(d_vals_fake).mean())
    <span style="color: #658b00">print</span>(<span style="color: #CD5555">f&#39;Epoch {</span>epoch<span style="color: #CD5555">:03d} | Avg Losses &gt;&gt;&#39;</span>
          <span style="color: #CD5555">f&#39; G/D {</span>all_g_losses[-<span style="color: #B452CD">1</span>]<span style="color: #CD5555">:.4f}/{</span>all_d_losses[-<span style="color: #B452CD">1</span>]<span style="color: #CD5555">:.4f}&#39;</span>
          <span style="color: #CD5555">f&#39; [D-Real: {</span>all_d_real[-<span style="color: #B452CD">1</span>]<span style="color: #CD5555">:.4f} D-Fake: {</span>all_d_fake[-<span style="color: #B452CD">1</span>]<span style="color: #CD5555">:.4f}]&#39;</span>)
    epoch_samples.append(
        create_samples(gen_model, fixed_z).detach().cpu().numpy())
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="visualizing">Visualizing </h2>


<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">itertools</span>


fig = plt.figure(figsize=(<span style="color: #B452CD">16</span>, <span style="color: #B452CD">6</span>))

<span style="color: #228B22">## Plotting the losses</span>
ax = fig.add_subplot(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>, <span style="color: #B452CD">1</span>)
 
plt.plot(all_g_losses, label=<span style="color: #CD5555">&#39;Generator loss&#39;</span>)
half_d_losses = [all_d_loss/<span style="color: #B452CD">2</span> <span style="color: #8B008B; font-weight: bold">for</span> all_d_loss <span style="color: #8B008B">in</span> all_d_losses]
plt.plot(half_d_losses, label=<span style="color: #CD5555">&#39;Discriminator loss&#39;</span>)
plt.legend(fontsize=<span style="color: #B452CD">20</span>)
ax.set_xlabel(<span style="color: #CD5555">&#39;Iteration&#39;</span>, size=<span style="color: #B452CD">15</span>)
ax.set_ylabel(<span style="color: #CD5555">&#39;Loss&#39;</span>, size=<span style="color: #B452CD">15</span>)

<span style="color: #228B22">## Plotting the outputs of the discriminator</span>
ax = fig.add_subplot(<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>, <span style="color: #B452CD">2</span>)
plt.plot(all_d_real, label=<span style="color: #CD5555">r&#39;Real: $D(\mathbf{x})$&#39;</span>)
plt.plot(all_d_fake, label=<span style="color: #CD5555">r&#39;Fake: $D(G(\mathbf{z}))$&#39;</span>)
plt.legend(fontsize=<span style="color: #B452CD">20</span>)
ax.set_xlabel(<span style="color: #CD5555">&#39;Iteration&#39;</span>, size=<span style="color: #B452CD">15</span>)
ax.set_ylabel(<span style="color: #CD5555">&#39;Discriminator output&#39;</span>, size=<span style="color: #B452CD">15</span>)

<span style="color: #228B22">#plt.savefig(&#39;figures/ch17-gan-learning-curve.pdf&#39;)</span>
plt.show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;">selected_epochs = [<span style="color: #B452CD">1</span>, <span style="color: #B452CD">2</span>, <span style="color: #B452CD">4</span>, <span style="color: #B452CD">10</span>, <span style="color: #B452CD">50</span>, <span style="color: #B452CD">100</span>]
fig = plt.figure(figsize=(<span style="color: #B452CD">10</span>, <span style="color: #B452CD">14</span>))
<span style="color: #8B008B; font-weight: bold">for</span> i,e <span style="color: #8B008B">in</span> <span style="color: #658b00">enumerate</span>(selected_epochs):
    <span style="color: #8B008B; font-weight: bold">for</span> j <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #B452CD">5</span>):
        ax = fig.add_subplot(<span style="color: #B452CD">6</span>, <span style="color: #B452CD">5</span>, i*<span style="color: #B452CD">5</span>+j+<span style="color: #B452CD">1</span>)
        ax.set_xticks([])
        ax.set_yticks([])
        <span style="color: #8B008B; font-weight: bold">if</span> j == <span style="color: #B452CD">0</span>:
            ax.text(
                -<span style="color: #B452CD">0.06</span>, <span style="color: #B452CD">0.5</span>, <span style="color: #CD5555">f&#39;Epoch {</span>e<span style="color: #CD5555">}&#39;</span>,
                rotation=<span style="color: #B452CD">90</span>, size=<span style="color: #B452CD">18</span>, color=<span style="color: #CD5555">&#39;red&#39;</span>,
                horizontalalignment=<span style="color: #CD5555">&#39;right&#39;</span>,
                verticalalignment=<span style="color: #CD5555">&#39;center&#39;</span>, 
                transform=ax.transAxes)
        
        image = epoch_samples[e-<span style="color: #B452CD">1</span>][j]
        ax.imshow(image, cmap=<span style="color: #CD5555">&#39;gray_r&#39;</span>)
    
<span style="color: #228B22">#plt.savefig(&#39;figures/ch17-vanila-gan-samples.pdf&#39;)</span>
plt.show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="calculating-scores">Calculating scores </h2>

<!-- code=python (!bc pycod) typeset with pygments style "perldoc" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #eeeedd">
  <pre style="font-size: 80%; line-height: 125%;"><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">math</span>


<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">distance</span>(X, Y, sqrt):
    nX = X.size(<span style="color: #B452CD">0</span>)
    nY = Y.size(<span style="color: #B452CD">0</span>)
    X = X.view(nX,-<span style="color: #B452CD">1</span>).cuda()
    X2 = (X*X).sum(<span style="color: #B452CD">1</span>).resize_(nX,<span style="color: #B452CD">1</span>)
    Y = Y.view(nY,-<span style="color: #B452CD">1</span>).cuda()
    Y2 = (Y*Y).sum(<span style="color: #B452CD">1</span>).resize_(nY,<span style="color: #B452CD">1</span>)

    M = torch.zeros(nX, nY)
    M.copy_(X2.expand(nX,nY) + Y2.expand(nY,nX).transpose(<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>) - <span style="color: #B452CD">2</span>*torch.mm(X,Y.transpose(<span style="color: #B452CD">0</span>,<span style="color: #B452CD">1</span>)))

    <span style="color: #8B008B; font-weight: bold">del</span> X, X2, Y, Y2
    
    <span style="color: #8B008B; font-weight: bold">if</span> sqrt:
        M = ((M+M.abs())/<span style="color: #B452CD">2</span>).sqrt()
    
    <span style="color: #8B008B; font-weight: bold">return</span> M

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">mmd</span>(Mxx, Mxy, Myy, sigma) :
    scale = Mxx.mean()
    Mxx = torch.exp(-Mxx/(scale*<span style="color: #B452CD">2</span>*sigma*sigma))
    Mxy = torch.exp(-Mxy/(scale*<span style="color: #B452CD">2</span>*sigma*sigma))
    Myy = torch.exp(-Myy/(scale*<span style="color: #B452CD">2</span>*sigma*sigma))
    a = Mxx.mean()+Myy.mean()-<span style="color: #B452CD">2</span>*Mxy.mean()
    mmd = math.sqrt(<span style="color: #658b00">max</span>(a, <span style="color: #B452CD">0</span>))

    <span style="color: #8B008B; font-weight: bold">return</span> mmd

<span style="color: #8B008B; font-weight: bold">def</span> <span style="color: #008b45">compute_score</span>(fake, real , k=<span style="color: #B452CD">1</span>, sigma=<span style="color: #B452CD">1</span>, sqrt=<span style="color: #8B008B; font-weight: bold">True</span>):

    Mxx = distance(real, real, <span style="color: #8B008B; font-weight: bold">False</span>)
    Mxy = distance(real, fake, <span style="color: #8B008B; font-weight: bold">False</span>)
    Myy = distance(fake, fake, <span style="color: #8B008B; font-weight: bold">False</span>)

 
    <span style="color: #658b00">print</span>(mmd(Mxx, Mxy, Myy, sigma))

whole_dl = DataLoader(mnist_dataset, batch_size=<span style="color: #B452CD">10000</span>, 
                      shuffle=<span style="color: #8B008B; font-weight: bold">True</span>, drop_last=<span style="color: #8B008B; font-weight: bold">True</span>) 
real_image = <span style="color: #658b00">next</span>(<span style="color: #658b00">iter</span>(whole_dl))[<span style="color: #B452CD">0</span>]
compute_score(torch.from_numpy(epoch_samples[-<span style="color: #B452CD">1</span>]), real_image)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section>
<h2 id="diffusion-models-basics">Diffusion models, basics </h2>

<p>Diffusion models are inspired by non-equilibrium thermodynamics. They
define a Markov chain of diffusion steps to slowly add random noise to
data and then learn to reverse the diffusion process to construct
desired data samples from the noise. Unlike VAE or flow models,
diffusion models are learned with a fixed procedure and the latent
variable has high dimensionality (same as the original data).
</p>
</section>

<section>
<h2 id="problems-with-probabilistic-models">Problems with probabilistic models </h2>

<p>Historically, probabilistic models suffer from a tradeoff between two
conflicting objectives: \textit{tractability} and
\textit{flexibility}. Models that are \textit{tractable} can be
analytically evaluated and easily fit to data (e.g. a Gaussian or
Laplace). However, these models are unable to aptly describe structure
in rich datasets. On the other hand, models that are \textit{flexible}
can be molded to fit structure in arbitrary data. For example, we can
define models in terms of any (non-negative) function \( \phi(\boldsymbol{x}) \)
yielding the flexible distribution \( p\left(\boldsymbol{x}\right) =
\frac{\phi\left(\boldsymbol{x} \right)}{Z} \), where \( Z \) is a normalization
constant. However, computing this normalization constant is generally
intractable. Evaluating, training, or drawing samples from such
flexible models typically requires a very expensive Monte Carlo
process.
</p>
</section>

<section>
<h2 id="diffusion-models">Diffusion models </h2>
<p>Diffusion models have several interesting features</p>
<ul>
<p><li> extreme flexibility in model structure,</li>
<p><li> exact sampling,</li>
<p><li> easy multiplication with other distributions, e.g. in order to compute a posterior, and</li>
<p><li> the model log likelihood, and the probability of individual states, to be cheaply evaluated.</li>
</ul>
</section>

<section>
<h2 id="original-idea">Original idea </h2>

<p>In the original formulation, one uses a Markov chain to gradually
convert one distribution into another, an idea used in non-equilibrium
statistical physics and sequential Monte Carlo. Diffusion models build
a generative Markov chain which converts a simple known distribution
(e.g. a Gaussian) into a target (data) distribution using a diffusion
process. Rather than use this Markov chain to approximately evaluate a
model which has been otherwise defined, one can  explicitly define the
probabilistic model as the endpoint of the Markov chain. Since each
step in the diffusion chain has an analytically evaluable probability,
the full chain can also be analytically evaluated.
</p>
</section>

<section>
<h2 id="diffusion-learning">Diffusion learning </h2>

<p>Learning in this framework involves estimating small perturbations to
a diffusion process. Estimating small, analytically tractable,
perturbations is more tractable than explicitly describing the full
distribution with a single, non-analytically-normalizable, potential
function.  Furthermore, since a diffusion process exists for any
smooth target distribution, this method can capture data distributions
of arbitrary form.
</p>
</section>



</div> <!-- class="slides" -->
</div> <!-- class="reveal" -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

  // Display navigation controls in the bottom right corner
  controls: true,

  // Display progress bar (below the horiz. slider)
  progress: true,

  // Display the page number of the current slide
  slideNumber: true,

  // Push each slide change to the browser history
  history: false,

  // Enable keyboard shortcuts for navigation
  keyboard: true,

  // Enable the slide overview mode
  overview: true,

  // Vertical centering of slides
  //center: true,
  center: false,

  // Enables touch navigation on devices with touch input
  touch: true,

  // Loop the presentation
  loop: false,

  // Change the presentation direction to be RTL
  rtl: false,

  // Turns fragments on and off globally
  fragments: true,

  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,

  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,

  // Stop auto-sliding after user input
  autoSlideStoppable: true,

  // Enable slide navigation via mouse wheel
  mouseWheel: false,

  // Hides the address bar on mobile devices
  hideAddressBar: true,

  // Opens links in an iframe preview overlay
  previewLinks: false,

  // Transition style
  transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

  // Transition speed
  transitionSpeed: 'default', // default/fast/slow

  // Transition style for full page slide backgrounds
  backgroundTransition: 'default', // default/none/slide/concave/convex/zoom

  // Number of slides away from the current that are visible
  viewDistance: 3,

  // Parallax background image
    //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

  // Parallax background size
  //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

  theme: Reveal.getQueryHash().theme, // available themes are in reveal.js/css/theme
    transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/none

});

Reveal.initialize({
  dependencies: [
      // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },

      // Interpret Markdown in <section> elements
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

      // Syntax highlight for <code> elements
      { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

      // Zoom in and out with Alt+click
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },

      // Speaker notes
      { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },

      // Remote control your reveal.js presentation using a touch device
      //{ src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } },

      // MathJax
      //{ src: 'reveal.js/plugin/math/math.js', async: true }
  ]
});

Reveal.initialize({

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 1170,  // original: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.0

});
</script>

<!-- begin footer logo
<div style="position: absolute; bottom: 0px; left: 0; margin-left: 0px">
<img src="somelogo.png">
</div>
   end footer logo -->




</body>
</html>

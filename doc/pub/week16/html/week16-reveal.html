<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week16-reveal.html week16-reveal reveal --html_slide_theme=beige
-->
<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Advanced machine learning and data analysis for the physical sciences">
<title>Advanced machine learning and data analysis for the physical sciences</title>

<!-- reveal.js: https://lab.hakim.se/reveal-js/ -->

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<!--
<link rel="stylesheet" href="reveal.js/css/reveal.css">
<link rel="stylesheet" href="reveal.js/css/theme/beige.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/beigesmall.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/solarized.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/serif.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/night.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/moon.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/sky.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/darkgray.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/default.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/cbc.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/simula.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/white.css" id="theme">
<link rel="stylesheet" href="reveal.js/css/theme/league.css" id="theme">
-->

<!-- For syntax highlighting -->
<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<style type="text/css">
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.reveal .alert-text-small   { font-size: 80%;  }
.reveal .alert-text-large   { font-size: 130%; }
.reveal .alert-text-normal  { font-size: 90%;  }
.reveal .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
  -webkit-border-radius: 14px; -moz-border-radius: 14px;
  border-radius:14px;
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.reveal .alert-block {padding-top:14px; padding-bottom:14px}
.reveal .alert-block > p, .alert-block > ul {margin-bottom:1em}
/*.reveal .alert li {margin-top: 1em}*/
.reveal .alert-block p+p {margin-top:5px}
/*.reveal .alert-notice { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_notice.png); }
.reveal .alert-summary  { background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_summary.png); }
.reveal .alert-warning { background-image: url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_warning.png); }
.reveal .alert-question {background-image:url(https://hplgit.github.io/doconce/bundled/html_images/small_gray_question.png); } */
/* Override reveal.js table border */
.reveal table td {
  border: 0;
}

<style type="text/css">
/* Override h1, h2, ... styles */
h1 { font-size: 2.8em; }
h2 { font-size: 1.5em; }
h3 { font-size: 1.4em; }
h4 { font-size: 1.3em; }
h1, h2, h3, h4 { font-weight: bold; line-height: 1.2; }
body { overflow: auto; } /* vertical scrolling */
hr { border: 0; width: 80%; border-bottom: 1px solid #aaa}
p.caption { width: 80%; font-size: 60%; font-style: italic; text-align: left; }
hr.figure { border: 0; width: 80%; border-bottom: 1px solid #aaa}
.slide .alert-text-small   { font-size: 80%;  }
.slide .alert-text-large   { font-size: 130%; }
.slide .alert-text-normal  { font-size: 90%;  }
.slide .alert {
  padding:8px 35px 8px 14px; margin-bottom:18px;
  text-shadow:0 1px 0 rgba(255,255,255,0.5);
  border:5px solid #bababa;
    -webkit-border-radius:14px; -moz-border-radius:14px;
  border-radius:14px
  background-position: 10px 10px;
  background-repeat: no-repeat;
  background-size: 38px;
  padding-left: 30px; /* 55px; if icon */
}
.slide .alert-block {padding-top:14px; padding-bottom:14px}
.slide .alert-block > p, .alert-block > ul {margin-bottom:0}
/*.slide .alert li {margin-top: 1em}*/
.deck .alert-block p+p {margin-top:5px}
/*.slide .alert-notice { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_notice.png); }
.slide .alert-summary  { background-image:url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_summary.png); }
.slide .alert-warning { background-image: url(https://hplgit.github.io/doconce/
bundled/html_images//small_gray_warning.png); }
.slide .alert-question {background-image:url(https://hplgit.github.io/doconce/
bundled/html_images/small_gray_question.png); } */
.dotable table, .dotable th, .dotable tr, .dotable tr td {
  border: 2px solid black;
  border-collapse: collapse;
  padding: 2px;
}
</style>


<!-- Styles for table layout of slides -->
<style type="text/css">
td.padding {
  padding-top:20px;
  padding-bottom:20px;
  padding-right:50px;
  padding-left:50px;
}
</style>

</head>


<body>
<div class="reveal">
<div class="slides">





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




<section>
<!-- ------------------- main content ---------------------- -->
<center>
<h1 style="text-align: center;">Advanced machine learning and data analysis for the physical sciences</h1>
</center>  <!-- document title -->

<!-- author(s): Morten Hjorth-Jensen -->
<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>
<!-- institution(s) -->
<center>
[1] <b>Department of Physics and Center for Computing in Science Education, University of Oslo, Norway</b>
</center>
<center>
[2] <b>Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA</b>
</center>
<br>
<center>
<h4>May 7, 2024</h4>
</center> <!-- date -->
<br>


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2024, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>
</section>

<section>
<h2 id="plans-for-the-week-of-may-6-10-2024">Plans for the week of May 6-10, 2024  </h2>

<div class="alert alert-block alert-block alert-text-normal">
<b>Generative models</b>
<p>
<ol>
<p><li> Finalizing discussion of Generative Adversarial Networks</li>
<p><li> Mathematics of diffusion models and selected examples
<!-- o "Video of lecture":"" --></li>
<p><li> <a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesMay7.pdf" target="_blank">Whiteboard notes</a></li>
</ol>
</div>


<div class="alert alert-block alert-block alert-text-normal">
<b>Reading on diffusion models</b>
<p>
<ol>
<p><li> A central paper is the one by Sohl-Dickstein et al, Deep Unsupervised Learning using Nonequilibrium Thermodynamics, <a href="https://arxiv.org/abs/1503.03585" target="_blank"><tt>https://arxiv.org/abs/1503.03585</tt></a></li>
<p><li> See also Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho, Variational Diffusion Models, <a href="https://arxiv.org/abs/2107.00630" target="_blank"><tt>https://arxiv.org/abs/2107.00630</tt></a></li>
</ol>
</div>
</section>

<section>
<h2 id="reminder-from-last-week-what-is-a-gan">Reminder from last week, what is a GAN? </h2>

<p>A GAN is a deep neural network which consists of two networks, a
so-called generator network and a discriminating network, or just
discriminator. Through several iterations of generation and
discrimination, the idea is that these networks will train each other,
while also trying to outsmart each other.
</p>

<p>In its simplest version, the two networks could be two standard neural networks with a given number of hidden of hidden layers and parameters to train.
The generator we have trained can then be used to produce new images.
</p>
</section>

<section>
<h2 id="labeling-the-networks">Labeling the networks </h2>

<p>For a GAN we have: </p>
<ol>
<p><li> a discriminator \( D \) estimates the probability of a given sample coming from the real dataset. It attempts at discriminating the trained data by the generator and is optimized to tell the fake samples from the real ones (our data set). We say a  discriminator tries to distinguish between real data and those generated by the abovementioned generator.</li>
<p><li> a generator \( G \) outputs synthetic samples given a noise variable input \( z \) (\( z \) brings in potential output diversity). It is trained to capture the real data distribution in order to generate samples that can be as real as possible, or in other words, can trick the discriminator to offer a high probability.</li>
</ol>
<p>
<p>At the end of the training, the generator can be used to generate for
example new images. In this sense we have trained a model which can
produce new samples. We say that we have implicitely defined a
probability.
</p>
</section>

<section>
<h2 id="which-data">Which data? </h2>

<p><b>GANs are generally a form of unsupervised machine learning</b>, although
they also incorporate aspects of supervised learning. Internally the
discriminator sets up a supervised learning problem. Its goal is to
learn to distinguish between the two classes of generated data and
original data. The generator then considers this classification
problem and tries to find adversarial examples, that is  samples which
will be misclassified by the discriminator.
</p>

<p>One can also design GAN architectures which work in a
semi-supervised learning setting. A semi-supervised learning environment includes both labeled and unlabeled data.
See <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf" target="_blank"><tt>https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf</tt></a> for a further discussion.
</p>

<p>Thus, GANs can be used both on labeled and on unlabeled data and are used in three most commonly used contexts, that is</p>
<ol>
<p><li> with labeled data (supervised training)</li>
<p><li> with unlabeled data (unsupervised learning)</li>
<p><li> a with a mix labed and unlabeled  data</li>
</ol>
</section>

<section>
<h2 id="improving-functionalities">Improving functionalities </h2>

<p>These two models compete against each other during the training
process: the generator \( G \) is trying hard to trick the discriminator,
while the critic model \( D \) is trying hard not to be cheated. This
interesting zero-sum game between two models motivates both to improve
their functionalities.
</p>
</section>

<section>
<h2 id="setup-of-the-gan">Setup of the GAN </h2>

<p>We define a probability \( p_{\boldsymbol{h}} \) which is used by the
generator. Usually it is given by a uniform distribution over the
input input \( \boldsymbol{h} \). Thereafter we define the distribution of the
generator which we want to train, \( p_{g} \) This is the generator's
distribution over the data \( \boldsymbol{x} \). Finally, we have the distribution
\( p_{r} \) over the real sample \( \boldsymbol{x} \)
</p>
</section>

<section>
<h2 id="optimization-part">Optimization part </h2>

<p>On one hand, we want to make sure the discriminator \( D \)'s decisions
over real data are accurate by maximizing \( \mathbb{E}_{\boldsymbol{x} \sim
p_{r}(\boldsymbol{x})} [\log D(\boldsymbol{x})] \). Meanwhile, given a fake sample \( G(\boldsymbol{h}), \boldsymbol{h} \sim
p_{\boldsymbol{h}}(\boldsymbol{h}) \), the discriminator is expected to output a probability,
\( D(G(\boldsymbol{h})) \), close to zero by maximizing \( \mathbb{E}_{\boldsymbol{h} \sim p_{\boldsymbol{h}}(\boldsymbol{h})}
[\log (1 - D(G(\boldsymbol{h})))] \).
</p>

<p>On the other hand, the generator is trained to increase the chances of
\( D \) producing a high probability for a fake example, thus to minimize
\( \mathbb{E}_{\boldsymbol{h} \sim p_{\boldsymbol{h}}(\boldsymbol{h})} [\log (1 - D(G(\boldsymbol{h})))] \).
</p>
</section>

<section>
<h2 id="minimax-game">Minimax game </h2>

<p>When combining both aspects together, \( D \) and \( G \) are playing a <b>minimax game</b> in which we should optimize the following loss function:</p>

<p>&nbsp;<br>
$$
\begin{aligned}
\min_G \max_D L(D, G) 
& = \mathbb{E}_{\boldsymbol{x} \sim p_{r}(\boldsymbol{x})} [\log D(\boldsymbol{x})] + \mathbb{E}_{\boldsymbol{h} \sim p_{\boldsymbol{h}}(\boldsymbol{h})} [\log(1 - D(G(\boldsymbol{h})))] \\
& = \mathbb{E}_{\boldsymbol{x} \sim p_{r}(\boldsymbol{x})} [\log D(\boldsymbol{x})] + \mathbb{E}_{\boldsymbol{x} \sim p_g(\boldsymbol{x})} [\log(1 - D(\boldsymbol{x})]
\end{aligned}
$$
<p>&nbsp;<br>

<p>where \( \mathbb{E}_{\boldsymbol{x} \sim p_{r}(\boldsymbol{x})} [\log D(\boldsymbol{x})] \) has no impact on \( G \) during gradient descent updates.</p>
</section>

<section>
<h2 id="optimal-value-for-d">Optimal value for \( D \) </h2>

<p>Now we have a well-defined loss function. Let's first examine what is the best value for \( D \).</p>

<p>&nbsp;<br>
$$
L(G, D) = \int_{\boldsymbol{x}} \bigg( p_{r}(\boldsymbol{x}) \log(D(\boldsymbol{x})) + p_g (\boldsymbol{x}) \log(1 - D(\boldsymbol{x})) \bigg) dx
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="best-value-of-d">Best value of \( D \) </h2>
<p>Since we are interested in what is the best value of \( D(\boldsymbol{x}) \) to maximize \( L(G, D) \), let us label </p>

<p>&nbsp;<br>
$$
\tilde{\boldsymbol{x}} = D(\boldsymbol{x}), 
A=p_{r}(\boldsymbol{x}), 
B=p_g(\boldsymbol{x})
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="integral-evaluation">Integral evaluation </h2>

<p>The integral (we can safely ignore the integral because \( \boldsymbol{x} \) is sampled over all the possible values) is:</p>

<p>&nbsp;<br>
$$
\begin{align*}
f(\tilde{\boldsymbol{x}}) 
& = A \log{\tilde{\boldsymbol{x}}} + B \log{(1-\tilde{\boldsymbol{x}})} \\
\frac{d f(\tilde{\boldsymbol{x}})}{d \tilde{\boldsymbol{x}}} & = A \frac{1}{\tilde{\boldsymbol{x}}} - B\frac{1}{1 - \tilde{\boldsymbol{x}}} \\
& = \frac{A - (A + B)\tilde{\boldsymbol{x}}} {\tilde{\boldsymbol{x}} (1 - \tilde{\boldsymbol{x}})}. \\
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="best-values">Best values </h2>

<p>If we set</p>

<p>&nbsp;<br>
$$
\frac{d f(\tilde{\boldsymbol{x}})}{d \tilde{\boldsymbol{x}}} = 0,
$$
<p>&nbsp;<br>

<p>we get
the best value of the discriminator:
</p>

<p>&nbsp;<br>
$$
D^*(\boldsymbol{x}) = \tilde{\boldsymbol{x}}^* =\frac{A}{A + B} = \frac{p_{r}(\boldsymbol{x})}{p_{r}(\boldsymbol{x}) + p_g(\boldsymbol{x})}
\in [0, 1].
$$
<p>&nbsp;<br>

<p>Once the generator is trained to its optimal, \( p_g \) gets
very close to \( p_{r} \). When \( p_g = p_{r} \), \( D^*(\boldsymbol{x}) \) becomes
\( 1/2 \). We will observe this when running the code below here.
</p>
</section>

<section>
<h2 id="at-their-optimal-values">At their optimal values </h2>

<p>When both \( G \) and \( D \) are at their optimal values, we have \( p_g = p_{r} \) and \( D^*(\boldsymbol{x}) = 1/2 \), the loss function becomes</p>

<p>&nbsp;<br>
$$
\begin{align*}
L(G, D^*) 
&= \int_{\boldsymbol{x}} \bigg( p_{r}(\boldsymbol{x}) \log(D^*(\boldsymbol{x})) + p_g (\boldsymbol{x}) \log(1 - D^*(\boldsymbol{x})) \bigg) d\boldsymbol{x} \\
&= \log \frac{1}{2} \int_{\boldsymbol{h}} p_{r}(\boldsymbol{x}) d\boldsymbol{x} + \log \frac{1}{2} \int_{\boldsymbol{x}} p_g(\boldsymbol{x}) d\boldsymbol{x} \\
&= -2\log2
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="what-does-the-loss-function-represent">What does the Loss Function Represent? </h2>

<p>The JS divergence between \( p_{r} \) and \( p_g \) can be computed as:</p>

<p>&nbsp;<br>
$$
\begin{align*}
D_{JS}(p_{r} \| p_g) 
=& \frac{1}{2} D_{KL}(p_{r} || \frac{p_{r} + p_g}{2}) + \frac{1}{2} D_{KL}(p_{g} || \frac{p_{r} + p_g}{2}) \\
=& \frac{1}{2} \bigg( \log2 + \int_x p_{r}(\boldsymbol{x}) \log \frac{p_{r}(\boldsymbol{x})}{p_{r} + p_g(\boldsymbol{x})} d\boldsymbol{x} \bigg) + \\& \frac{1}{2} \bigg( \log2 + \int_x p_g(\boldsymbol{x}) \log \frac{p_g(\boldsymbol{x})}{p_{r} + p_g(\boldsymbol{x})} d\boldsymbol{x} \bigg) \\
=& \frac{1}{2} \bigg( \log4 + L(G, D^*) \bigg)
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="what-does-the-loss-function-quantify">What does the loss function quantify? </h2>

<p>We have </p>
<p>&nbsp;<br>
$$
L(G, D^*) = 2D_{JS}(p_{r} \| p_g) - 2\log2.
$$
<p>&nbsp;<br>

<p>Essentially the loss function of GAN quantifies the similarity between
the generative data distribution \( p_g \) and the real sample
distribution \( p_{r} \) by JS divergence when the discriminator is
optimal. The best \( G^* \) that replicates the real data distribution
leads to the minimum \( L(G^*, D^*) = -2\log2 \) which is aligned with
equations above.
</p>
</section>

<section>
<h2 id="problems-with-gans">Problems with GANs </h2>

<p>Although GANs have achieved  great success in the generation of realistic images, the training is not easy; The process is known to be slow and unstable.</p>

<div class="alert alert-block alert-block alert-text-normal">
<b>Hard to reach equilibrium.</b>
<p>
<p>Two models are trained simultaneously to an equilibrium to a
two-player non-cooperative game. However, each model updates its cost
independently with no respect to another player in the game. Updating
the gradient of both models concurrently cannot guarantee a
convergence.
</p>
</div>
</section>

<section>
<h2 id="vanishing-gradient">Vanishing Gradient  </h2>

<p>When the discriminator is perfect, we are guaranteed with
\( D(x) = 1, \forall x \in p_r \) and \( D(x) = 0, \forall x \in p_g \).
</p>

<p>Then, the
loss function \( L \) falls to zero and we end up with no gradient to
update the loss during learning iterations. One can encouter situations where 
the discriminator gets better and the gradient vanishes fast.
</p>

<p>As a result, training GANs may face the following problems </p>
<ol>
<p><li> If the discriminator behaves badly, the generator does not have accurate feedback and the loss function cannot represent the real data</li>
<p><li> If the discriminator does a great job, the gradient of the loss function drops down to close to zero and the learning can become slow</li>
</ol>
</section>

<section>
<h2 id="improved-gans">Improved GANs </h2>

<p>One of the solutions to improved GANs training, is the introduction of
what is called the Wasserstein diatance, which is a way to compute the
difference/distance between two probability distribitions. For those
interested in reading more, we recommend for example chapter 17 of
Rashcka's et al textbook, Machine Learning with PyTorch and Scikit-Learn, chapter 17, see URL:"https://github.com/rasbt/python-machine-learning-book\
-3rd-edition/tree/master/ch17"
</p>

<p>For a definition of the Wasserstein distance, see for example <a href="https://arxiv.org/pdf/2103.01678" target="_blank"><tt>https://arxiv.org/pdf/2103.01678</tt></a></p>
</section>

<section>
<h2 id="diffusion-models-basics">Diffusion models, basics </h2>

<p>Diffusion models are inspired by non-equilibrium thermodynamics. They
define a Markov chain of diffusion steps to slowly add random noise to
data and then learn to reverse the diffusion process to construct
desired data samples from the noise. Unlike VAE or flow models,
diffusion models are learned with a fixed procedure and the latent
variable has high dimensionality (same as the original data).
</p>
</section>

<section>
<h2 id="problems-with-probabilistic-models">Problems with probabilistic models </h2>

<p>Historically, probabilistic models suffer from a tradeoff between two
conflicting objectives: \textit{tractability} and
\textit{flexibility}. Models that are \textit{tractable} can be
analytically evaluated and easily fit to data (e.g. a Gaussian or
Laplace). However, these models are unable to aptly describe structure
in rich datasets. On the other hand, models that are \textit{flexible}
can be molded to fit structure in arbitrary data. For example, we can
define models in terms of any (non-negative) function \( \phi(\boldsymbol{x}) \)
yielding the flexible distribution \( p\left(\boldsymbol{x}\right) =
\frac{\phi\left(\boldsymbol{x} \right)}{Z} \), where \( Z \) is a normalization
constant. However, computing this normalization constant is generally
intractable. Evaluating, training, or drawing samples from such
flexible models typically requires a very expensive Monte Carlo
process.
</p>
</section>

<section>
<h2 id="diffusion-models">Diffusion models </h2>
<p>Diffusion models have several interesting features</p>
<ul>
<p><li> extreme flexibility in model structure,</li>
<p><li> exact sampling,</li>
<p><li> easy multiplication with other distributions, e.g. in order to compute a posterior, and</li>
<p><li> the model log likelihood, and the probability of individual states, to be cheaply evaluated.</li>
</ul>
</section>

<section>
<h2 id="original-idea">Original idea </h2>

<p>In the original formulation, one uses a Markov chain to gradually
convert one distribution into another, an idea used in non-equilibrium
statistical physics and sequential Monte Carlo. Diffusion models build
a generative Markov chain which converts a simple known distribution
(e.g. a Gaussian) into a target (data) distribution using a diffusion
process. Rather than use this Markov chain to approximately evaluate a
model which has been otherwise defined, one can  explicitly define the
probabilistic model as the endpoint of the Markov chain. Since each
step in the diffusion chain has an analytically evaluable probability,
the full chain can also be analytically evaluated.
</p>
</section>

<section>
<h2 id="diffusion-learning">Diffusion learning </h2>

<p>Learning in this framework involves estimating small perturbations to
a diffusion process. Estimating small, analytically tractable,
perturbations is more tractable than explicitly describing the full
distribution with a single, non-analytically-normalizable, potential
function.  Furthermore, since a diffusion process exists for any
smooth target distribution, this method can capture data distributions
of arbitrary form.
</p>
</section>

<section>
<h2 id="mathematics-of-diffusion-models">Mathematics of diffusion models </h2>

<p>Let us go back our discussions of the variational autoencoders from
last week, see
<a href="https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb" target="_blank"><tt>https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb</tt></a>. As
a first attempt at understanding diffusion models, we can think of
these as stacked VAEs, or better, recursive VAEs.
</p>

<p>Let us try to see why. As an intermediate step, we consider so-called
hierarchical VAEs, which can be seen as a generalization of VAEs that
include multiple hierarchies of latent spaces.
</p>
</section>

<section>
<h2 id="chains-of-vaes">Chains of VAEs </h2>
<p>As an intermediate step, we introduce what is often called Markovian
VAE where the generative process is a Markov chain and build a hierarchy of VAEs.
</p>

<p>Each transition down the hierarchy is Markovian, where we decode each
latent set of variables \( \boldsymbol{h}_t \) in terms of the previous latent variable$\boldsymbol{h}_{t-1}$.
Intuitively, and visually, this can be seen as simply stacking VAEs on
top of each other (see figure next slide).
</p>

<p>One can think of such a model as a recursive VAE.</p>
</section>

<section>
<h2 id="mathematical-representation">Mathematical representation </h2>

<p>Mathematically, we represent the joint distribution and the posterior
of a Markovian VAE as
</p>
<p>&nbsp;<br>
$$
\begin{align*}
    p(\boldsymbol{x}, \boldsymbol{h}_{1:T}) &= p(\boldsymbol{h}_T)p_{\boldsymbol{\theta}}(\boldsymbol{x}|\boldsymbol{h}_1)\prod_{t=2}^{T}p_{\boldsymbol{\theta}}(\boldsymbol{h}_{t-1}|\boldsymbol{h}_{t})\\
    q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x}) &= q_{\boldsymbol{\phi}}(\boldsymbol{h}_1|\boldsymbol{x})\prod_{t=2}^{T}q_{\boldsymbol{\phi}}(\boldsymbol{h}_{t}|\boldsymbol{h}_{t-1})
\end{align*}
$$
<p>&nbsp;<br>
</section>

<section>
<h2 id="back-to-the-marginal-probability">Back to the marginal probability </h2>

<p>We can then define the marginal probability we want to optimize as</p>
$$
\begin{align*}
\log p(\boldsymbol{x}) &= \log \int p(\boldsymbol{x}, \boldsymbol{h}_{1:T}) d\boldsymbol{h}_{1:T}  \\
&= \log \int \frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})} d\boldsymbol{h}_{1:T}         && \text{(Multiply by 1 = $\frac{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}$)}\\
&= \log \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\right]         && \text{(Definition of Expectation)}\\
&\geq \mathbb{E}_{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\left[\log \frac{p(\boldsymbol{x}, \boldsymbol{h}_{1:T})}{q_{\boldsymbol{\phi}}(\boldsymbol{h}_{1:T}|\boldsymbol{x})}\right]         && \text{(Discussed last week)}
\end{align*}
$$
</section>

<section>
<h2 id="diffusion-models-for-hierarchical-vae-from-url-https-arxiv-org-abs-2208-11970">Diffusion models for hierarchical VAE, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<p>A Markovian hierarchical Variational Autoencoder with \( T \) hierarchical
latents.  The generative process is modeled as a Markov chain, where
each latent \( \boldsymbol{h}_t \) is generated only from the previous latent
\( \boldsymbol{h}_{t+1} \)
</p>

<br/><br/>
<center>
<p><img src="figures/figure1.png" width="800" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="diffusion-models-from-url-https-arxiv-org-abs-2208-11970">Diffusion models, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<br/><br/>
<center>
<p><img src="figures/figure2.png" width="800" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="diffusion-models-part-2-from-url-https-arxiv-org-abs-2208-11970">Diffusion models, part 2, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<br/><br/>
<center>
<p><img src="figures/figure3.png" width="800" align="bottom"></p>
</center>
<br/><br/>
</section>

<section>
<h2 id="diffusion-models-part-3-from-url-https-arxiv-org-abs-2208-11970">Diffusion models, part 3, from <a href="https://arxiv.org/abs/2208.11970" target="_blank"><tt>https://arxiv.org/abs/2208.11970</tt></a>  </h2>

<br/><br/>
<center>
<p><img src="figures/figure4.png" width="800" align="bottom"></p>
</center>
<br/><br/>
</section>



</div> <!-- class="slides" -->
</div> <!-- class="reveal" -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

  // Display navigation controls in the bottom right corner
  controls: true,

  // Display progress bar (below the horiz. slider)
  progress: true,

  // Display the page number of the current slide
  slideNumber: true,

  // Push each slide change to the browser history
  history: false,

  // Enable keyboard shortcuts for navigation
  keyboard: true,

  // Enable the slide overview mode
  overview: true,

  // Vertical centering of slides
  //center: true,
  center: false,

  // Enables touch navigation on devices with touch input
  touch: true,

  // Loop the presentation
  loop: false,

  // Change the presentation direction to be RTL
  rtl: false,

  // Turns fragments on and off globally
  fragments: true,

  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,

  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,

  // Stop auto-sliding after user input
  autoSlideStoppable: true,

  // Enable slide navigation via mouse wheel
  mouseWheel: false,

  // Hides the address bar on mobile devices
  hideAddressBar: true,

  // Opens links in an iframe preview overlay
  previewLinks: false,

  // Transition style
  transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

  // Transition speed
  transitionSpeed: 'default', // default/fast/slow

  // Transition style for full page slide backgrounds
  backgroundTransition: 'default', // default/none/slide/concave/convex/zoom

  // Number of slides away from the current that are visible
  viewDistance: 3,

  // Parallax background image
    //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

  // Parallax background size
  //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

  theme: Reveal.getQueryHash().theme, // available themes are in reveal.js/css/theme
    transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/none

});

Reveal.initialize({
  dependencies: [
      // Cross-browser shim that fully implements classList - https://github.com/eligrey/classList.js/
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },

      // Interpret Markdown in <section> elements
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

      // Syntax highlight for <code> elements
      { src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },

      // Zoom in and out with Alt+click
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },

      // Speaker notes
      { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },

      // Remote control your reveal.js presentation using a touch device
      //{ src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } },

      // MathJax
      //{ src: 'reveal.js/plugin/math/math.js', async: true }
  ]
});

Reveal.initialize({

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 1170,  // original: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.0

});
</script>

<!-- begin footer logo
<div style="position: absolute; bottom: 0px; left: 0; margin-left: 0px">
<img src="somelogo.png">
</div>
   end footer logo -->




</body>
</html>

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6d32a2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html week16.do.txt --no_mako -->\n",
    "<!-- dom:TITLE: Advanced machine learning and data analysis for the physical sciences -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40461fd",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Advanced machine learning and data analysis for the physical sciences\n",
    "**Morten Hjorth-Jensen**, Department of Physics and Center for Computing in Science Education, University of Oslo, Norway and Department of Physics and Astronomy and Facility for Rare Isotope Beams, Michigan State University, East Lansing, Michigan, USA\n",
    "\n",
    "Date: **May 7, 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b0a7e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Plans for the week of May 6-10, 2024\n",
    "\n",
    "**Generative models.**\n",
    "\n",
    "1. Finalizing discussion of Generative Adversarial Networks\n",
    "\n",
    "2. Mathematics of diffusion models and selected examples\n",
    "\n",
    "3. [Video of lecture](https://youtu.be/lYgKGCQRUhQ)\n",
    "\n",
    "4. [Whiteboard notes](https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/HandwrittenNotes/2024/NotesMay7.pdf)\n",
    "\n",
    "**Reading on diffusion models.**\n",
    "\n",
    "1. A central paper is the one by Sohl-Dickstein et al, Deep Unsupervised Learning using Nonequilibrium Thermodynamics, <https://arxiv.org/abs/1503.03585>\n",
    "\n",
    "2. Calvin Luo at <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "3. See also Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho, Variational Diffusion Models, <https://arxiv.org/abs/2107.00630>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481707c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Reminder from last week, what is a GAN?\n",
    "\n",
    "A GAN is a deep neural network which consists of two networks, a\n",
    "so-called generator network and a discriminating network, or just\n",
    "discriminator. Through several iterations of generation and\n",
    "discrimination, the idea is that these networks will train each other,\n",
    "while also trying to outsmart each other.\n",
    "\n",
    "In its simplest version, the two networks could be two standard neural networks with a given number of hidden of hidden layers and parameters to train.\n",
    "The generator we have trained can then be used to produce new images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1899342",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Labeling the networks\n",
    "\n",
    "For a GAN we have: \n",
    "1. a discriminator $D$ estimates the probability of a given sample coming from the real dataset. It attempts at discriminating the trained data by the generator and is optimized to tell the fake samples from the real ones (our data set). We say a  discriminator tries to distinguish between real data and those generated by the abovementioned generator.\n",
    "\n",
    "2. a generator $G$ outputs synthetic samples given a noise variable input $z$ ($z$ brings in potential output diversity). It is trained to capture the real data distribution in order to generate samples that can be as real as possible, or in other words, can trick the discriminator to offer a high probability.\n",
    "\n",
    "At the end of the training, the generator can be used to generate for\n",
    "example new images. In this sense we have trained a model which can\n",
    "produce new samples. We say that we have implicitely defined a\n",
    "probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f571bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Which data?\n",
    "\n",
    "**GANs are generally a form of unsupervised machine learning**, although\n",
    "they also incorporate aspects of supervised learning. Internally the\n",
    "discriminator sets up a supervised learning problem. Its goal is to\n",
    "learn to distinguish between the two classes of generated data and\n",
    "original data. The generator then considers this classification\n",
    "problem and tries to find adversarial examples, that is  samples which\n",
    "will be misclassified by the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380028c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Semi-supervised learning\n",
    "\n",
    "One can also design GAN architectures which work in a\n",
    "semi-supervised learning setting. A semi-supervised learning environment includes both labeled and unlabeled data.\n",
    "See <https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf> for a further discussion.\n",
    "\n",
    "Thus, GANs can be used both on labeled and on unlabeled data and are used in three most commonly used contexts, that is\n",
    "1. with labeled data (supervised training)\n",
    "\n",
    "2. with unlabeled data (unsupervised learning)\n",
    "\n",
    "3. a with a mix labed and unlabeled  data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b45b32",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Improving functionalities\n",
    "\n",
    "These two models compete against each other during the training\n",
    "process: the generator $G$ is trying hard to trick the discriminator,\n",
    "while the critic model $D$ is trying hard not to be cheated. This\n",
    "interesting zero-sum game between two models motivates both to improve\n",
    "their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d6b20",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Setup of the GAN\n",
    "\n",
    "We define a probability $p_{\\boldsymbol{h}}$ which is used by the\n",
    "generator. Usually it is given by a uniform distribution over the\n",
    "input $\\boldsymbol{h}$. Thereafter we define the distribution of the\n",
    "generator which we want to train, $p_{g}$ This is the generator's\n",
    "distribution over the data $\\boldsymbol{x}$. Finally, we have the distribution\n",
    "$p_{r}$ over the real sample $\\boldsymbol{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05935e18",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization part\n",
    "\n",
    "On one hand, we want to make sure the discriminator $D$'s decisions\n",
    "over real data are accurate by maximizing $\\mathbb{E}_{\\boldsymbol{x} \\sim\n",
    "p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})]$. Meanwhile, given a fake sample $G(\\boldsymbol{h}), \\boldsymbol{h} \\sim\n",
    "p_{\\boldsymbol{h}}(\\boldsymbol{h})$, the discriminator is expected to output a probability,\n",
    "$D(G(\\boldsymbol{h}))$, close to zero by maximizing $\\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})}\n",
    "[\\log (1 - D(G(\\boldsymbol{h})))]$.\n",
    "\n",
    "On the other hand, the generator is trained to increase the chances of\n",
    "$D$ producing a high probability for a fake example, thus to minimize\n",
    "$\\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})} [\\log (1 - D(G(\\boldsymbol{h})))]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee5e71",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Minimax game\n",
    "\n",
    "When combining both aspects together, $D$ and $G$ are playing a **minimax game** in which we should optimize the following loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755f225",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_G \\max_D L(D, G) \n",
    "& = \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})] + \\mathbb{E}_{\\boldsymbol{h} \\sim p_{\\boldsymbol{h}}(\\boldsymbol{h})} [\\log(1 - D(G(\\boldsymbol{h})))] \\\\\n",
    "& = \\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})] + \\mathbb{E}_{\\boldsymbol{x} \\sim p_g(\\boldsymbol{x})} [\\log(1 - D(\\boldsymbol{x})]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bab7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbb{E}_{\\boldsymbol{x} \\sim p_{r}(\\boldsymbol{x})} [\\log D(\\boldsymbol{x})]$ has no impact on $G$ during gradient descent updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5fa79",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimal value for $D$\n",
    "\n",
    "Now we have a well-defined loss function. Let's first examine what is the best value for $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c2ac2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L(G, D) = \\int_{\\boldsymbol{x}} \\bigg( p_{r}(\\boldsymbol{x}) \\log(D(\\boldsymbol{x})) + p_g (\\boldsymbol{x}) \\log(1 - D(\\boldsymbol{x})) \\bigg) d\\boldsymbol{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f09424",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Best value of $D$\n",
    "Since we are interested in what is the best value of $D(\\boldsymbol{x})$ to maximize $L(G, D)$, let us label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc7ce5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{\\boldsymbol{x}} = D(\\boldsymbol{x}), \n",
    "A=p_{r}(\\boldsymbol{x}), \n",
    "B=p_g(\\boldsymbol{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a355f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Integral evaluation\n",
    "\n",
    "The integral (we can safely ignore the integral because $\\boldsymbol{x}$ is sampled over all the possible values) is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ae43c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "f(\\tilde{\\boldsymbol{x}}) \n",
    "& = A \\log{\\tilde{\\boldsymbol{x}}} + B \\log{(1-\\tilde{\\boldsymbol{x}})} \\\\\n",
    "\\frac{d f(\\tilde{\\boldsymbol{x}})}{d \\tilde{\\boldsymbol{x}}} & = A \\frac{1}{\\tilde{\\boldsymbol{x}}} - B\\frac{1}{1 - \\tilde{\\boldsymbol{x}}} \\\\\n",
    "& = \\frac{A - (A + B)\\tilde{\\boldsymbol{x}}} {\\tilde{\\boldsymbol{x}} (1 - \\tilde{\\boldsymbol{x}})}. \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fad1d2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Best values\n",
    "\n",
    "If we set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5ec58",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{d f(\\tilde{\\boldsymbol{x}})}{d \\tilde{\\boldsymbol{x}}} = 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586f531",
   "metadata": {
    "editable": true
   },
   "source": [
    "we get\n",
    "the best value of the discriminator:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc5d92",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "D^*(\\boldsymbol{x}) = \\tilde{\\boldsymbol{x}}^* =\\frac{A}{A + B} = \\frac{p_{r}(\\boldsymbol{x})}{p_{r}(\\boldsymbol{x}) + p_g(\\boldsymbol{x})}\n",
    "\\in [0, 1].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f733f",
   "metadata": {
    "editable": true
   },
   "source": [
    "Once the generator is trained to its optimal, $p_g$ gets\n",
    "very close to $p_{r}$. When $p_g = p_{r}$, $D^*(\\boldsymbol{x})$ becomes\n",
    "$1/2$. We will observe this when running the code from last week (see jupyter-notebook from week 15)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a09bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## At their optimal values\n",
    "\n",
    "When both $G$ and $D$ are at their optimal values, we have $p_g = p_{r}$ and $D^*(\\boldsymbol{x}) = 1/2$, the loss function becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500635dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "L(G, D^*) \n",
    "&= \\int_{\\boldsymbol{x}} \\bigg( p_{r}(\\boldsymbol{x}) \\log(D^*(\\boldsymbol{x})) + p_g (\\boldsymbol{x}) \\log(1 - D^*(\\boldsymbol{x})) \\bigg) d\\boldsymbol{x} \\\\\n",
    "&= \\log \\frac{1}{2} \\int_{\\boldsymbol{h}} p_{r}(\\boldsymbol{x}) d\\boldsymbol{x} + \\log \\frac{1}{2} \\int_{\\boldsymbol{x}} p_g(\\boldsymbol{x}) d\\boldsymbol{x} \\\\\n",
    "&= -2\\log2\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f4c10",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What does the Loss Function Represent?\n",
    "\n",
    "The JS divergence between $p_{r}$ and $p_g$ can be computed as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549872d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "D_{JS}(p_{r} \\| p_g) \n",
    "=& \\frac{1}{2} D_{KL}(p_{r} || \\frac{p_{r} + p_g}{2}) + \\frac{1}{2} D_{KL}(p_{g} || \\frac{p_{r} + p_g}{2}) \\\\\n",
    "=& \\frac{1}{2} \\bigg( \\log2 + \\int_x p_{r}(\\boldsymbol{x}) \\log \\frac{p_{r}(\\boldsymbol{x})}{p_{r} + p_g(\\boldsymbol{x})} d\\boldsymbol{x} \\bigg) + \\\\& \\frac{1}{2} \\bigg( \\log2 + \\int_x p_g(\\boldsymbol{x}) \\log \\frac{p_g(\\boldsymbol{x})}{p_{r} + p_g(\\boldsymbol{x})} d\\boldsymbol{x} \\bigg) \\\\\n",
    "=& \\frac{1}{2} \\bigg( \\log4 + L(G, D^*) \\bigg)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4812eb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## What does the loss function quantify?\n",
    "\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f324c7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "L(G, D^*) = 2D_{JS}(p_{r} \\| p_g) - 2\\log2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e587d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The loss function of GANs quantifies the similarity between\n",
    "the generative data distribution $p_g$ and the real sample\n",
    "distribution $p_{r}$ by the so-called JS divergence when the discriminator is\n",
    "optimal. The best $G^*$ that replicates the real data distribution\n",
    "leads to the minimum $L(G^*, D^*) = -2\\log2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2e763",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Problems with GANs\n",
    "\n",
    "Although GANs have achieved  great success in the generation of realistic images, the training is not easy; The process is known to be slow and unstable.\n",
    "\n",
    "**Hard to reach equilibrium.**\n",
    "\n",
    "Two models are trained simultaneously to an equilibrium to a\n",
    "two-player non-cooperative game. However, each model updates its cost\n",
    "independently with no respect to another player in the game. Updating\n",
    "the gradient of both models concurrently cannot guarantee a\n",
    "convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9308c7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Vanishing Gradient\n",
    "\n",
    "When the discriminator is perfect, we are guaranteed with\n",
    "$D(\\boldsymbol{x}) = 1, \\forall \\boldsymbol{x} \\in p_r$ and $D(\\boldsymbol{x}) = 0, \\forall \\boldsymbol{x} \\in p_g$.\n",
    "\n",
    "Then, the\n",
    "loss function $L$ falls to zero and we end up with no gradient to\n",
    "update the loss during learning iterations. One can encouter situations where \n",
    "the discriminator gets better and the gradient vanishes fast.\n",
    "\n",
    "As a result, training GANs may face the following problems \n",
    "1. If the discriminator behaves badly, the generator does not have accurate feedback and the loss function cannot represent the real data\n",
    "\n",
    "2. If the discriminator does a great job, the gradient of the loss function drops down to close to zero and the learning can become slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4701b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Improved GANs\n",
    "\n",
    "One of the solutions to improved GANs training, is the introduction of\n",
    "what is called the Wasserstein diatance, which is a way to compute the\n",
    "difference/distance between two probability distribitions. For those\n",
    "interested in reading more, we recommend for example chapter 17 of\n",
    "Rashcka's et al textbook,\n",
    "Machine Learning with PyTorch and Scikit-Learn, chapter 17, see <https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17>\n",
    "\n",
    "For a definition of the Wasserstein distance, see for example <https://arxiv.org/pdf/2103.01678>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08586bf4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More codes\n",
    "\n",
    "1. For codes and background, see Raschka et al, Machine Learning with PyTorch and Scikit-Learn, chapter 17, see <https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch17> for codes\n",
    "\n",
    "2. Babcock and Bali, Generative AI with Python and TensorFlow2, chapter 6 and codes at <https://github.com/raghavbali/generative_ai_with_tensorflow/blob/master/Chapter_6/conditional_gan.ipynb>\n",
    "\n",
    "3. See also Foster's text Generative Deep Learning and chapter 4 with codes at <https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks/04_gan>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06cae80",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, basics\n",
    "\n",
    "Diffusion models are inspired by non-equilibrium thermodynamics. They\n",
    "define a Markov chain of diffusion steps to slowly add random noise to\n",
    "data and then learn to reverse the diffusion process to construct\n",
    "desired data samples from the noise. Unlike VAE or flow models,\n",
    "diffusion models are learned with a fixed procedure and the latent\n",
    "variable has high dimensionality (same as the original data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb54844",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Problems with probabilistic models\n",
    "\n",
    "Historically, probabilistic models suffer from a tradeoff between two\n",
    "conflicting objectives: \\textit{tractability} and\n",
    "\\textit{flexibility}. Models that are \\textit{tractable} can be\n",
    "analytically evaluated and easily fit to data (e.g. a Gaussian or\n",
    "Laplace). However, these models are unable to aptly describe structure\n",
    "in rich datasets. On the other hand, models that are \\textit{flexible}\n",
    "can be molded to fit structure in arbitrary data. For example, we can\n",
    "define models in terms of any (non-negative) function $\\phi(\\boldsymbol{x})$\n",
    "yielding the flexible distribution $p\\left(\\boldsymbol{x}\\right) =\n",
    "\\frac{\\phi\\left(\\boldsymbol{x} \\right)}{Z}$, where $Z$ is a normalization\n",
    "constant. However, computing this normalization constant is generally\n",
    "intractable. Evaluating, training, or drawing samples from such\n",
    "flexible models typically requires a very expensive Monte Carlo\n",
    "process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f2b16",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models\n",
    "Diffusion models have several interesting features\n",
    "* extreme flexibility in model structure,\n",
    "\n",
    "* exact sampling,\n",
    "\n",
    "* easy multiplication with other distributions, e.g. in order to compute a posterior, and\n",
    "\n",
    "* the model log likelihood, and the probability of individual states, to be cheaply evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc85189",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Original idea\n",
    "\n",
    "In the original formulation, one uses a Markov chain to gradually\n",
    "convert one distribution into another, an idea used in non-equilibrium\n",
    "statistical physics and sequential Monte Carlo. Diffusion models build\n",
    "a generative Markov chain which converts a simple known distribution\n",
    "(e.g. a Gaussian) into a target (data) distribution using a diffusion\n",
    "process. Rather than use this Markov chain to approximately evaluate a\n",
    "model which has been otherwise defined, one can  explicitly define the\n",
    "probabilistic model as the endpoint of the Markov chain. Since each\n",
    "step in the diffusion chain has an analytically evaluable probability,\n",
    "the full chain can also be analytically evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6638f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion learning\n",
    "\n",
    "Learning in this framework involves estimating small perturbations to\n",
    "a diffusion process. Estimating small, analytically tractable,\n",
    "perturbations is more tractable than explicitly describing the full\n",
    "distribution with a single, non-analytically-normalizable, potential\n",
    "function.  Furthermore, since a diffusion process exists for any\n",
    "smooth target distribution, this method can capture data distributions\n",
    "of arbitrary form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847408bc",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mathematics of diffusion models\n",
    "\n",
    "Let us go back our discussions of the variational autoencoders from\n",
    "last week, see\n",
    "<https://github.com/CompPhysics/AdvancedMachineLearning/blob/main/doc/pub/week15/ipynb/week15.ipynb>. As\n",
    "a first attempt at understanding diffusion models, we can think of\n",
    "these as stacked VAEs, or better, recursive VAEs.\n",
    "\n",
    "Let us try to see why. As an intermediate step, we consider so-called\n",
    "hierarchical VAEs, which can be seen as a generalization of VAEs that\n",
    "include multiple hierarchies of latent spaces.\n",
    "\n",
    "**Note**: Many of the derivations and figures here are inspired and borrowed from the excellent exposition of diffusion models by Calvin Luo at <https://arxiv.org/abs/2208.11970>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b871ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Chains of VAEs\n",
    "\n",
    "Markovian\n",
    "VAEs represent a  generative process where we use  Markov chain to build a hierarchy of VAEs.\n",
    "\n",
    "Each transition down the hierarchy is Markovian, where we decode each\n",
    "latent set of variables $\\boldsymbol{h}_t$ in terms of the previous latent variable $\\boldsymbol{h}_{t-1}$.\n",
    "Intuitively, and visually, this can be seen as simply stacking VAEs on\n",
    "top of each other (see figure next slide).\n",
    "\n",
    "One can think of such a model as a recursive VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97d7b6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Mathematical representation\n",
    "\n",
    "Mathematically, we represent the joint distribution and the posterior\n",
    "of a Markovian VAE as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86167090",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T}) &= p(\\boldsymbol{h}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{h}_{t-1}|\\boldsymbol{h}_{t})\\\\\n",
    "    q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x}) &= q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_1|\\boldsymbol{x})\\prod_{t=2}^{T}q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{t}|\\boldsymbol{h}_{t-1})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f584ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Back to the marginal probability\n",
    "\n",
    "We can then define the marginal probability we want to optimize as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745009cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x}) &= \\log \\int p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T}) d\\boldsymbol{h}_{1:T}  \\\\\n",
    "&= \\log \\int \\frac{p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T})q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})} d\\boldsymbol{h}_{1:T}         && \\text{(Multiply by 1 = $\\frac{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}$)}\\\\\n",
    "&= \\log \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\frac{p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\right]         && \\text{(Definition of Expectation)}\\\\\n",
    "&\\geq \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\right]         && \\text{(Discussed last week)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e06f52",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models for hierarchical VAE, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "A Markovian hierarchical Variational Autoencoder with $T$ hierarchical\n",
    "latents.  The generative process is modeled as a Markov chain, where\n",
    "each latent $\\boldsymbol{h}_t$ is generated only from the previous latent\n",
    "$\\boldsymbol{h}_{t+1}$. Here $\\boldsymbol{z}$ is our latent variable $\\boldsymbol{h}$.\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure1.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure1.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115e9db",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Equation for the Markovian hierarchical VAE\n",
    "\n",
    "We obtain then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfb7bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{x}, \\boldsymbol{h}_{1:T})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\right]\n",
    "&= \\mathbb{E}_{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{1:T}|\\boldsymbol{x})}\\left[\\log \\frac{p(\\boldsymbol{h}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}|\\boldsymbol{h}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{h}_{t-1}|\\boldsymbol{h}_{t})}{q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_1|\\boldsymbol{x})\\prod_{t=2}^{T}q_{\\boldsymbol{\\phi}}(\\boldsymbol{h}_{t}|\\boldsymbol{h}_{t-1})}\\right]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd0605",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will modify this equation when we discuss what are normally called Variational Diffusion Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5984b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Variational Diffusion Models\n",
    "\n",
    "The easiest way to think of a Variational Diffusion Model (VDM) is as a Markovian Hierarchical Variational Autoencoder with three key restrictions:\n",
    "\n",
    "1. The latent dimension is exactly equal to the data dimension\n",
    "\n",
    "2. The structure of the latent encoder at each timestep is not learned; it is pre-defined as a linear Gaussian model.  In other words, it is a Gaussian distribution centered around the output of the previous timestep\n",
    "\n",
    "3. The Gaussian parameters of the latent encoders vary over time in such a way that the distribution of the latent at final timestep $T$ is a standard Gaussian\n",
    "\n",
    "The VDM posterior is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf9bce",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0) = \\prod_{t = 1}^{T}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f5674",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Second assumption\n",
    "\n",
    "The distribution of each latent variable in the encoder is a Gaussian centered around its previous hierarchical latent.\n",
    "Here then, the structure of the encoder at each timestep $t$ is not learned; it\n",
    "is fixed as a linear Gaussian model, where the mean and standard\n",
    "deviation can be set beforehand as hyperparameters, or learned as\n",
    "parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5fba3",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Parameterizing Gaussian encoder\n",
    "\n",
    "We parameterize the Gaussian encoder with mean $\\boldsymbol{\\mu}_t(\\boldsymbol{x}_t) =\n",
    "\\sqrt{\\alpha_t} \\boldsymbol{x}_{t-1}$, and variance $\\boldsymbol{\\Sigma}_t(\\boldsymbol{x}_t) =\n",
    "(1 - \\alpha_t) \\textbf{I}$, where the form of the coefficients are\n",
    "chosen such that the variance of the latent variables stay at a\n",
    "similar scale; in other words, the encoding process is\n",
    "variance-preserving.\n",
    "\n",
    "Note that alternate Gaussian parameterizations\n",
    "are allowed, and lead to similar derivations.  The main takeaway is\n",
    "that $\\alpha_t$ is a (potentially learnable) coefficient that can vary\n",
    "with the hierarchical depth $t$, for flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b28282d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Encoder transitions\n",
    "\n",
    "Mathematically, the encoder transitions are defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0632c1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:27\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1}) = \\mathcal{N}(\\boldsymbol{x}_{t} ; \\sqrt{\\alpha_t} \\boldsymbol{x}_{t-1}, (1 - \\alpha_t) \\textbf{I}) \\label{eq:27} \\tag{1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f8e70",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Third assumption\n",
    "\n",
    "From the third assumption, we know that $\\alpha_t$ evolves over time\n",
    "according to a fixed or learnable schedule structured such that the\n",
    "distribution of the final latent $p(\\boldsymbol{x}_T)$ is a standard Gaussian.\n",
    "We can then update the joint distribution of a Markovian VAE to write\n",
    "the joint distribution for a VDM as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9f226",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "p(\\boldsymbol{x}_{0:T}) &= p(\\boldsymbol{x}_T)\\prod_{t=1}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t) \\\\\n",
    "\\text{where,}&\\nonumber\\\\\n",
    "p(\\boldsymbol{x}_T) &= \\mathcal{N}(\\boldsymbol{x}_T; \\boldsymbol{0}, \\textbf{I})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e8d7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Noisification\n",
    "\n",
    "Collectively, what this set of assumptions describes is a steady\n",
    "noisification of an image input over time. We progressively corrupt an\n",
    "image by adding Gaussian noise until eventually it becomes completely\n",
    "identical to pure Gaussian noise.  See figure on next slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572e5aa",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure2.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure2.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68513b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Gaussian modeling\n",
    "\n",
    "Note that our encoder distributions $q(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})$ are no\n",
    "longer parameterized by $\\boldsymbol{\\phi}$, as they are completely modeled as\n",
    "Gaussians with defined mean and variance parameters at each timestep.\n",
    "Therefore, in a VDM, we are only interested in learning conditionals\n",
    "$p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_{t})$, so that we can simulate\n",
    "new data.  After optimizing the VDM, the sampling procedure is as\n",
    "simple as sampling Gaussian noise from $p(\\boldsymbol{x}_T)$ and iteratively\n",
    "running the denoising transitions\n",
    "$p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_{t})$ for $T$ steps to generate a\n",
    "novel $\\boldsymbol{x}_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9706a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimizing the variational diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f67dd0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x})\n",
    "&= \\log \\int p(\\boldsymbol{x}_{0:T}) d\\boldsymbol{x}_{1:T}\\\\\n",
    "&= \\log \\int \\frac{p(\\boldsymbol{x}_{0:T})q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)} d\\boldsymbol{x}_{1:T}\\\\\n",
    "&= \\log \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\frac{p(\\boldsymbol{x}_{0:T})}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\right]\\\\\n",
    "&\\geq {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_{0:T})}{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)\\prod_{t=1}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t)}{\\prod_{t = 1}^{T}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\prod_{t=2}^{T}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t-1}|\\boldsymbol{x}_t)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\prod_{t = 1}^{T-1}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\prod_{t=1}^{T-1}p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\prod_{t = 1}^{T-1}q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\prod_{t = 1}^{T-1}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d77949",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Continues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3939ef8c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\log p(\\boldsymbol{x})\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\prod_{t = 1}^{T-1}\\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[ \\sum_{t=1}^{T-1} \\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\sum_{t=1}^{T-1}\\mathbb{E}_{q(\\boldsymbol{x}_{1:T}|\\boldsymbol{x}_0)}\\left[ \\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "&= {\\mathbb{E}_{q(\\boldsymbol{x}_{1}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right] + \\mathbb{E}_{q(\\boldsymbol{x}_{T-1}, \\boldsymbol{x}_T|\\boldsymbol{x}_0)}\\left[\\log \\frac{p(\\boldsymbol{x}_T)}{q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})}\\right] + \\sum_{t=1}^{T-1}\\mathbb{E}_{q(\\boldsymbol{x}_{t-1}, \\boldsymbol{x}_t, \\boldsymbol{x}_{t+1}|\\boldsymbol{x}_0)}\\left[\\log \\frac{p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1})}{q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})}\\right]}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a310d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Interpretations\n",
    "\n",
    "These equations can be interpreted as\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{1}|\\boldsymbol{x}_0)}\\left[\\log p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_0|\\boldsymbol{x}_1)\\right]$ can be interpreted as a **reconstruction term**, predicting the log probability of the original data sample given the first-step latent.  This term also appears in a vanilla VAE, and can be trained similarly.\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{T-1}|\\boldsymbol{x}_0)}\\left[D_{KL}(q(\\boldsymbol{x}_T|\\boldsymbol{x}_{T-1})\\vert\\vert p(\\boldsymbol{x}_T))\\right]$ is a **prior matching term**; it is minimized when the final latent distribution matches the Gaussian prior.  This term requires no optimization, as it has no trainable parameters; furthermore, as we have assumed a large enough $T$ such that the final distribution is Gaussian, this term effectively becomes zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572da440",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The last term\n",
    "\n",
    "* $\\mathbb{E}_{q(\\boldsymbol{x}_{t-1}, \\boldsymbol{x}_{t+1}|\\boldsymbol{x}_0)}\\left[D_{KL}(q(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t-1})\\vert\\vert p_{\\boldsymbol{\\theta}}(\\boldsymbol{x}_{t}|\\boldsymbol{x}_{t+1}))\\right]$ is a \\textit{consistency term}; it endeavors to make the distribution at $\\boldsymbol{x}_t$ consistent, from both forward and backward processes.  That is, a denoising step from a noisier image should match the corresponding noising step from a cleaner image, for every intermediate timestep; this is reflected mathematically by the KL Divergence.  This term is minimized when we train $p_{\\theta}(\\boldsymbol{x}_t|\\boldsymbol{x}_{t+1})$ to match the Gaussian distribution $q(\\boldsymbol{x}_t|\\boldsymbol{x}_{t-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ccc35",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Diffusion models, part 2, from <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- dom:FIGURE: [figures/figure3.png, width=800 frac=1.0] -->\n",
    "<!-- begin figure -->\n",
    "\n",
    "<img src=\"figures/figure3.png\" width=\"800\"><p style=\"font-size: 0.9em\"><i>Figure 1: </i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25be2a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Optimization cost\n",
    "\n",
    "The cost of optimizing a VDM is primarily dominated by the third term, since we must optimize over all timesteps $t$.\n",
    "\n",
    "Under this derivation, all three terms are computed as expectations,\n",
    "and can therefore be approximated using Monte Carlo estimates.\n",
    "However, actually optimizing the ELBO using the terms we just derived\n",
    "might be suboptimal; because the consistency term is computed as an\n",
    "expectation over two random variables $\\left\\{\\boldsymbol{x}_{t-1},\n",
    "\\boldsymbol{x}_{t+1}\\right\\}$ for every timestep, the variance of its Monte\n",
    "Carlo estimate could potentially be higher than a term that is\n",
    "estimated using only one random variable per timestep.  As it is\n",
    "computed by summing up $T-1$ consistency terms, the final estimated\n",
    "value may have high variance for large $T$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75543568",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More details\n",
    "\n",
    "For more details and implementaions, see Calvin Luo at <https://arxiv.org/abs/2208.11970>\n",
    "\n",
    "<!-- FIGURE: [figures/figure4.png, width=800 frac=1.0] -->"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
